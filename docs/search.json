[
  {
    "objectID": "index.html#syllabus",
    "href": "index.html#syllabus",
    "title": "Personality PsychologyLab Handbook",
    "section": "Syllabus",
    "text": "Syllabus\n\nInstructor\nDr. Rob Brotherton (rbrother@barnard.edu)\nOffice hour: TBC\n\n\nTime & venue\n\n\n\n\n\nSection\nTime\nVenue\n\n\n\n\n001\nMonday 10:10–1PM\nMilbank 410\n\n\n002\nMonday 1:10–4PM\nMilbank 410\n\n\n\n\n\n\n\nClass schedule\n\n\n\n\n \n  \n    Date \n    Topic \n    Assignment \n  \n \n\n  \n    9/11 \n    Course overview \n     \n  \n  Project 1: Correlation\n\n    9/18 \n    Project planning \n     \n  \n  \n    9/25 \n    Data cleaning \n     \n  \n  \n    10/2 \n    Analysis \n    Presentation slide \n  \n  \n    10/9 \n    Presentations \n    Project 1 report \n  \n  Project 2: Multiple regression\n\n    10/16 \n    Project planning \n     \n  \n  \n    10/23 \n    Data cleaning & analysis \n     \n  \n  \n    10/30 \n    Visualization & reporting \n    Presentation slide \n  \n  \n    11/6 \n    Presentations \n    Project 2 report \n  \n  Project 3: Scale design\n\n    11/13 \n    Scale planning \n     \n  \n  \n    11/20 \n    Questionnaire design \n     \n  \n  \n    11/27 \n    No class (Thanksgiving) \n     \n  \n  \n    12/4 \n    Analysis & reporting \n    Presentation slide \n  \n  \n    12/11 \n    Presentations \n    Project 3 report \n  \n\n\n\n\n* Assignments due by the following class."
  },
  {
    "objectID": "index.html#course-overview",
    "href": "index.html#course-overview",
    "title": "Personality PsychologyLab Handbook",
    "section": "Course overview",
    "text": "Course overview\nThis lab is designed to offer experience participating in, reading, critiquing, and proposing research addressing social psychological phenomena. The lab will usually be taken concurrently with PSYC-BC2138 Social Psychology Lecture, and will expand upon the methodological and analytic issues introduced there, as well as giving you the opportunity to explore in greater depth a topic of your choosing from within (or beyond) those covered in the lectures by proposing your own original research project.\n\nResearch projects\nThe semester is broken into 3 projects. Each section will culminate in an in-class presentation and submission of a brief write up of your project.\n\n\nClass format & participation\nLabs are substantially more interactive and discussion-based than the traditional lecture format, and depend on everyone’s participation. Your active participation across the semester will therefore contribute a substantial portion of your grade.\nIf you have questions, thoughts, or ideas you want to share, feel free to do so at any time (while keeping within the bounds of polite conversation, obviously–don’t interrupt or talk over other people! But do feel free to respond to others without having to raise your hand or wait to be called on). Everyone will get the most out of this lab when the discussion can develop organically and everyone feels free to be part of the conversation if & when they have something to add.\nBeing part of the in-person discussion is one obvious way to participate, but it’s not the only way. Different people have different styles of participation, and the lab is designed to try and accommodate and encourage different approaches (as well as allowing for the greater-than-usual possibility of missing class for health reasons). Your level of engagement with your project partner(s), your TA and Prof. Brotherton as you work through your project is also an important form of participation. You can also participate by coming to office hours.\nAt a minimum, I’ll be looking for some form of participation (loosely defined) from you every week; higher participation grades will be earned through regular, enthusiastic, productive participation (note that quality is more important than quantity).\n\n\nWorkload\nAs a general rule for the amount of time students should expect to commit to classes, the college suggests three hours per week in or outside of class per credit. Since this class is worth 1.5 credits, that corresponds to 4.5 hours per week, split between time in the classroom and time spent completing the associated assignments.\n\n\nFinal Grades\nYour final letter grade for the course is a product of your scores for each assignment, weighted as indicated in the class schedule, and determined according to the following boundaries:\nLetter grade:  A+ A  A- B+ B  B- C+ C  C- D  F\nNumeric score: 97 93 90 87 83 80 77 73 70 60 <60"
  },
  {
    "objectID": "index.html#course-policies",
    "href": "index.html#course-policies",
    "title": "Personality PsychologyLab Handbook",
    "section": "Course policies",
    "text": "Course policies\n\nAttendance & timeliness\nIn-person attendance of each lab session is expected, except in emergencies. Normally it is departmental policy to remove students who miss more than two sessions from the course; however, given ongoing revisions to college-wide health-related policies, exceptions may be made. If you are feeling unwell, you should not come to class and notify me of nonattendance before class if possible. When you are attending, please arrive on time for class. Frequent lateness will impact your participation grade.\n\n\nAssignment deadlines & late policy\nAssignments are listed in the class schedule next to the class session to which they correspond. Most assignments are due at 5pm the day after class. All assignments relate to your project proposal—the idea is to build this major piece of work incrementally over the course of the semester. The 5pm next-day deadline is necessary to allow time to provide substantive feedback to everyone in advance of the next assignment.\nA grade penalty of 5 points will be applied for each day (or part thereof) that an assignment is late (up to a maximum of 6 days; work not submitted before the next lab will receive a score of zero). For example, if your work is A+ quality but is submitted a day-and-a-half late, you will only receive a B+. Due to time constraints, you may also not receive feedback on late work.\nThis policy is intended to incentivize timely submission while easing the stress of genuine emergencies. When things come up that prevent timely submission you can prioritize accordingly, knowing that a small penalty on one assignment for this lab will not tank your final grade.\n\n\nAcademic integrity\nStudents are expected to follow the Barnard Honor Code, available at https://barnard.edu/honor-code.\nNote that even though you may collaborate in lab and on the research proposal, you may not collaborate on written assignments. You must write your own reports.\n\n\nAcademic accommodations and general wellness\nIt is always important to recognize the different pressures, burdens, and stressors you may be facing, whether personal, emotional, physical, financial, mental, or academic. The faculty and administration recognize this, and are prepared to provide assistance to students in need. I encourage you to seek advice from your advisor, Dean, the Center for Accessibility Resources & Disability Services (CARDS), or Barnard Health & Wellness as needed. Please let me know of any issues you wish to share with me that you feel are impacting your ability to complete the course to the best of your ability. Though it isn’t always easy, it is better to proactively seek help rather than letting problems build up."
  },
  {
    "objectID": "lab-2.html",
    "href": "lab-2.html",
    "title": "Lab 2: Project Planning",
    "section": "",
    "text": "Project planning\nA correlation refers an association between two things. It is a statement of a statistical relationship–a general tendency, rather than a rigid law. To say that some aspect of personality is correlated with something else–for example, neuroticism is correlated with lower wellbeing or openness is correlated with greater cognitive ability–is to say that those things tend to go together. Not everyone who scores high on neuroticism will have lower wellbeing than anyone low on neuroticism, but there is some tendency for the two to go together on the whole.\nOf course, these kind of correlations aren’t just facts found lying around in nature; they are empirical findings produced by researchers. All the findings you learn about in the personality psychology lecture (and beyond) are the product of research procedures. Researchers decide what psychological constructs they want to investigate; how to operationally define those constructs; what statistical analyses are appropriate; and what conclusions may be drawn.\nWith this project, you will examine a correlation between a personality trait and some other construct of your choosing by analyzing existing data.\nAt the start of next week’s class, each project team will give a short, informal presentation of their research proposal. This should outline:"
  },
  {
    "objectID": "lab-2.html#goals",
    "href": "lab-2.html#goals",
    "title": "Lab 2: Project Planning",
    "section": "Goals",
    "text": "Goals\n\nExamine the ANES 2016 dataset\nIdentify variables for your correlation analysis\nSearch the literature to find relevant research\nFormulate a brief research proposal"
  },
  {
    "objectID": "lab-2.html#step-1.-examine-the-data",
    "href": "lab-2.html#step-1.-examine-the-data",
    "title": "Lab 2: Project Planning",
    "section": "Step 1. Examine the data",
    "text": "Step 1. Examine the data\nThe dataset we will use is from the American National Election Studies (ANES), academic surveys of voters in the United States conducted before and after every presidential election, going back to the 1940s. Specifically, for this project we will use data collected around the 2016 election. The reason for using this (instead of more recent data) is that the 2016 survey included a personality scale: the Ten-item Personality Inventory (TIPI: Gosling et al., 2003). This allow us to look at how the Big 5 personality traits of Openness, Conscientiousness, Extraversion, Agreeableness, and Neuroticism correlate with any of the other variables recorded in the survey."
  },
  {
    "objectID": "lab-2.html#step-2.-find-relevant-research",
    "href": "lab-2.html#step-2.-find-relevant-research",
    "title": "Lab 2: Project Planning",
    "section": "Step 2. Find relevant research",
    "text": "Step 2. Find relevant research\nReal research doesn’t happen in a vacuum; research plans and expectations should be informed by what has come before. Therefore once you have an idea of what variables you would like to analyze, you will search the literature to see what other researchers have found of these (or related) personality traits.\n\nWhatto look for\nA published, scholarly journal article detailing an empirical finding relevant to your variables of interest. This might be a paper reporting one or several individual studies that the researchers conducted, or it may be a review or meta-analysis1 paper.\n\n\nWhere to look\n\nGoogle Scholar\nGoogle Scholar searches the full text of scholarly articles. It casts a wide net, searching across all disciplines, and including books and other materials in addition to journal articles, so will likely find many articles not very relevant to the topic as well as those that are relevant.\n\n\nAPA PsycINFO\nThe link above should take you to PsycINFO, a database for scholarly psychology research (you can also serch for psycinfo in a CLIO quicksearch). PsycInfo gives you the ability to do much more focused searching than Google Scholar.\n\nYou can do sequential searches and then combine them with the Boolean operators AND, OR, and NOT by selecting them from the dropdown boxes.\nYou can select where your keywords should appear, i.e. in the title, abstract, or full text of articles. Selecting Word in Major Subject Heading can help narrow down your search to articles that are actually on the topic you’re interested in (rather than just containing the keyword).\nThe APA Thesaurus of Psychological Index Terms link at the top can be useful for finding technical terms used in psychology, and other related ideas."
  },
  {
    "objectID": "lab-2.html#step-3.-articulate-your-hypothesis",
    "href": "lab-2.html#step-3.-articulate-your-hypothesis",
    "title": "Lab 2: Project Planning",
    "section": "Step 3. Articulate your hypothesis",
    "text": "Step 3. Articulate your hypothesis\nHaving chosen your variables and found some relevant research to inform your theoretical perspective about how the variables are (or aren’t) associated, you should be able to articulate your hypothesis. This is a formal statement of your expectations about how the variables are associated, and it will be tested quantitatively by calculating a correlation statistic."
  },
  {
    "objectID": "lab-3.html",
    "href": "lab-3.html",
    "title": "Lab 3: Data cleaning",
    "section": "",
    "text": "Working with data in R"
  },
  {
    "objectID": "lab-3.html#goals",
    "href": "lab-3.html#goals",
    "title": "Lab 3: Data cleaning",
    "section": "Goals",
    "text": "Goals\n\nGet your R environment set up\nRead the data you need into R\nSelect required variables\nFilter the data based on completeness (and any other criteria)\nCompute any required variables (scale means, number of items missing, etc)"
  },
  {
    "objectID": "lab-3.html#getting-r-ready",
    "href": "lab-3.html#getting-r-ready",
    "title": "Lab 3: Data cleaning",
    "section": "Getting R ready",
    "text": "Getting R ready\nIn addition to containing a Big 5 personality scale, the ANES 2016 dataset is convenient for our purposes because someone went to the trouble of creating an R package which makes working with the ANES data relatively straightforward (not that you won’t still run into issues!): anesr (github.com/jamesmartherus/anesr).\nTo start exploring the data in R, you first need to set up your environment. This means installing the anesr package from github. Since the package is hosted on GitHub (as opposed to the official R repository of packages), the easiest way to install it is by first installing the devtools package, which has a function for installing other packages from GitHub.\n\ninstall.packages(\"devtools\")\n\ndevtools::install_github(\"jamesmartherus/anesr\")\n\nWe will also use some other packages for data wrangling and analysis. Developers have created a collection of packages for R called the tidyverse to make coding these common tasks easier. The tidyverse can be installed like so:\n\ninstall.packages(\"tidyverse\")\n\nIf you execute those lines of code the packages will be installed on your system. That step only needs to be done once, but you need to ‘activate’ the packages using library() to make their functions and data available each time to start a new R session.\n\nlibrary(anesr)\nlibrary(tidyverse)"
  },
  {
    "objectID": "lab-3.html#getting-data-into-r",
    "href": "lab-3.html#getting-data-into-r",
    "title": "Lab 3: Data cleaning",
    "section": "Getting data into R",
    "text": "Getting data into R\n\ndata(timeseries_2016)\n\nWhen you run that line of code you won’t see any output, but you should see the name timeseries_2016 appear in your Environment pane. That is now an object in R called a data.frame. You can think of it as a spreadsheet like you’re familiar with from Excel or Google Sheets; a set of columns, one for each variable in the dataset, and a row for each participant’s answers.\nTyping the name of the data.frame and running that line of code will show the first few columns and rows.\n\ntimeseries_2016\n\n# A tibble: 4,270 × 1,842\n   version       V160001 V160001_orig V160101 V160101f V160101w V160102 V160102f\n   <chr>           <dbl>        <dbl>   <dbl>    <dbl>    <dbl>   <dbl>    <dbl>\n 1 ANES2016Time…       1       300001   0.827    0.888        0   0.842    0.927\n 2 ANES2016Time…       2       300002   1.08     1.16         0   1.01     1.08 \n 3 ANES2016Time…       3       300003   0.388    0.416        0   0.367    0.398\n 4 ANES2016Time…       4       300004   0.360    0.385        0   0.366    0.418\n 5 ANES2016Time…       5       300006   0.647    0.693        0   0.646    0.726\n 6 ANES2016Time…       6       300007   0.706    0.759        0   0.688    0.725\n 7 ANES2016Time…       7       300008   3.96     4.25         0   4.62     4.79 \n 8 ANES2016Time…       8       300012   0.962    1.03         0   0.943    1.04 \n 9 ANES2016Time…       9       300018   0.976    1.05         0   1.01     1.07 \n10 ANES2016Time…      10       300020   0.618    0.664        0   0.600    0.638\n# ℹ 4,260 more rows\n# ℹ 1,834 more variables: V160102w <dbl>, V160201 <dbl>, V160201f <dbl>,\n#   V160201w <dbl>, V160202 <dbl>, V160202f <dbl>, V160202w <dbl>,\n#   V160501 <hvn_lbll>, V160502 <hvn_lbll>, V161001 <hvn_lbll>,\n#   V161002 <hvn_lbll>, V161003 <hvn_lbll>, V161004 <hvn_lbll>,\n#   V161005 <hvn_lbll>, V161006 <hvn_lbll>, V161007 <hvn_lbll>,\n#   V161008 <hvn_lbll>, V161009 <hvn_lbll>, V161010a <hvn_lbll>, …\n\n\nYou can also click on the name in the Environment pane to see the data like a spreadsheet in a new tab.\n\nSelect your variables\nAs you can see, the data.frame contains a lot of variables; there are 1,842 columns of data. You’ll only need a few of those. So the first step is selecting just the variables you need to work with.\nThere are a lot of ways to do this. The simplest would be to make a note of the variable IDs from the codebook and use them within dplyr’s select() function. This allows us to simply type in variable names separated by commas. You can also give the columns new names when selecting,\nFor this example I’ll look at the correlation between extraversion and the ‘feeling thermometer’ for the Democratic Party. Extraversion has two TIPI items; their IDs (from the codebook) are V162333 and V162338. The ID for the Democratic Party feeling thermometer is V161095.\n\nmy_data <- timeseries_2016 |> \n  select(extraversion1 = \"V162333\", \n         extraversion2 = \"V162338\", ,\n         feeling_thermometer = \"V161095\")\n\nLet’s see what this new data.frame looks like:\n\nmy_data\n\n# A tibble: 4,270 × 3\n   extraversion1 extraversion2 feeling_thermometer\n   <hvn_lbll>    <hvn_lbll>    <hvn_lbll>         \n 1 6             5              0                 \n 2 6             6             15                 \n 3 6             2             50                 \n 4 6             4             30                 \n 5 5             7             70                 \n 6 5             6             15                 \n 7 5             1             85                 \n 8 6             3              0                 \n 9 7             1             15                 \n10 5             5             50                 \n# ℹ 4,260 more rows\n\n\nIt all looks good so far. But if you inspect the data more extensively (click the name in your Environment and scroll down a bit) you’ll notice that there are some negative numbers in the data. That’s from survey codes which record missing data. If you try to calculate an average score with those included it’ll mess up the sums, so we need to do some data cleaning to handle things like that.\n\n\nCleaning the data\nThere are a lot of different ways we could handle this. One way is to filter() the data, retaining only rows which meet certain conditions.\n\nmy_data_complete <- my_data |>\n  filter(if_all(contains(\"extraversion\"), ~ . %in% 1:7))  |> \n  filter(feeling_thermometer >= 0)\n\nNotice how many rows have been removed:\n\nnrow(my_data)\n\n[1] 4270\n\nnrow(my_data_complete)\n\n[1] 3540\n\n\nAnother way would be to mutate() the data; that is, change certain values based on some condition.\n\n# my_data_complete <- my_data |>\n#     mutate(across(contains(\"extraversion\"), ~case_when(\n#         . < 1 ~ NA,\n#         TRUE ~ .\n#     ))) |> \n#     mutate(feeling_thermometer = case_when(feeling_thermometer < 0 ~ NA, TRUE ~ feeling_thermometer))\n\n\n\nComputing scale averages\nNow that the data is subsetted and the missing/invalid responses are taken care of, the last thing to do is compute any new values required for analysis. As an example, if you have a scale which has multiple questions asking about a particular construct, it is often necessary to compute an average score for each participant.\nThe TIPI has 10 questions in total, two for each of the Big 5 personality traits. So it may be desirable to compute a mean trait score by averaging its two respective items.\nNotice, however, that for each of the 5 traits, one question is positively worded and one is negatively worded. For extraversion, item V162333 is “extraverted, enthusiastic”, while item V162338 is “reserved, quiet”. The second one needs to be reverse-coded, so that higher scores on both items indicate greater extraversion. Since answers can range from 1 to 7, an easy way to recode the scores is to subtract the participant’s response from 8; 1 becomes 7, 2 becomes 6, etc.\n\nmy_data_complete <- my_data_complete |>\n    mutate(extraversion2 = 8 - extraversion2)\n\nNow we can go ahead and compute the average, using mutate() to create a new column containing the rowMeans() (i.e. an average for each row) for the specified columns.\n\nmy_data_complete <- my_data_complete |>\n    mutate(extraversion_mean = rowMeans(across(contains(\"extraversion\"))))"
  },
  {
    "objectID": "lab-4.html",
    "href": "lab-4.html",
    "title": "Lab 4: Analysis",
    "section": "",
    "text": "Analyzing data in R\nRunning with my example from last week, my variables were avearge extraversion scores and the Democratic Party feeling thermometer score. I made a data.frame with just those variables, filtered the data down to complete, valid responses, recoded the negatively-worded item, and computed an extraversion mean score. To refresh your memory, here’s the entire pipeline from start to finish:"
  },
  {
    "objectID": "lab-4.html#goals",
    "href": "lab-4.html#goals",
    "title": "Lab 4: Analysis",
    "section": "Goals",
    "text": "Goals\n\nDescribe and visualize your variables\nUnderstand what the correlation statistic quantifies\nPerform the appropriate correlational analysis on your data\nInterpret the results"
  },
  {
    "objectID": "lab-4.html#describing-your-data",
    "href": "lab-4.html#describing-your-data",
    "title": "Lab 4: Analysis",
    "section": "Describing your data",
    "text": "Describing your data\n\nmy_data_complete |> \n  mutate(across(everything(), as.numeric)) |> \n  pivot_longer(everything()) |> \n  summarize(n = n(),\n            mean = mean(value), \n            sd = sd(value),\n            .by = name)\n\n# A tibble: 4 × 4\n  name                    n  mean    sd\n  <chr>               <int> <dbl> <dbl>\n1 extraversion1        3540  4.79  1.58\n2 extraversion2        3540  3.65  1.76\n3 feeling_thermometer  3540 48.3  30.0 \n4 extraversion_mean    3540  4.22  1.38"
  },
  {
    "objectID": "lab-4.html#visualizing-the-data",
    "href": "lab-4.html#visualizing-the-data",
    "title": "Lab 4: Analysis",
    "section": "Visualizing the data",
    "text": "Visualizing the data\nAs with most things, there are a lot of different ways of producing graphs using R. One of the most widely used and powerful is the ggplot2 package.1 The name refers to the idea of the “grammar of graphics”, and it is built around a layering approach. You first specify your data and aesthetics (what should data will go on the x and y axes), then geometry (do you want data to be represented by points or bars or as a histogram?), any scaling (e.g. what values should be labeled on each axis), and theme elements (how do you want the plot to look generally?). There can be a lot of complexity, but building things up layer by layer, gradually adding and refining elements, is a powerful and satisfying approach.\n\nmy_data_complete |> \n  ggplot(aes(x = extraversion1)) +\n  geom_histogram(binwidth = 1)\n\nDon't know how to automatically pick scale for object of type <haven_labelled>.\nDefaulting to continuous.\n\n\n\n\n\nFigure 1.1: Histogram of responses to “extraverted, enthusiastic” TIPI item\n\n\n\n\nThe default theme is perfectly serviceable, but you can customize every element. Here I’ll specify a couple of aspects using the theme() function, and I’ll assign it to the name theme_apa. Then I can always add theme_apa as a layer to my plots going forward.\n\ntheme_apa <- theme(\n  panel.background = element_blank(),\n  axis.line = element_line()\n)\n\n\nmy_data_complete |> \n  ggplot(aes(x = extraversion1)) +\n  geom_histogram(binwidth = 1, color = \"white\") +\n  scale_x_continuous(breaks = 1:7) +\n  theme_apa\n\n\n\n\nFigure 1.2: Histogram of responses to “extraverted, enthusiastic” TIPI item\n\n\n\n\n\nmy_data_complete |> \n  ggplot(aes(x = 8 - extraversion2)) +\n  geom_histogram(binwidth = 1, color = \"white\") +\n  scale_x_continuous(breaks = 1:7) +\n  theme_apa\n\n\n\n\nFigure 1.3: Histogram of responses to “reserved, quiet” TIPI item\n\n\n\n\n\nmy_data_complete |> \n  ggplot(aes(x = extraversion_mean)) +\n  geom_histogram(binwidth = 0.5, color = \"white\") +\n  scale_x_continuous(breaks = 1:7) +\n  theme_apa\n\n\n\n\nFigure 1.4: Histogram of average scores on TIPI Extraversion subscale\n\n\n\n\n\nmy_data_complete |> \n  ggplot(aes(x = feeling_thermometer)) +\n  geom_histogram(binwidth = 1, color = \"white\") +\n  scale_x_continuous(breaks = seq(from = 0, to = 100, by = 10)) +\n  theme_apa\n\n\n\n\nFigure 1.5: Histogram of responses to Democratic Party feeling thermometer"
  },
  {
    "objectID": "lab-4.html#the-correlation-statistic",
    "href": "lab-4.html#the-correlation-statistic",
    "title": "Lab 4: Analysis",
    "section": "The correlation statistic",
    "text": "The correlation statistic\nThe correlation statistic can be computed with a single line of code, as you’ll see. But it’s important to understand the math happening behind the scenes."
  },
  {
    "objectID": "lab-4.html#correlation-in-r",
    "href": "lab-4.html#correlation-in-r",
    "title": "Lab 4: Analysis",
    "section": "Correlation in R",
    "text": "Correlation in R\nThe data is ready to be analyzed. The correlation between two variables can be found using the cor() function.\n\ncor(x = my_data_complete$extraversion_mean, \n    y = my_data_complete$feeling_thermometer)\n\n[1] -0.01012898\n\n\nIf you got an answer of NA instead of a number, it is probably because your data has some missing data. You just need to tell cor() to only use data for which both pairs of values are nonmissing:\n\ncor(x = my_data_complete$extraversion_mean, \n    y = my_data_complete$feeling_thermometer,\n    use = \"pairwise.complete.obs\")\n\n[1] -0.01012898\n\n\n\nmy_data_complete |> \n  ggplot(aes(x = extraversion_mean, y = feeling_thermometer)) +\n  geom_point(position = position_jitter(width = 0.4, height = 0), \n             alpha = 0.1) +\n  scale_x_continuous(breaks = 1:7) +\n  scale_y_continuous(breaks = seq(from = 0, to = 100, by = 10)) +\n  theme_apa\n\n\n\n\nFigure 2.1: Scatterplot (with jitter) of average extraversion scores and feeling thermometer scores"
  },
  {
    "objectID": "lab-5.html",
    "href": "lab-5.html",
    "title": "Lab 5: Presentations",
    "section": "",
    "text": "Presentation\nYou will produce a miniature research paper reporting your project. Note that each team member will produce their own individual report; even though the project has been collaborative, your write up will be your own.\nYour report should consist of the following sections:"
  },
  {
    "objectID": "lab-5.html#guide-to-presenting",
    "href": "lab-5.html#guide-to-presenting",
    "title": "Lab 5: Presentations",
    "section": "Guide to presenting",
    "text": "Guide to presenting\nEach team will give a two-minute presentation, accompanied by a single PowerPoint slide, which should encapsulate the motivation, methods, anticipated findings, and interpretation of your proposed project. Two minutes is not a lot of time. Apparently, people speak at a rate of around 125 to 150 words per minute on average. So a 2-minute presentation will be no more than around 300 words. The single-slide, not-many-words format demands clarity, conciseness, and being bold to spark the audience’s interest in your topic.\nAvoid simply reading excerpts from your paper. That would be boring, and would probably take up too many words. Make it fun and interesting. Try to grab the audience’s attention and hit them with just the most important points of your ideas.\nYou will also have a single PowerPoint slide to accompany your presentation. Make it count. You can’t just cram a load of text on there, because nobody will be able to read it. Plus, it’d distract from what you’re saying. Make it a visual aid that somehow supports or clarifies what you’re saying. It might be a visual representation of your design, a key piece of your experimental stimuli, a graph of your expected results, or just a pertinent meme which conveys the motivation for your question.\nAfter your two-minute talk you’ll take a few questions from the audience, and your responsiveness will contribute toward your grade as well as the quality of your presentation itself (remember a perfectly acceptable answer if often: “Good question; I don’t know the answer!”). It’s not usually an issue, but just in case your audience is left speechless, I suggest coming with a couple of questions or thoughts of your own that you can throw at the audience to spark more questions.\nEach pair will be allotted five minutes total for their talk and Q&A. Going over time and/or failing to leave time for questions will impact your presentation grade. It is up to each pair to decide how to divide up the two-minute talk, and to practice to make sure the presentation is to time."
  },
  {
    "objectID": "lab-5.html#guide-to-watching-presentations",
    "href": "lab-5.html#guide-to-watching-presentations",
    "title": "Lab 5: Presentations",
    "section": "Guide to watching presentations",
    "text": "Guide to watching presentations\nAs an audience member, you are still being graded for class participation this week. That means giving everyone else’s presentation the attention and enthusiasm it deserves, and rewarding their hard work with questions. (Going to the trouble of putting together a presentation only for nobody to have anything to say about it is not a good feeling.)\nGood questions to ask are things like “Could you clarify X”, “Had you considered Y”, or “How might this relate to Z.” One reason for presenting your project is to hopefully get some useful feedback from the audience with which to refine your final paper, so try to give the kind of feedback you hope to receive."
  },
  {
    "objectID": "lab-6.html#goals",
    "href": "lab-6.html#goals",
    "title": "Lab 6: Project planning",
    "section": "Goals",
    "text": "Goals\n\nUnderstand the idea of multiple regression\nIdentify variables for your analysis\nSearch the literature to find relevant research\nFormulate a brief research proposal"
  },
  {
    "objectID": "lab-7.html#goals",
    "href": "lab-7.html#goals",
    "title": "Lab 7: Data cleaning & analysis",
    "section": "Goals",
    "text": "Goals\n\nControl conditions\nFactorial designs\n\n\nlm(dv ~ iv1 * iv2)"
  },
  {
    "objectID": "lab-8.html#goals",
    "href": "lab-8.html#goals",
    "title": "Lab 8: Visualization & reporting",
    "section": "Goals",
    "text": "Goals\n\nStyle and contents of an APA Introduction section\nHow to frame previous findings to create a coherent and compelling justification\nAPA style for citations & references"
  },
  {
    "objectID": "lab-9.html",
    "href": "lab-9.html",
    "title": "Lab 9: Presentations",
    "section": "",
    "text": "Present in class.\nWrite up due by next class."
  },
  {
    "objectID": "lab-10.html#goals",
    "href": "lab-10.html#goals",
    "title": "Lab 10: Scale planning",
    "section": "Goals",
    "text": "Goals\n\nUnderstand the process of scale design and validation\nPick a personality trait to design a scale around\nWrite a brief proposal of your project and expectations"
  },
  {
    "objectID": "lab-11.html#goals",
    "href": "lab-11.html#goals",
    "title": "Lab 11: Questionnaire design",
    "section": "Goals",
    "text": "Goals\n\nGenerate items\nConsider face validity\nDecide on reponse options\nCreate your survey using Google Forms"
  },
  {
    "objectID": "lab-13.html",
    "href": "lab-13.html",
    "title": "Lab 13: Presentations",
    "section": "",
    "text": "Present in class.\nWrite up due by next class."
  },
  {
    "objectID": "appendix-r-basics.html",
    "href": "appendix-r-basics.html",
    "title": "Appendix A — Getting started with R",
    "section": "",
    "text": "Fundamentals of R for data analysis\nR is a programming language well-suited to interactive data exploration and analysis. It might seem daunting if you’ve have no experience with coding, but the basic idea is that you have some data, like you are familiar with from a regular Excel or Google Sheets spreadsheet, and you perform operations on your data using functions a lot like you would in Excel/Sheets. For example, you might compute an average in Sheets by typing =AVERAGE(A1:A10). In R you might type mean(my_data$column_a). The specifics of the function names are different, but the basic idea is the same.\nThere are two other ideas that will help you get started coding in R."
  },
  {
    "objectID": "appendix-r-basics.html#posit.cloud",
    "href": "appendix-r-basics.html#posit.cloud",
    "title": "Appendix A — Getting started with R",
    "section": "posit.cloud",
    "text": "posit.cloud\nYou will use posit.cloud to work with data in R.\n\nLet’s do something cool\n\n\nWait, what are you talking about?\nThere are a few different names involved here, so to try and clear things up:\n\nR is a coding language\nRStudio is a software interface for using R\nPosit is the name of the company that makes RStudio\nposit.cloud provides a way of using RStudio in your web browser\n\nYou can install R and RStudio on your own computer for free and do things that way, but using the cloud-based RStudio via posit.cloud simplifies things immesnely."
  },
  {
    "objectID": "a-statistics.html#analyzing-data",
    "href": "a-statistics.html#analyzing-data",
    "title": "Appendix B — Summary of Basic Statistics",
    "section": "Analyzing data",
    "text": "Analyzing data\nOnce a researcher has gathered data from an experiment, she needs to interpret the data. Of course, you could just list the individual observations and try to form an intuition about the general outcome, but there are more formal means to determine whether the experimental manipulation had an effect. A statistical description summarizes the data in a way that permits interpretation.\nNote that even though you will be proposing a piece of research and not actually collecting or analyzing data, familiarity with the following statistical concepts and procedures will be essential for you to propose an appropriate analysis for your proposed design, and for you to meaningfully interpret the potential results of such a design."
  },
  {
    "objectID": "a-statistics.html#descriptive-statistics",
    "href": "a-statistics.html#descriptive-statistics",
    "title": "Appendix B — Summary of Basic Statistics",
    "section": "Descriptive statistics",
    "text": "Descriptive statistics\nThe first step is to describe your data. These kinds of statistics are called descriptive statistics or summary statistics. With an experimental design where you want to compare groups, the most obvious place to start is to find an average value for the observations in a group. The average, or mean, is a measure of typical performance; it summarizes all the scores and produces a single number which represents the most typical value. The basic formula for the mean of a set of scores is:\n\\[\nM = \\dfrac{\\Sigma X}{n}\n\\]\nIn this equation, \\(X\\) refers to all the scores in the group, and n is the number of scores in the group. The symbol \\(\\Sigma\\) instructs you to sum all the scores. A simple way of saying the formula in words is: Add up all the scores in the group and divide by the number of scores in that group. If you experiment involves comparing two or more groups, you can obviously calculate the mean of each group of scores separately. If the means are different, maybe your experimental manipulation had an effect.\nHowever, there is always variability in the scores in a group. The mean is a central value, but some scores fall below it and others above it. Therefore, researchers also need to describe the amount of variability in scores. This puts the mean in context, describing just how representative of all the scores it is. If there is high variability, scores are spread widely and the mean is relatively unrepresentative; if there is low variability, scores are clustered tightly and the mean is relatively representative. When variability is high, the group means might be different just due to chance, not because of your experimental manipulation.\nA mathematical way of describing the amount of variability in a group of scores is to calculate the deviation of each score from the mean, square the deviations, and then sum the squared deviations. This quantity is called Sum of Squares (SS). One mathematical formula is:\n\\[\nSS = \\Sigma(X - M)^2\n\\]\nDividing SS by the number of scores in the group minus 1 produces a quantity called variance, which is represented by the symbol s2. Variance is the average squared deviation. (Remember that to calculate an average, you add a set of scores and divide by n. Here we add a set of deviations and divide by n – 1. We use n – 1, rather than just n, because it is a necessary statistical adjustment to account for the fact that samples tend to underestimate variability.)\n\\[\ns^2 = \\dfrac{\\Sigma(X-M)^2}{n-1}\n\\]\nTaking the square root of the variance produces another quantity, called standard deviation. It is represented mathematically by the symbol s, but in psychology papers you will most often see it represented by the letters SD.\n\\[\nSD = \\sqrt{\\dfrac{\\Sigma(X-M)^2}{n-1}}\n\\]\nWhile variance is the average squared deviation, SD is the average deviation in the original units (i.e. not squared). This is the most intuitive way to convey how much scores typically varied about the mean."
  },
  {
    "objectID": "a-statistics.html#inferential-statistics",
    "href": "a-statistics.html#inferential-statistics",
    "title": "Appendix B — Summary of Basic Statistics",
    "section": "Inferential statistics",
    "text": "Inferential statistics\nKnowing the standard deviation and mean for each experimental group gives you a good idea of how much scores differed within each group, and how much the groups differed on average. But researchers still need to perform a statistical test to determine whether the groups differed more than would be expected by chance alone. These kinds of statistical tests are called inferential statistics, because we are using our sample data to make an inference about what would happen if everyone in the population had taken part in our experiment, rather than just the small number of people who happened to be in our samples.\n\nCorrelation\nWhen you measure two variables and wish to know if scores on one measure are related to scores on the other, you calculate the correlation coefficient. This quantifies the extent to which changes on one measure are related to changes on the other. For example, if higher scores on measure X are associated with higher scores on measure Y, there is a positive correlation. If higher scores on measure X are associated with lower scores on measure Y, there is a negative correlation. No correlation means that scores on X are unrelated to scores on Y.\nTo calculate the correlation between two variables, you must first calculate the Sum Product, SP. The mathematical formula is:\n\\[\nSP = (X-M_X)(Y-M_Y)\n\\]\nNotice that \\(X - M_X\\) and \\(Y - M_Y\\) are deviation scores, just like we calculated for the standard deviation. Here we have two variables, \\(X\\) and \\(Y\\), so the equation is telling us to calculate the deviation of each score from its respective mean. We then multiply each deviation for variable \\(X\\) by its counterpart deviation from variable \\(Y\\). These are the “products,” meaning multiplied deviation scores. Finally, the tells us to add up all those products, giving the “sum of products,” \\(SP\\).\nOnce we have calculated \\(SP\\), the correlation coefficient, symbolized by \\(r\\) is calculated using the following equation:\n\\[\nr = \\dfrac{SP}{\\sqrt{SS_X SS_Y}}\n\\]\nHere, \\(SS_X\\) and \\(SS_Y\\) are the Sums of Squares for each variable. Multiplying them and taking the square root gets us a measure of the variability in \\(X\\) and \\(Y\\) separately. The numerator, \\(SP\\), represents the covariability of \\(X\\) and \\(Y\\). So the equation results in covariability as a proportion of all variability. It can range from \\(-1\\), meaning a perfect negative correlation, to \\(0\\), meaning no correlation at all, to \\(+1\\), meaning a perfect positive correlation. As a rule of thumb, in psychology, correlations of less than around \\(\\pm 0.30\\) are considered weak, around \\(\\pm 0.30\\) to \\(\\pm 0.70\\) are considered moderate, and greater than around \\(\\pm 0.70\\) are considered large.\n\n\n\nThe \\(t\\)-test\n\n\n\n\n \n  \n    df \n    t \n  \n \n\n  \n    1 \n    12.706 \n  \n  \n    2 \n    4.303 \n  \n  \n    3 \n    3.182 \n  \n  \n    4 \n    2.776 \n  \n  \n    5 \n    2.571 \n  \n  \n    6 \n    2.447 \n  \n  \n    7 \n    2.365 \n  \n  \n    8 \n    2.306 \n  \n  \n    9 \n    2.262 \n  \n  \n    10 \n    2.228 \n  \n  \n    11 \n    2.201 \n  \n  \n    12 \n    2.179 \n  \n  \n    13 \n    2.160 \n  \n  \n    14 \n    2.145 \n  \n  \n    15 \n    2.131 \n  \n  \n    16 \n    2.120 \n  \n  \n    17 \n    2.110 \n  \n  \n    18 \n    2.101 \n  \n  \n    19 \n    2.093 \n  \n  \n    20 \n    2.086 \n  \n  \n    21 \n    2.080 \n  \n  \n    22 \n    2.074 \n  \n  \n    23 \n    2.069 \n  \n  \n    24 \n    2.064 \n  \n  \n    25 \n    2.060 \n  \n  \n    26 \n    2.056 \n  \n  \n    27 \n    2.052 \n  \n  \n    28 \n    2.048 \n  \n  \n    29 \n    2.045 \n  \n  \n    30 \n    2.042 \n  \n  \n    31 \n    2.040 \n  \n  \n    32 \n    2.037 \n  \n  \n    33 \n    2.035 \n  \n  \n    34 \n    2.032 \n  \n  \n    35 \n    2.030 \n  \n  \n    36 \n    2.028 \n  \n  \n    37 \n    2.026 \n  \n  \n    38 \n    2.024 \n  \n  \n    39 \n    2.023 \n  \n  \n    40 \n    2.021 \n  \n\n\n\n\n\nOne test to compare two groups of scores is the \\(t\\)-test. One form of the \\(t\\)-test formula, assuming that the two groups have equal sample sizes, is as follows:\n\\[t = \\dfrac{M_1-M_2}{\\dfrac{s_1^2}{n_1}+\\dfrac{s_2^2}{n_2}}\\]\nThe numerator is simply the difference between the group means (the different group means are represented by the subscripts \\(1\\) and \\(2\\)). The denominator quantifies how much of a difference is to be expected due to chance alone. It divides each group variance (\\(s^2\\)) by the number of scores in that group, adds the answers, and then takes the square root.\nThe size of the \\(t\\) statistic required to conclude that a difference between groups is real depends on the size of the samples (how many observations you took). The greater the number of observations, the smaller the \\(t\\) required to identify a real difference. In order to determine the exact value of \\(t\\) required to declare the difference in groups to be reliable, several values must be determined.\nOne of these is the degrees of freedom for the test (\\(df\\)). The degrees of freedom, \\(df\\), is another statistical correction that weights the number of observations in each experimental group. Basically, we lose one degree of freedom for each group, so with two groups, \\(df = N – 2\\) (\\(N\\) being the total number of scores), or:\n\\[df=(n_1-1)+(n_2-1)\\]\nThe other quantity to determine is alpha (\\(\\alpha\\)), or the significance level. By convention, this is usually set at \\(\\alpha = .05\\). This means that you are willing to chance being incorrect in your conclusion \\(.05\\) (or 5%) of the time. More specifically, if you were able to repeat your experiment a hundred times, even if your experimental manipulation does nothing at all sometimes you would observe group means that are quite far apart just by chance alone. Specifying \\(\\alpha = .05\\) means that you will only regard a difference between means as statistically significant if it is one so large that it would occur just 5% of the time if your manipulation didn’t actually work.\nOnce you know \\(df\\) and \\(\\alpha\\), you can proceed. Associated with each \\(df\\) value is a critical \\(t\\) value (see table to the right). This is a cutoff value; if the \\(t\\) statistic you calculate for your data exceeds this critical cutoff, you conclude that there is a statically significant difference between the groups, i.e. the groups differ more than would be expected by chance alone 95% of the time (with \\(\\alpha = .05\\), there is always a 5% chance of seeing such a difference by chance).\nMany tables of these cutoff values of \\(t\\) are available, for the many possible values of \\(df\\) and \\(\\alpha\\). Here, we provide a table that provides a table that assumes \\(\\alpha = .05\\). Look at the table and run down the \\(df\\) column until you find the value of \\(df\\) that matches the value for your data. The number to the right of that value is the critical value for \\(t\\) at the \\(\\alpha = .05\\) significance level.\n\nEffect size for two-group designs\nIn addition to knowing whether a difference between two groups is statistically significant, it is necessary to quantify the effect size. The most common measure of effect size for two-group designs is Cohen’s \\(d\\). This is standardized way of quantifying the magnitude of difference between groups caused by the experimental manipulation, in relation to the random variability in the data. Again assuming that the two groups have the same sample size, the formula for Cohen’s \\(d\\) is:\n\\[d = \\dfrac{M_1 - M_2}{(SD_1+ SD_2) / 2}\\]\nThe numerator gives the difference between group means. The denominator adds each group’s standard deviation and divides by two to give the average standard deviation of the two groups (also called pooled standard deviation). Therefore, if Cohen’s \\(d = 1.00\\), there was a difference between the groups of one standard deviation.\nCohen suggested the following rule of thumb for interpreting effect sizes in psychological research: \\(d = 0.2\\) indicates a small effect; \\(d = 0.5\\) indicates a moderate effect; \\(d = 0.8\\) indicates a large effect.\n\n\nStatistical power and sample size for two-group designs\nAn important aspect to consider when planning research is what sample size will be required—i.e, how many participants you should aim to recruit. This can be calculated in advance by using statistical principles and some assumptions about the quantities previously mentioned.\nFirst, consider alpha. As previously mentioned, for psychological research this is usually set as \\(\\alpha = .05\\). This is also known as the Type 1 error rate, or false positive rate—the frequency at which you would mistakenly think that your experimental manipulation had an effect when really it didn’t.\nSecond, the Type 2 error rate, or false negative rate, is how often you might fail to detect a real effect of your manipulation. This quantity is called beta (\\(\\beta\\)). It is related to alpha; a smaller alpha means a more stringent test, which means we are deliberately reducing our chances of detecting a real effect. But beta is also affected by sample size. The more participants in a study, the greater statistical power it will have, because increasing sample size makes it easier to detect real differences. For psychological research, it is common to specify a desired Type 2 error rate of 20%. The corresponding 80% is called the statistical power of the study: the chances that it will successfully detect the treatment effect it is designed to detect.\nThird, as previously explained, Cohen’s \\(d\\) measures effect size by dividing the size of difference between group means by the pooled standard deviation. You should be able to estimate the effect size you expect your manipulation to have based on previous research which has studied similar constructs. Failing that, you should specify the minimum effect size you would be willing to accept as meaningful.\nKnowing the values for alpha, power, and effect size allows you to calculate the required sample size. The following is an approximate equation for calculating the required sample size:\n\\(n = \\dfrac{2(Z_a + Z_B)^2}{d^2}\\)\nHere \\(d\\) is Cohen’s effect size. \\(Z_a\\) and \\(Z_B\\) are constants based on the mathematical properties of the normal distribution and our specified values for alpha (\\(.05\\)) and desired power (\\(.80\\)). For these values, \\(Z_a = 1.96\\); \\(Z_B = .8416\\). So if you expected your manipulation to cause a small effect (\\(d = 0.2\\)), you would require \\(2 * (1.96+0.8416)^2 / 0.22 \\approx 393\\) participants in each condition. For a large effect size like \\(0.8\\), you would require \\(2 * (1.96+0.8416)^2 / 0.80 \\approx 25\\) participants per condition.\n\n\n\nANOVA\nThe Analysis of Variance (ANOVA) test is an extension of the \\(t\\) test. It is used where there are more than two groups to be compared. ANOVAs look at the ratio of variance between groups (deviations of group means from a grand mean) to error variance (deviation of individual scores). The larger the ratio, the more likely it is that the differences among groups are due to the experimental manipulation and not just due to chance.\nANOVA can even be used with more than one independent variable. Experiments often manipulate more than one independent variable, and examine the effects of those variables using ANOVA. This kind of analysis is called a “factorial” ANOVA, because there is more than one “factor”, meaning independent variable. The experimental design is referred to by the number of “levels” (meaning conditions) of each factor. For example, if a design has two independent variables, each with two different conditions, it would be referred to as a 2x2 ANOVA design. A 4x3x2 design has one factor with four levels, another factor with three levels, and a third factor with two levels.\nThese experiments can potentially describe the real world more completely and realistically. Consider the following example.\nSome research on people’s perceptions of procedural justice and fairness suggests that people feel they’ve been treated fairly when they get what they want. Some other research, however, suggests that people feel they’ve been treated fairly when they get what they deserve. So if you have behaved badly and you are then treated badly, you might be satisfied and say it was fair. A study to examine this hypothesis might manipulate people’s behavior as one independent variable; participants could put in a situation where they are led to behave either positively (not cheating on a test) or negatively (cheating on a test). The second independent variable might be how a research assistant then treats the participant, either respectfully or disrespectfully. This would be a 2x2 design—two IVs, each with two levels. The dependent variable—the thing that the researcher measures—might be participants’ feeling of how fairly they were treated.\nFactorial designs are more complicated to interpret, because of the more complicated design. One type of information we get is about the effect of each variable by itself. This is called the main effect. With two independent variables, there are two main effects. In the example above, either behavior or treatment could have had a significant effect on perceived fairness.\nThe second type of information we get from factorial designs is called an interaction. If there is an interaction, the effect of one independent variable depends on the level of the other independent variable. So in the above example, one outcome may be to find a main effect of treatment but no interaction; people might simply think they have been treated fairly when they were treated with respect, regardless of their actual behavior. However, another possible outcome would be to find an interaction between treatment and behavior; maybe your perception of the fairness of your treatment depends on how you behaved. If you are treated poorly but you did something to deserve it, you might perceive it as fair. One the other hand, being treated respectfully for bad behavior might be perceived as unfair. This would indicate an interaction.\n\nEffect size & power for ANOVA\nThe small, free application G*Power can help you determine required sample sizes for ANOVA designs. http://www.gpower.hhu.de/"
  },
  {
    "objectID": "a-statistics.html#sec-viz",
    "href": "a-statistics.html#sec-viz",
    "title": "Appendix B — Summary of Basic Statistics",
    "section": "Visualizing data",
    "text": "Visualizing data\nEven though you won’t be collecting data, you will be forecasting plausible-seeming results. Doing so requires understanding at least the gist of the relevant statistics as described above. One other piece of the puzzle is thinking about your hypothetical data and results visually: how would it look as a graph? In fact, if you’re unsure about what results to expect, or you’re unsure whether your expected results are really plausible, thinking about a corresponding graph can help clarify your thinking.\nThere are a few standard ways of visualizing data, depending on the nature of the data and the design of the study. (Note that my examples here are deliberately rough; a pencil sketch is perfectly fine as long as it is clear.)\nFor bivariate correlational data, a scatterplot is usually appropriate. This will have a labelled x-axis and y-axis, one for each of your two variables. Which variable goes on which axis is somewhat arbitrary, though if you can think of your variables as a “predictor” (something you would know about a person) and “predicted” (the variable you want to predict based on the predictor), you can put the predictor on the x-axis and predicted on the y-axis (see Figure 1).\n\n\n\nFigure B.1: Example of a scatterplot showing a dot for each hypothetical data point. Note that axes should have meaningful labels.\n\n\nFor comparing groups—either two groups in a t-test design or three (or more) groups in a single-factor ANOVA design—a bar graph is often the best choice. Here the categorical grouping variable will be on the x-axis and scores on the dependent variables will be on the y-axis. Each bar represents a different group, and the height of the bar represents the average score on the DV of all participants within that group.\n\n\n\nFigure B.2: Example of a bar graph showing average scores on the dependent variable for three conditions of the independent variable. Errorbars represent the 95% Confidence Interval for each mean. Note that, again, your graph would have more meaningful labels.\n\n\nFor a 2x2 ANOVA design, a line graph can be clearest. In this case, one IV is represented as two marks on the x-axis, and the second IV is represented by separate lines (different colors, or solid and dashed, say). The y-axis represents scores on the DV.\n\n\n\nFigure B.3: Example of a 2x2 line graph. The two conditions of IV1 are represented on the x-axis, and the two conditions of IV2 are represented by the solid and dashed lines."
  }
]