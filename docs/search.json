[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Personality Psychology Lab Handbook",
    "section": "",
    "text": "Course details\nPre-requisites: PSYC BC1001 Introduction to Psychology; PSYC BC1101 Statistics; PSYC BC1020 Research Methods\nCo-requisite: PSYC BC2125 Personality Psychology",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Syllabus</span>"
    ]
  },
  {
    "objectID": "index.html#course-details",
    "href": "index.html#course-details",
    "title": "Personality Psychology Lab Handbook",
    "section": "",
    "text": "Time, venue & instructor\nMonday 10:10-1PM, Milbank 410\nInstructor: Dr. Rob Brotherton (rbrother@barnard.edu)\nOffice hour: Wednesday 10-11AM, Milbank 415M\n\n\nOverview\nThis lab will usually be taken concurrently with BC2125 Personality lecture. It will expand upon some of the theoretical, methodological and analytic issues introduced there, as well as giving you the opportunity to explore topics from within and beyond those covered in the lectures in greater depth through hands-on experience with research design and data analysis.\nThe semester is broken into 3 projects, each illustrating a common methodological and analytic approach in personality psychology. Through these projects you will gain experience in formulating psychological research questions relating to personality; analyzing and visualizing data; and interpreting and communicating your findings. Projects will be undertaken in small groups; group members will collaborate on design and analysis. Each project will culminate in an in-class group presentation and submission of a brief individual write up of your project.\n\n\nSchedule and deadlines\n\n\n\n\n\n\nDate\nTopic\n\n\n\n\n9/9\nCourse overview\n\n\nProject 1: t-test\n\n\n9/16\nProject planning\n\n\n9/23\nData cleaning\n\n\n9/30\nAnalysis\n\n\n10/7\nPresentations\n\n\nProject 2: Correlation\n\n\n10/14\nProject planning\n\n\n10/21\nData cleaning & analysis\n\n\n10/28\nVisualization & reporting\n\n\n11/4\nNo class (academic holiday)\n\n\n11/11\nPresentations\n\n\nProject 3: Regression\n\n\n11/18\nProject planning\n\n\n11/25\nData cleaning & analysis\n\n\n12/2\nVisualization & reporting\n\n\n12/9\nPresentations\n\n\n\n\n\n\n\n\nWritten project reports are due one week following the in-class presentation (before the next week’s lab session) on the following dates.\n\n\n\n\n\n\nDue Date\n\n\n\n\nProject 1 report\n10/14\n\n\nProject 2 report\n11/18\n\n\nProject 3 report\n12/16\n\n\n\n\n\n\n\nClass format & participation\nLabs are substantially more interactive and discussion-based than the traditional lecture format, and depend on everyone’s active participation in class discussions and activity as well as group work focused around the projects. Your active participation across the semester will therefore contribute a substantial portion of your grade.\nIf you have questions, thoughts, or ideas you want to share, feel free to do so at any time (while keeping within the bounds of polite conversation, obviously–don’t interrupt or talk over other people! But do feel free to respond to others without having to raise your hand or wait to be called on). Everyone will get the most out of this lab when the discussion can develop organically and everyone feels free to be part of the conversation if & when they have something to add.\nBeing part of the in-person discussion is one obvious way to participate, but it’s not the only way. Different people have different styles of participation, and the lab is designed to try and accommodate and encourage different approaches. Your level of engagement with your project partner(s), your TA and Prof. Brotherton as you work through your projects is also an important form of participation. You can also participate by coming to office hours.\nAt a minimum (i.e. for a passing grade), I’ll be looking for some form of participation (loosely defined) from you every week. Higher participation grades will be earned through regular, enthusiastic, productive participation (note that quality is more important than quantity).\n\n\nWorkload\nAs a general rule for the amount of time students should expect to commit to classes, the college suggests three hours per week in or outside of class per credit. Since this class is worth 2.5 credits, that corresponds to 7.5 hours per week, split between time in the classroom and time spent completing the associated assignments.\n\n\nFinal Grades\nYour numeric score for the course is a product of your scores for each assignment, weighted as follows:\n\n\n\n\n\n\n\nWeight (%)\n\n\n\n\nParticipation (over the course of the semester)\n10\n\n\nPresentations\n30\n\n\nReports\n60\n\n\n\n\n\n\n\n\nFinal grades are determined according to the following boundaries:\nLetter grade:  A+ A  A- B+ B  B- C+ C  C- D  F\nNumeric score: 97 93 90 87 83 80 77 73 70 60 &lt;60",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Syllabus</span>"
    ]
  },
  {
    "objectID": "index.html#course-policies",
    "href": "index.html#course-policies",
    "title": "Personality Psychology Lab Handbook",
    "section": "Course policies",
    "text": "Course policies\n\nAttendance & timeliness\nIn-person attendance of every lab session is expected, and you should expect to stay for the full duration of the lab. Normally it is departmental policy to remove students who miss more than two lab sessions from the course; however, given ongoing revisions to college-wide health-related policies, exceptions may be made. If you are feeling unwell, you should not come to class and notify me of nonattendance before class if possible.\nWhen you are attending, please arrive on time for class. Frequent lateness will impact your participation grade.\n\n\nAssignment late policy\nPresentations will be given in-class on the dates listed in the class schedule. It is expected that all group members contribute equally to the presentation preparation and delivery. Therefore, all group members will receive the same group score, except in exceptional circumstances when it is clear that contributions were not equal. If a group member is unable to present in-person on the day of the presentation due to unforeseen circumstances, please notify Prof. Brotherton. The presentation will be given by the remaining group members, and the absent member may be assigned the group score, assuming equal contributions to the preparation of the presentation.\nWritten project reports are due one week following the in-class presentation, i.e. before the next week’s lab session–see dates below. A grade penalty of 5 points will be applied for each day (or part thereof) that an assignment is late (up to a maximum of 6 days; work not submitted before the next lab will receive a score of zero). For example, if your work is A+ quality but is submitted a day-and-a-half late, you will only receive a B+. This policy is intended to incentivize timely submission while easing the stress of genuine emergencies. When things come up that prevent timely submission you can prioritize accordingly, knowing that a small penalty on one assignment for this lab will not tank your final grade.\n\n\nAcademic integrity\nStudents are expected to follow the Barnard Honor Code, available at https://barnard.edu/honor-code.\nNote that while you will collaborate with group members on the design, analysis, and presentation of research projects, you may not collaborate on the written report: each group member must write their own individual reports.\n\n\nUse of generative AI (e.g. ChatGPT)\nGenerative AI is an extremely useful tool for many purposes; real researchers are of course using it to help with their research. For this class, you are welcome to use AI tools to help with idea generation, help you understand readings, help formulate your ideas for written reports, etc. However, note the emphasis on helping rather than doing things for you. Passing someone else’s work off as your own is plagiarism and a violation of the honor code, and that includes the work of AI assistants. AI tools can enhance, but should not substitute for, your own efforts. Please be aware that it is generally obvious when someone has put little thought of their own into their work. Relying on ChatGPT (or similar) to do most of the work for you will result in bad work (and will accordingly earn you a bad grade).\n\n\nAcademic accommodations and general wellness\nIt is always important to recognize the different pressures, burdens, and stressors you may be facing, whether personal, emotional, physical, financial, mental, or academic. The faculty and administration recognize this, and are prepared to provide assistance to students in need. I encourage you to seek advice from your advisor, Dean, the Center for Accessibility Resources & Disability Services (CARDS), or Barnard Health & Wellness as needed. Please let me know of any issues you wish to share with me that you feel are impacting your ability to complete the course to the best of your ability. Though it isn’t always easy, it is better to proactively seek help rather than letting problems build up.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Syllabus</span>"
    ]
  },
  {
    "objectID": "t-test_1_zodiac.html",
    "href": "t-test_1_zodiac.html",
    "title": "2  Project Planning",
    "section": "",
    "text": "Goals",
    "crumbs": [
      "Project 1: $t$-test",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Project Planning</span>"
    ]
  },
  {
    "objectID": "t-test_1_zodiac.html#project-overview",
    "href": "t-test_1_zodiac.html#project-overview",
    "title": "2  Project Planning",
    "section": "Project overview",
    "text": "Project overview\nOne way we can investigate personality is to look for differences between groups of people: does one group of people tend to score higher or lower on some particular trait than another group? With this project, you will look at whether a personality trait seems to differ (on average) between two different groups of people by analyzing an existing data set.\nSpecifically, for this project you will be comparing scores on one of the Big 5 personality traits: openness, conscientiousness, extraversion, agreeableness, or neuroticism.\n\n\n\nThe Big 5 theory of personality\n\n\nWhat groups will you compare? We’re going to look for differences between people with different astrological starsigns (Pisces, Aries, Leo, Virgo, etc…). Why starsigns? Because it’s something a little bit fun that I expect you will be at least somewhat familiar with, and you’ll be able to come up with some idea about how people with one sign might differ from people with another sign (Leos will surely be more extraverted than Pisces, right?!). To be clear: astrology is not something that contemporary academic psychologists generally take very seriously. However, it makes for a fine introduction to ways of thinking about the reliability and validity of approaches to categorizing and describing personality, as well as constructing hypotheses and analyzing data.\n\n\n\nThe twelve astrological starsigns\n\n\n\nComparing groups: the \\(t\\)-test\nThe way we compare groups like this is to statistically test the “null hypothesis” (\\(H_0\\)) using a \\(t\\)-test. \\(H_0\\) states that there is no difference between the group averages at all. Because of the inherent randomness in sample data, however, we wouldn’t expect to find precisely no difference between two groups even if that null hypothesis is correct in reality. The \\(t\\)-test quantifies exactly how much our sample averages differ in the context of the general variability in the data. This gives a measure of how much of a difference we have observed over and above what we would expect by chance alone, assuming that there really isn’t a difference. If the difference between our samples is sufficiently big, we can say that it is sufficiently unlikely under the \\(H_0\\) model of reality; we reject \\(H_0\\) and tentatively accept the “alternative hypothesis”, (\\(H_1\\)) which states that there is a difference between the groups.\nNote that this is a statistical statement about a general tendency, not a rigid law. If we reject the null hypothesis, we’re saying that there seems to be a difference in the groups averages, not that everyone in one group scores higher than everyone in the other group.\nNote also that this kind of analysis, and all the empirical findings you learn about in the personality psychology lecture (and beyond) are the product of research and statistical procedures. Researchers decide what psychological constructs they want to investigate; how to measure those constructs; what statistical analyses are appropriate; and what conclusions may be drawn. There are strengths, limitations, and trade offs involved in every decision along the way.",
    "crumbs": [
      "Project 1: $t$-test",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Project Planning</span>"
    ]
  },
  {
    "objectID": "t-test_1_zodiac.html#step-1.-examine-the-data",
    "href": "t-test_1_zodiac.html#step-1.-examine-the-data",
    "title": "2  Project Planning",
    "section": "Step 1. Examine the data",
    "text": "Step 1. Examine the data\nThe dataset we will use is from the General Social Survey (GSS). Here’s a description from the GSS website:\n\n\n\n\n\n\nGSS description\n\n\n\nThe General Social Survey (GSS) is a nationally representative survey of adults in the United States conducted since 1972. The GSS collects data on contemporary American society in order to monitor and explain trends in opinions, attitudes and behaviors. The GSS has adapted questions from earlier surveys, thereby allowing researchers to conduct comparisons for up to 80 years.\nThe GSS contains a standard core of demographic, behavioral, and attitudinal questions, plus topics of special interest. Among the topics covered are civil liberties, crime and violence, intergroup tolerance, morality, national spending priorities, psychological well-being, social mobility, and stress and traumatic events.\nAltogether, the GSS is the single best source for sociological and attitudinal trend data covering the United States. It allows researchers to examine the structure and functioning of society in general, as well as the role played by relevant subgroups and to compare the United States to other nations.\nThe GSS aims to make high-quality data easily accessible to scholars, students, policy-makers, and others, with minimal cost and waiting.\nFrom https://gss.norc.org/About-The-GSS\n\n\nSpecifically, for this project we will use data collected in 2006. The reason for using this (rather than more recent data) is that the 2006 survey included a personality scale: the Ten-Item Personality Inventory (TIPI: Gosling et al., 2003). This scale is a short measure of the “Big Five” personality traits of Openness, Conscientiousness, Extraversion, Agreeableness, and Neuroticism.\nFor this project, you will pick one of these traits and see whether it differs between people of different star signs. For this kind of analysis you will have two variables.\nYour dependent variable will be one of the Big Five traits:\n\nExtraversion (big5a1 & big5a2)\nAgreeableness (big5b1 & big5b2)\nConscientiousness (big5c1 & big5c2)\nNeuroticism (big5d1 & big5d2)\nOpenness (big5e1 & big5e2)\n\nYour quasi-independent variable will be Zodiac star sign (zodiac). Specifically, you will select two groups to compare (e.g. Leo versus Virgo).\nTo see exactly how these constructs were measured and how the data is coded you will look up the variable IDs (the big5xx and zodiac codes in parentheses above) in the GSS Codebook.",
    "crumbs": [
      "Project 1: $t$-test",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Project Planning</span>"
    ]
  },
  {
    "objectID": "t-test_1_zodiac.html#step-2.-read-relevant-research",
    "href": "t-test_1_zodiac.html#step-2.-read-relevant-research",
    "title": "2  Project Planning",
    "section": "Step 2. Read relevant research",
    "text": "Step 2. Read relevant research\nReal research doesn’t happen in a vacuum; research plans and expectations should be informed by what has come before. Therefore once you have a general idea for your study, you will see what other researchers have found and refine your plans and expectations based on what you learn.\nA real research project would involve an exhaustive literature review, in which you attempt to find and understand all the research relevant to your question. Since this project of ours is just for practice and our time is limited, you don’t need to read everything. For now, pick one of these papers to skim to give you an idea of what has been found.\n\nClarke, D., Gabriels, T., & Barnes, J. (1996). Astrological signs as determinants of extroversion and emotionality: An empirical study. The Journal of Psychology, 130(2), 131–140. https://doi.org/10.1080/00223980.1996.9914995\nMayo, J., White, O., & Eyesenck, H. J. (1978). An empirical study of the relation between astrological factors and personality. Journal of Social Psychology, 105(2), 229.\nMcGrew, J. H., & McFall, R. M. (1990). A scientific inquiry into the validity of astrology. Journal of Scientific Exploration, 4(1), 75-83.\nSaklofske, D. H., Kelly, I. W., & McKerracher, D. W. (1982). An empirical study of personality and astrological factors. Journal of Psychology, 110(2), 275. https://doi.org/10.1080/00223980.1982.9915349\nSmithers, A. G., & Cooper, H. J. (1978). Personality and season of birth. The Journal of Social Psychology, 105(2), 237-241. https://doi.org/10.1080/00224545.1978.9924120",
    "crumbs": [
      "Project 1: $t$-test",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Project Planning</span>"
    ]
  },
  {
    "objectID": "t-test_1_zodiac.html#step-3.-articulate-your-hypothesis",
    "href": "t-test_1_zodiac.html#step-3.-articulate-your-hypothesis",
    "title": "2  Project Planning",
    "section": "Step 3. Articulate your hypothesis",
    "text": "Step 3. Articulate your hypothesis\nBy this point you should be able to state your:\n\nOperational definitions (that is, the specific questions that participants were asked and how they could answer, per the codebook)\nThe constructs that those operational definitions measure (i.e. what exactly is extraversion, as a broad psychological concept that the relevant questions participants were asked somehow tap into)\nYour hypothesis\n\nYour hypothesis is a formal statement of your expectation about the outcome of your statistical test. For this project the main question that your hypothesis addresses is: do you think there will be a difference between the two groups you are comparing? That is, will you find a difference between group averages big enough that it doesn’t just seem to be attributable to chance variation in the data?\nIf you do expect a difference, you should also specify which group you expect to score higher/lower, and how substantial you expect it to be (i.e. a weak, moderate, or strong effect size; see Appendix B).",
    "crumbs": [
      "Project 1: $t$-test",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Project Planning</span>"
    ]
  },
  {
    "objectID": "t-test_2_zodiac.html",
    "href": "t-test_2_zodiac.html",
    "title": "3  Data preparation",
    "section": "",
    "text": "Goals",
    "crumbs": [
      "Project 1: $t$-test",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data preparation</span>"
    ]
  },
  {
    "objectID": "t-test_2_zodiac.html#working-with-data-in-r",
    "href": "t-test_2_zodiac.html#working-with-data-in-r",
    "title": "3  Data preparation",
    "section": "Working with data in R",
    "text": "Working with data in R\n\nGetting R ready\nTo start exploring the data in R, you first need to set up your environment. While “base” R (meaning all the functions built in to the R language) can do everything we need, a feature of R that makes it well-suited for data analysis is that you can easily install additional “packages” that make common tasks, like data cleaning and visualization, even easier. In particular, we will use a family of related packages called the “tidyverse”. Usually this would need to be installed like so:\n\ninstall.packages(\"tidyverse\")\n\nHowever the Projects template I set up for you in posit.cloud already has the package installed. Packages only need to be installed once, so there’s no need for you to do so again. You will, however, need to ‘activate’ the packages using the library() function to make their functions available.\n\nlibrary(tidyverse)\n\n\n\nGetting data into R\nGetting data into R often involves reading in a .csv (comma-separated values) spreadsheet file that you downloaded to your computer. Indeed, you can go to the GSS website and download the data in a variety of forms. For our convenience, I have already done that. Your posit.cloud project has a folder called data and inside that folder there is a file named gss_2006.csv. That’s the complete GSS data for the year 2006. To start working with that data, we first need to ‘read’ it into R.\n\ndata &lt;- read_csv(\"data/gss_2006.csv\")\n\nWarning: One or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\n\n\nRows: 4510 Columns: 1316\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (1298): year, id, wrkstat, hrs1, hrs2, evwork, wrkslf, wrkgovt, occ80, p...\nlgl   (18): away7, where7, mar8, relate9, gender9, old9, relate10, gender10,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nWhen you execute the code you won’t see any output, but you should see the name data (or whatever name you assigned the result of read_csv() to) appear in your Environment pane. That is now an object in R called a data.frame. You can think of it as a spreadsheet like you’re familiar with from Excel or Google Sheets; a set of columns, one for each variable in the dataset, and a row for each participant’s answers. In fact, you can also click on the name in the Environment pane to view the data in a new tab, just like looking at a spreadsheet. Or you can see a preview of the full spreadsheet using code:\n\nhead(data)\n\n# A tibble: 6 × 1,316\n   year    id wrkstat  hrs1  hrs2 evwork wrkslf wrkgovt occ80 prestg80 indus80\n  &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;\n1  2006     1       1    35    NA     NA      2       2    95       66     832\n2  2006     2       1    40    NA     NA      2       2   243       44     560\n3  2006     3       5    NA    NA      1      2       2   715       29     352\n4  2006     4       2    24    NA     NA      2       2   313       46      60\n5  2006     5       6    NA    NA      2     NA      NA    NA       NA      NA\n6  2006     6       1    37    NA     NA      2       2   375       47     711\n# ℹ 1,305 more variables: found &lt;dbl&gt;, occ10 &lt;dbl&gt;, occindv &lt;dbl&gt;,\n#   occstatus &lt;dbl&gt;, occtag &lt;dbl&gt;, prestg10 &lt;dbl&gt;, prestg105plus &lt;dbl&gt;,\n#   indus10 &lt;dbl&gt;, indstatus &lt;dbl&gt;, indtag &lt;dbl&gt;, marital &lt;dbl&gt;, agewed &lt;dbl&gt;,\n#   divorce &lt;dbl&gt;, widowed &lt;dbl&gt;, spwrksta &lt;dbl&gt;, sphrs1 &lt;dbl&gt;, sphrs2 &lt;dbl&gt;,\n#   spevwork &lt;dbl&gt;, spwrkslf &lt;dbl&gt;, spocc80 &lt;dbl&gt;, sppres80 &lt;dbl&gt;,\n#   spind80 &lt;dbl&gt;, spocc10 &lt;dbl&gt;, spoccindv &lt;dbl&gt;, spoccstatus &lt;dbl&gt;,\n#   spocctag &lt;dbl&gt;, sppres10 &lt;dbl&gt;, sppres105plus &lt;dbl&gt;, spind10 &lt;dbl&gt;, …\n\n\n\n\nSelect your variables\nAs you can see, the data.frame contains a lot of variables; there are 1316 columns of data. You’ll only need a few of those. So the first step is selecting just the variables you need to work with.\nThere are a lot of ways to do this. The simplest would be to make a note of the variable IDs from the codebook and pipe the full data.frame into the select() function.1 This allows us to simply type in variable names separated by commas. Since I’ll probably forget which ID is which, I’ll give the columns more meaningful names as I select them.\n\ndata &lt;- data |&gt; \n  select(extraversion1 = big5a1, \n         extraversion2 = big5a2,\n         zodiac)\n\nLet’s see what this new data.frame looks like:\n\nhead(data)\n\n# A tibble: 6 × 3\n  extraversion1 extraversion2 zodiac\n          &lt;dbl&gt;         &lt;dbl&gt;  &lt;dbl&gt;\n1            NA            NA     NA\n2            NA            NA      5\n3            NA            NA      5\n4            NA            NA      7\n5            NA            NA     10\n6            NA            NA     12\n\n\nAnother useful thing you can ask for is a summary() of your data.frame:\n\nsummary(data)\n\n extraversion1  extraversion2       zodiac      \n Min.   :1.00   Min.   :1.000   Min.   : 1.000  \n 1st Qu.:2.00   1st Qu.:1.000   1st Qu.: 3.000  \n Median :2.00   Median :2.000   Median : 6.000  \n Mean   :2.66   Mean   :2.035   Mean   : 6.444  \n 3rd Qu.:4.00   3rd Qu.:2.000   3rd Qu.: 9.000  \n Max.   :5.00   Max.   :5.000   Max.   :12.000  \n NA's   :3006   NA's   :2994    NA's   :157     \n\n\nI also recommend that you always inspect the data more extensively by eye (click the name in your Environment to open a tab showing the data and scroll down a bit). Generally it’s looking good, but there are a few issues we need to address before we can properly describe and analyze the data.\n\n\nCleaning the data\nYou’ll notice that the Zodiac data is coded as numbers; it would be helpful to turn those into labels. Also you might have noticed when looking in the codebook that one of your personality questions is worded positively (so that higher numbers mean a higher score on that personality trait) but the other is worded negatively (so that higher scores mean less of that trait). We need to make those consistent by reverse-coding the negatively-worded one before we can compute an average score.\n\nRe-labelling categorical variables\nFirst let’s label the zodiac column. The original data is recorded as the numbers 1 through 12 corresponding to the 12 star signs. Since R doesn’t know any better, it assumes these numbers should be treated as regular numbers, so it will compute an average score and things like that even though you and I know it doesn’t make a lot of sense to compute the average star sign for a bunch of people. It would make more sense to turn that variable into a “factor”, meaning a categorical variable.\nTo change something about the data like this, we can use the mutate() function. It can either create a new column or change the data in an existing column, depending on the name you specify first. After the name, the equals sign indicates what that resulting column will contain. In this case, we use the factor() function to create the new factor data. It consists of the original numeric zodiac data where the original score (the level of the resulting factor) is either 5 or 12; those numbers will be assigned labels “Leo” and “Pisces” respectively. Since for this project you are comparing just two signs, you only need to explicitly label those two. The others then become missing data (represented as NA).\n\ndata_cleaned &lt;- data |&gt; \n  mutate(zodiac = factor(zodiac, levels = c(5, 12), labels = c(\"Leo\", \"Pisces\")))\n\n\n\nRe-coding numeric variables\nFor the personality trait questions, or goal is to eventually average each participants’ answers to the two questions. However, remember that one question is positively-worded and the other negatively-worded, so it wouldn’t make sense to average them together just yet. To add to the confusion, as the codebook shows, the original data is coded so that 1 indicates “strongly agree” and 5 indicates “strongly disagree”. We want higher scores to indicate more of the trait in question, so we need to be careful about this.\nFor extraversion, item big5a1 (which I renamed extraversion1) is “reserved”, while item big5a2 (renamed extraversion2) is “outgoing, sociable”. Since right now a higher numeric score means the participant disagreed with the description, for the first question, a higher score means more extraversion. It is actually the second question–the positively-worded one–that we need to reverse-code.\nSince answers can range from 1 to 5, an easy way to reverse the scores is to subtract the participant’s response from 6; 1 becomes 5, 2 becomes 4, etc. (Note the use of mutate() again to computationally change something about the data.)\n\ndata_cleaned &lt;- data_cleaned |&gt; \n  mutate(extraversion2 = 6 - extraversion2)\n\nMake sure to identify the correct item for your trait; for some it is the first question whereas for others it is the second.\n\n\nComputing a scale average\nNow that both questions are scored consistently, the only thing that remains is to compute the average of the two for each participant. We’ll create this new column using mutate() once again. The average score is computed by the rowMeans() function, which produces an average score for each row in the data. We need to tell it which columns to average across, using the across() function within which we specify the two personality trait columns by name.\n\ndata_cleaned &lt;- data_cleaned |&gt; \n  mutate(extraversion_mean = rowMeans(across(c(extraversion1, extraversion2))))\n\n\n\nHandle missing data\nOne last thing; notice that the data contains a lot of missing data now, because we dropped anyone who wasn’t one of the two star signs we were interested in, and a lot of people were missing the Big 5 data in the first place. We might as well tidy things up, because if someone is missing one or both of the personality average score or star sign, they are no use to us.\n\ndata_cleaned &lt;- data_cleaned |&gt; \n  drop_na()\n\nLet’s see how it looks.\n\nsummary(data_cleaned)\n\n extraversion1   extraversion2      zodiac    extraversion_mean\n Min.   :1.000   Min.   :1.000   Leo   :119   Min.   :1.000    \n 1st Qu.:2.000   1st Qu.:4.000   Pisces:129   1st Qu.:3.000    \n Median :2.000   Median :4.000                Median :3.000    \n Mean   :2.657   Mean   :3.907                Mean   :3.282    \n 3rd Qu.:4.000   3rd Qu.:5.000                3rd Qu.:4.000    \n Max.   :5.000   Max.   :5.000                Max.   :5.000    \n\n\nPhew. We have our two extraversion items (one reverse-coded), the Zodiac labels, and the computed extraversion mean scores for each of the 248 participants with complete data. We’re ready to analyze the data!\nNotice that the number of rows in the data.frame has changed, because rows that didn’t meet that condition have been dropped.\n\nnrow(data)\n\n[1] 4510\n\nnrow(data_cleaned) \n\n[1] 248\n\n\nAfter filtering to keep only rows with complete data, we’re left with 248 valid responses (119 Leos and 129 Pisces).",
    "crumbs": [
      "Project 1: $t$-test",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data preparation</span>"
    ]
  },
  {
    "objectID": "t-test_2_zodiac.html#footnotes",
    "href": "t-test_2_zodiac.html#footnotes",
    "title": "3  Data preparation",
    "section": "",
    "text": "The select() function, along with filter(), mutate(), across(), everything(), and others that you’ll see in my example code, is part of the tidyverse family of packages (specifically these all come from the dplyr package, but we’ll also use functions from other tidyverse packages like tidyr and ggplot2). There are other ways to do all these things without using tidyverse packages, just relying on what’s referred to as “base” R functions. The tidyverse approach just makes this kind of data manipulation generally easier and makes the code more interpretable. If you’re curious to see how base R and tidyverse functions differ in syntax, a good place to start is https://dplyr.tidyverse.org/articles/base.html.↩︎",
    "crumbs": [
      "Project 1: $t$-test",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data preparation</span>"
    ]
  },
  {
    "objectID": "t-test_3_zodiac.html",
    "href": "t-test_3_zodiac.html",
    "title": "4  Analysis",
    "section": "",
    "text": "Goals",
    "crumbs": [
      "Project 1: $t$-test",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Analysis</span>"
    ]
  },
  {
    "objectID": "t-test_3_zodiac.html#analyzing-data-in-r",
    "href": "t-test_3_zodiac.html#analyzing-data-in-r",
    "title": "4  Analysis",
    "section": "Analyzing data in R",
    "text": "Analyzing data in R\nRunning with my example from last week, I want to compare average extraversion scores between Leos and Pisces. I made a data.frame with just those columns; recoded the Zodiac labels and reverse-scored one of the extraversion items; and computed an extraversion mean score. To refresh your memory, here’s the entire pipeline from start to finish:\n\nlibrary(tidyverse)\n\ndata_cleaned &lt;- read_csv(\"data/gss_2006.csv\") |&gt; \n  select(extraversion1 = big5a1, \n         extraversion2 = big5a2,\n         zodiac) |&gt; \n  mutate(zodiac = factor(zodiac, levels = c(5, 12), labels = c(\"Leo\", \"Pisces\"))) |&gt; \n  mutate(extraversion2 = 6 - extraversion2) |&gt; \n  mutate(extraversion_mean = rowMeans(across(c(extraversion1, extraversion2)))) |&gt; \n  drop_na()\n\n\nDescribing your data\nThe most common descriptive statistics are the mean (\\(M\\)) and standard deviation (\\(SD\\)). You should report these for each variable in your analysis.\nYou can find these for a set of numbers using R’s built-in mean() and sd() functions.\n\nmean(data_cleaned$extraversion1)\n\n[1] 2.657258\n\nsd(data_cleaned$extraversion1)\n\n[1] 1.120054\n\n\nThis might be a perfectly appropriate approach, but with a lot of variables it might not be the most efficient. A more powerful approach is to use tidyverse summarize() function. There you can create any number of named variables, each computing some kind of summary. The biggest advantage is you can specific a grouping variable using the .by argument. This means that each of the statistics you ask for will be computed separately for each category of the grouping variable.\n\ndata_cleaned |&gt;\n  summarize(n = n(),\n            mean = mean(extraversion_mean), \n            sd = sd(extraversion_mean),\n            .by = zodiac)\n\n# A tibble: 2 × 4\n  zodiac     n  mean    sd\n  &lt;fct&gt;  &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Leo      119  3.39 0.857\n2 Pisces   129  3.19 0.791\n\n\nWhen it comes to visualizing the data later, I will want to show the confidence interval associated with each group mean. I can compute this right now as part of summarize. There’s no built-in confidence interval function, but we can easily make one ourselves.\n\nci &lt;- function(x) {\n  qt(.975, df = length(x) - 1) * sqrt( var(x) / length(x) )\n}\n\nAnd, having created the function, use it within summarize() just like any other function.\n\nsummary &lt;- data_cleaned |&gt;\n  summarize(n = n(),\n            mean = mean(extraversion_mean), \n            sd = sd(extraversion_mean),\n            ci = ci(extraversion_mean),\n            .by = zodiac)\n\nsummary\n\n# A tibble: 2 × 5\n  zodiac     n  mean    sd    ci\n  &lt;fct&gt;  &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Leo      119  3.39 0.857 0.156\n2 Pisces   129  3.19 0.791 0.138\n\n\n\n\nVisualizing the data\nIn addition to reporting the mean and standard deviation, it is useful to visualize the distribution of the data. This can reveal nuances that are not obvious in those single numeric summary values.\nAs with most things, there are a lot of different ways of producing graphs using R. One of the most widely used and powerful is the ggplot2 package.1 The name refers to the idea of the “grammar of graphics”, and it is built around a layering approach. You first specify your data and aesthetics (what should data will go on the x and y axes), then geometry (do you want data to be represented by points or bars or as a histogram?), any scaling (e.g. what values should be labeled on each axis), and theme elements (how do you want the plot to look generally?). There can be a lot of complexity, but building things up layer by layer, gradually adding and refining elements, is a powerful and satisfying approach.\nHere’s a simple histogram of the first extraversion item. I pipe the data into the ggplot() function, specifying that I want the extraversion1 column to be represented as the x aesthetic. Then I add geometry using geom_histogram. That geom function automatically computes bins and counts; here I just specify I want a binwidth of 1, i.e. each column of the histogram will represent one scale point. Note that ggplot layers are added using + rather than the usual |&gt; pipe.\n\ndata_cleaned |&gt; \n  ggplot(aes(x = extraversion1)) +\n  geom_histogram(binwidth = 1)\n\n\n\n\n\n\n\nFigure 4.1: Histogram of responses to “extraverted, enthusiastic” TIPI item\n\n\n\n\n\nThe default theme is perfectly serviceable, but you can customize every element. Here I’ll specify a couple of aspects using the theme() function, and I’ll assign it to the name theme_apa. Then I can always add theme_apa as a layer to my plots going forward.\n\ntheme_apa &lt;- theme(\n  panel.background = element_blank(),\n  axis.line = element_line()\n)\n\nI’ll also customize the “breaks” on the x-axis (where the ticks and numeric labels go) and the axis labels.\n\ndata_cleaned |&gt; \n  ggplot(aes(x = extraversion1)) +\n  geom_histogram(binwidth = 1, color = \"white\") +\n  scale_x_continuous(breaks = 1:5) +\n  labs(x = \"Responses to extraversion item 1: reserved\",\n       y = \"Number of responses\") +\n  theme_apa\n\n\n\n\n\n\n\nFigure 4.2: Histogram of responses to “reserved” TIPI item\n\n\n\n\n\nHere’s a histogram of the other extraversion item.\n\ndata_cleaned |&gt; \n  ggplot(aes(x = extraversion2)) +\n  geom_histogram(binwidth = 1, color = \"white\") +\n  scale_x_continuous(breaks = 1:5) +\n  labs(x = \"Responses to extraversion item 2: outgoing, sociable\",\n       y = \"Number of responses\") +\n  theme_apa\n\n\n\n\n\n\n\nFigure 4.3: Histogram of responses to “outgoing, sociable” TIPI item\n\n\n\n\n\nAnd here’s a histogram of the average extraversion scores I computed.\n\ndata_cleaned |&gt; \n  ggplot(aes(x = extraversion_mean)) +\n  geom_histogram(binwidth = 0.5, color = \"white\") +\n  scale_x_continuous(breaks = 1:7) +\n  labs(x = \"Average scores across both TIPI extraversion items\",\n       y = \"Count\") +\n  theme_apa\n\n\n\n\n\n\n\nFigure 4.4: Histogram of average scores on TIPI Extraversion subscale\n\n\n\n\n\nNotice that while both individual extraversion items were a bit skewed, the distribution of averages is approximately normally-distributed (albeit with a big spike in the middle).",
    "crumbs": [
      "Project 1: $t$-test",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Analysis</span>"
    ]
  },
  {
    "objectID": "t-test_3_zodiac.html#hypothesis-test",
    "href": "t-test_3_zodiac.html#hypothesis-test",
    "title": "4  Analysis",
    "section": "Hypothesis test",
    "text": "Hypothesis test\n\nThe \\(t\\) statistic\nThe \\(t\\)-test can be computed with a single line of code, as you’ll see. But it’s important to understand the math happening behind the scenes.\nIf you need to refresh your memory from a past statistics class, refer to the \\(t\\)-test Appendix.\n\n\nThe \\(t\\)-test\nR has a built-in t.test() function. When the data is organized with one column containing the grouping variable (the IV) and one column containing the numeric DV scores, the t.test function requires a “formula” argument. This allows us to provide the names of those columns in the format “DV ~ IV”, i.e. compare scores on the DV across the groups of the IV. We also supply a “data” argument which points R to the data.frame containing those columns, and we can perform the \\(t\\)-test with the assumption of equal variances by stating var.equal = TRUE as another argument.\n\nt.test(formula = extraversion_mean ~ zodiac, data = data_cleaned, var.equal = TRUE)\n\n\n    Two Sample t-test\n\ndata:  extraversion_mean by zodiac\nt = 1.916, df = 246, p-value = 0.05652\nalternative hypothesis: true difference in means between group Leo and group Pisces is not equal to 0\n95 percent confidence interval:\n -0.005610518  0.406626738\nsample estimates:\n   mean in group Leo mean in group Pisces \n            3.386555             3.186047 \n\n\n\n\nVisualizing the difference\nLastly, it is always helpful to visualize the comparison that the \\(t\\)-test is making, to supplement the numeric results. One option is a bar graph in which the height of each bar represents the mean score for each group. We can also add error bars showing those confidence intervals we computed earlier.\n\nsummary |&gt; \n  ggplot(aes(x = zodiac, y = mean)) +\n  geom_col() +\n  geom_errorbar(aes(ymax = mean + ci, ymin = mean - ci), width = 0.2) +\n  coord_cartesian(ylim = c(1, 5)) +\n  theme_apa",
    "crumbs": [
      "Project 1: $t$-test",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Analysis</span>"
    ]
  },
  {
    "objectID": "t-test_3_zodiac.html#footnotes",
    "href": "t-test_3_zodiac.html#footnotes",
    "title": "4  Analysis",
    "section": "",
    "text": "The ggplot2 package is part of the tidyverse, so because we already ran library(tidyverse) earlier the ggplot2 functions are already available to us. If you needed to, you could always run library(ggplot2) to activate it separately.↩︎",
    "crumbs": [
      "Project 1: $t$-test",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Analysis</span>"
    ]
  },
  {
    "objectID": "t-test_4_zodiac.html",
    "href": "t-test_4_zodiac.html",
    "title": "5  Presentation & report",
    "section": "",
    "text": "Presentation",
    "crumbs": [
      "Project 1: $t$-test",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Presentation & report</span>"
    ]
  },
  {
    "objectID": "t-test_4_zodiac.html#presentation",
    "href": "t-test_4_zodiac.html#presentation",
    "title": "5  Presentation & report",
    "section": "",
    "text": "Guide to presenting\nEach team will give a short presentation which should encapsulate the motivation, methods, anticipated findings, and interpretation of your proposed project. Aim for clarity, conciseness, and being bold to spark the audience’s interest in your topic and findings.\nAvoid simply reading excerpts from your paper. That would be boring, and would probably take up too many words. Make it fun and interesting. Try to grab the audience’s attention and hit them with just the most important points of your ideas.\nMake your slides count. You can’t just cram a load of text on there, because nobody will be able to read it. Plus, it’d distract from what you’re saying. Make it a visual aid that somehow supports or clarifies what you’re saying. It might be a visual representation of your design, a key piece of your experimental stimuli, a graph of your expected results, or just a pertinent meme which conveys the motivation for your question.\nAfter your presentation the group will take a few questions from the audience, and your responsiveness will contribute toward your grade as well as the quality of your presentation itself (remember a perfectly acceptable answer if often: “Good question; I don’t know the answer! But here are some thoughts…”). It’s not usually an issue, but just in case your audience is left speechless, I suggest coming with a couple of questions or thoughts of your own that you can throw at the audience to spark more questions (“You might be wondering…”).\nIt is up to each group to decide how to divide up the talk, and to practice to make sure the presentation is to time.\n\n\nGuide to watching presentations\nAs an audience member, you are still being graded for class participation. That means giving everyone else’s presentation the attention and enthusiasm it deserves, and rewarding their hard work with questions. (Going to the trouble of putting together a presentation only for nobody to have anything to say about it is not a good feeling.)\nGood questions to ask are things like “Could you clarify X”, “Had you considered Y”, or “How might this relate to Z.” One reason for presenting your project is to hopefully get some useful feedback from the audience with which to refine your final paper, so try to give the kind of feedback you hope to receive.",
    "crumbs": [
      "Project 1: $t$-test",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Presentation & report</span>"
    ]
  },
  {
    "objectID": "t-test_4_zodiac.html#sec-report",
    "href": "t-test_4_zodiac.html#sec-report",
    "title": "5  Presentation & report",
    "section": "Written report",
    "text": "Written report\nYou will produce a miniature research paper reporting your project. Note that each team member will produce their own individual report; even though the project has been collaborative, your write up will be your own.\n\nFormat\nYour report should consist of the following sections:\n\nIntroduction (two or three paragraphs, including summary of relevant research and hypothesis)\nMethod (a description of the variables you selected, the number of valid responses, and any other information about the procedures that generated the data that you think necessary to report)\nResults (a technical report of any descriptive statistics, figures, and statistics you produced)\nDiscussion (a paragraph or two interpreting your results and drawing conclusions)\n\n\n\nDeadline\nThe report is due by the next class (see late policy from Syllabus 1.2.2).\n\n\nGrading\nYou will receive a score out of 100 for your report. See Appendix E for general qualitative criteria which will be assessed in the context of the expectations detailed above.",
    "crumbs": [
      "Project 1: $t$-test",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Presentation & report</span>"
    ]
  },
  {
    "objectID": "correlation_1_anes.html",
    "href": "correlation_1_anes.html",
    "title": "6  Project Planning",
    "section": "",
    "text": "Goals",
    "crumbs": [
      "Project 2: Correlation",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Project Planning</span>"
    ]
  },
  {
    "objectID": "correlation_1_anes.html#project-overview",
    "href": "correlation_1_anes.html#project-overview",
    "title": "6  Project Planning",
    "section": "Project overview",
    "text": "Project overview\nA correlation refers an association between two things. It is a statement of a statistical relationship–a general tendency, rather than a rigid law. To say that some aspect of personality is correlated with something else–for example, neuroticism is correlated with lower wellbeing or openness is correlated with greater cognitive ability–is to say that those things tend to go together. Not everyone who scores high on neuroticism will have lower wellbeing than anyone low on neuroticism, but there is some tendency for the two to go together on the whole.\nOf course, these kind of correlations aren’t just facts found lying around in nature; they are empirical findings produced by researchers. All the findings you learn about in the personality psychology lecture (and beyond) are the product of research procedures. Researchers decide what psychological constructs they want to investigate; how to measure those constructs; what statistical analyses are appropriate; and what conclusions may be drawn. There are strengths, limitations, and trade offs involved in every decision along the way.\nWith this project, you will examine a correlation between a personality trait and another construct of your choosing by analyzing existing data.\n\nStep 1. Examine the data\nThe dataset we will use is from the American National Election Studies (ANES), academic surveys of voters in the United States conducted before and after every presidential election, going back to the 1940s. Specifically, for this project we will use data collected around the 2016 election. The reason for using this (rather than more recent data) is that the 2016 survey included a personality scale: the Ten-Item Personality Inventory (TIPI: Gosling et al., 2003). This scale is a short measure of the “Big Five” personality traits of Openness, Conscientiousness, Extraversion, Agreeableness, and Neuroticism.\nFor this project, you will pick one of these traits and investigate its correlation with another question from the survey. The full dataset contains almost 2,000 questions in total. Since this is your first project, however, I am going to constrain your choice. For this kind of correlation analysis you will have two variables. You can think of one as the “predictor” and the other as the “outcome”; you want to see if the predictor has any association with the outcome.\nYour predictor variable will be one of the Big Five traits:\n\nExtraversion (V162333 & V162338)\nAgreeableness (V162334 & V162339)\nConscientiousness (V162335 & V162340)\nNeuroticism (V162336 & V162341)\nOpenness (V162337 & V162342)\n\nYour outcome variable will be one of the following “feeling thermometer” questions, referring to the two main presidential candidates, political parties, or liberals/conservatives in general:\n\nDemocratic presidential candidate (V162078) OR Republican presidential candidate (V162079)\nDemocratic party (V161095) OR Republican party (V161096)\nLiberals (V162097) OR Conservatives (V162101)\n\nTo see exactly how these constructs were measured you will look up the variable IDs (the V16… codes in parentheses above) in the Codebook.\n\n\nStep 2. Read relevant research\nReal research doesn’t happen in a vacuum; research plans and expectations should be informed by what has come before. Therefore once you know which variables you will analyze, you will see what other researchers have found about these (or related) personality traits.\nA real research project would involve an exhaustive literature review, in which you attempt to find and understand all the research relevant to your question. Since this project of ours is just for practice and our time is limited, you don’t need to read everything; pick one of these papers to skim to give you an idea of what has been found.\n\nGerber, A. S., Huber, G. A., Doherty, D., & Dowling, C. M. (2011). The big five personality traits in the political arena. Annual Review of Political Science, 14, 265-287.\nCooper, C. A., Golden, L., & Socha, A. (2013). The big five personality factors and mass politics. Journal of Applied Social Psychology, 43(1), 68-82.\n\n\n\nStep 3. Articulate your hypothesis\nBy this point you should be able to state your:\n\nOperational definitions (that is, the specific questions that participants were asked and how they could answer, per the codebook)\nThe constructs that those operational definitions measure (i.e. does the question measure perceived political preferences in general? Or some more specific form of affiliation/alignment?)\nYour hypothesis\n\nYour hypothesis is a formal statement of your expectation about how your constructs are (or aren’t) associated, and it will be tested quantitatively by calculating a correlation statistic.\nThe main question that your hypothesis addresses is: do you think the two variables will be significantly correlated? That is, will you find an association consistent enough that it doesn’t just seem to be attributable to chance variation in the data?1\nIf you do expect a significant correlation, you should also specify whether you expect it to be positive or negative, and how strong you expect it to be (i.e. weak, moderate, strong; see Appendix B).",
    "crumbs": [
      "Project 2: Correlation",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Project Planning</span>"
    ]
  },
  {
    "objectID": "correlation_1_anes.html#footnotes",
    "href": "correlation_1_anes.html#footnotes",
    "title": "6  Project Planning",
    "section": "",
    "text": "Even random data will produce spurious correlations by chance some of the time; see spuriouscorrelations.com↩︎",
    "crumbs": [
      "Project 2: Correlation",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Project Planning</span>"
    ]
  },
  {
    "objectID": "correlation_2_anes.html",
    "href": "correlation_2_anes.html",
    "title": "7  Data preparation",
    "section": "",
    "text": "Goals",
    "crumbs": [
      "Project 2: Correlation",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Data preparation</span>"
    ]
  },
  {
    "objectID": "correlation_2_anes.html#working-with-data-in-r",
    "href": "correlation_2_anes.html#working-with-data-in-r",
    "title": "7  Data preparation",
    "section": "Working with data in R",
    "text": "Working with data in R\n\nGetting R ready\nAs with the first project we’ll make use of the tidyverse package, so it needs to be ‘activated’ using the library function.\n\nlibrary(tidyverse)\n\n\n\nGetting data into R\nLikewise, we need to read in the relevant data file to work with in R. Like the GSS, ANES datasets can be downloaded from their website, but I’ve already done that for us: the data is in a .csv file in the data subfolder of this project.\n\nraw_data &lt;- read.csv(\"data/anes_2016.csv\")\n\nRemember that when you execute the code you won’t see any output, but you should see the name you used on the left-hand side of the &lt;- assignment operator appear in your Environment pane.\nDon’t forget to take a look at the data.frame object to make sure it’s as you expect. One way is to click on the name in the Environment pane to view the data as a spreadsheet in a new tab.\n\n\nSelect your variables\nAs you can see, the data.frame contains a lot of variables; there are 1,842 columns of data. You’ll only need a few of those. So the first step is selecting just the variables you need to work with.\nThere are a lot of ways to do this. The simplest would be to make a note of the variable IDs from the codebook and use the select() function.1 This allows us to simply type in variable names separated by commas.\nFor this example I’ll look at the correlation between extraversion and the Democratic party feeling thermometer. Extraversion has two TIPI items; their IDs (from the codebook) are V162333 and V162338. The ID for the Democratic Party feeling thermometer is V161095. Since I’ll probably forget which ID is which, I’ll give the columns more meaningful names as I select them.\n\nmy_data &lt;- raw_data |&gt; \n  select(extraversion1 = \"V162333\", \n         extraversion2 = \"V162338\",\n         feeling_thermometer = \"V161095\")\n\nLet’s see what this new data.frame looks like:\n\nhead(my_data)\n\n  extraversion1 extraversion2 feeling_thermometer\n1             6             5                   0\n2             6             6                  15\n3             6             2                  50\n4             6             4                  30\n5             5             7                  70\n6             5             6                  15\n\nsummary(my_data)\n\n extraversion1    extraversion2   feeling_thermometer\n Min.   :-9.000   Min.   :-9.00   Min.   :-99.00     \n 1st Qu.: 2.000   1st Qu.: 2.00   1st Qu.: 16.25     \n Median : 5.000   Median : 4.00   Median : 50.00     \n Mean   : 3.041   Mean   : 2.69   Mean   : 45.81     \n 3rd Qu.: 6.000   3rd Qu.: 6.00   3rd Qu.: 70.00     \n Max.   : 7.000   Max.   : 7.00   Max.   :100.00     \n\n\nIt all looks good so far. But if you inspect the data more extensively (click the name in your Environment to open a tab showing the data and scroll down a bit) you’ll notice that there are some negative numbers in the data. That’s from survey codes which record missing data. If you try to calculate an average score with those included it’ll mess up the sums, so we need to do some data cleaning to handle things like that.\n\n\nCleaning the data\nThere are a lot of different ways we could handle this. One way is to filter() the data, retaining only rows which meet certain conditions.2\nThe ANES coding scheme uses negative values for the various kinds of missing or inappropriate data, which makes things simple: only positive values are valid and should be retained.\nTo implement this as a filter(), we can use the if_all() function; i.e., we are going to select some columns and if all the values in those columns meet some condition the row will be retained. To select the columns we can use the everything() function, since the positive-valid/negative-invalid rule is true of every column in our data. The part after the comma, ~ . &gt;= 0, articulates the condition. The ~ prefix is necessary because instead of naming one specific column to refer to its values we use . as a placeholder representing the values in each of the selected columns; the value must be greater than or equal to 0 to be retained.3\n\nmy_data_complete &lt;- my_data |&gt; \n  filter(if_all(everything(), ~ . &gt;= 0))\n\nNotice that the number of rows in the data.frame has changed, because rows that didn’t meet that condition have been dropped.\n\nnrow(my_data)\n\n[1] 4270\n\nnrow(my_data_complete) \n\n[1] 3540\n\n\nAfter filtering to keep only rows with complete data, we’re left with 3,540 valid responses.\n\n\nComputing scale averages\nNow that we have selected our columns and filtered out missing/invalid responses, the last thing to do is compute any new values required for analysis. As an example, if you have a scale which has multiple questions asking about a particular construct, it is often necessary to compute an average score for each participant.\nThe TIPI has 10 questions in total, two for each of the Big 5 personality traits, so it may be desirable to compute a mean trait score by averaging its two respective items.\nNotice, however, that for each of the 5 traits, one question is positively worded and one is negatively worded. For extraversion, item V162333 (which I renamed extraversion1) is “extraverted, enthusiastic”, while item V162338 (renamed extraversion2) is “reserved, quiet”. The second one needs to be reverse-coded, so that higher scores on both items indicate greater extraversion. Since answers can range from 1 to 7, an easy way to recode the scores is to subtract the participant’s response from 8; 1 becomes 7, 2 becomes 6, etc.\n\nmy_data_complete &lt;- my_data_complete |&gt;\n    mutate(extraversion2 = 8 - extraversion2)\n\nNow we can go ahead and compute the average, using mutate() to create a new column (named extraversion_mean) consisting of the rowMeans() (i.e. an average for each row) across() the specified columns (those for which the column name contains(\"extraversion\").\n\nmy_data_complete &lt;- my_data_complete |&gt;\n    mutate(extraversion_mean = rowMeans(across(contains(\"extraversion\"))))\n\nLet’s see how it looks.\n\nhead(my_data_complete)\n\n  extraversion1 extraversion2 feeling_thermometer extraversion_mean\n1             6             3                   0               4.5\n2             6             2                  15               4.0\n3             6             6                  50               6.0\n4             6             4                  30               5.0\n5             5             1                  70               3.0\n6             5             2                  15               3.5\n\nsummary(my_data_complete)\n\n extraversion1   extraversion2  feeling_thermometer extraversion_mean\n Min.   :1.000   Min.   :1.00   Min.   :  0.00      Min.   :1.000    \n 1st Qu.:4.000   1st Qu.:2.00   1st Qu.: 25.00      1st Qu.:3.500    \n Median :5.000   Median :3.00   Median : 50.00      Median :4.000    \n Mean   :4.787   Mean   :3.65   Mean   : 48.32      Mean   :4.218    \n 3rd Qu.:6.000   3rd Qu.:5.00   3rd Qu.: 70.00      3rd Qu.:5.000    \n Max.   :7.000   Max.   :7.00   Max.   :100.00      Max.   :7.000    \n\n\nWe have our two extraversion items (one reverse-coded), the feeling thermometer rating, and the computed extraversion mean scores for each of the 3,540 participants with complete data. We’re ready to analyze the data!",
    "crumbs": [
      "Project 2: Correlation",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Data preparation</span>"
    ]
  },
  {
    "objectID": "correlation_2_anes.html#footnotes",
    "href": "correlation_2_anes.html#footnotes",
    "title": "7  Data preparation",
    "section": "",
    "text": "The select() function, along with filter(), mutate(), across(), everything(), and others that you’ll see in my example code, is part of the tidyverse family of packages (specifically these all come from the dplyr package, but we’ll also use functions from other tidyverse packages like tidyr and ggplot2). There are other ways to do all these things without using tidyverse packages, just relying on what’s referred to as “base” R functions. The tidyverse approach just makes this kind of data manipulation generally easier and makes the code more interpretable. If you’re curious to see how base R and tidyverse functions differ in syntax, a good place to start is https://dplyr.tidyverse.org/articles/base.html.↩︎\nAnother way would be to mutate() the data, changing the invalid response codes into the value NA, R’s special value to indicate missing data. This could be achieved like so:\nmy_data_complete &lt;- my_data |&gt;\n  mutate(across(everything(), ~replace(., . &lt; 0, NA)))\nThat would mutate (i.e. change values) across every column. You can read the second part (after the ~) as “replace the original values (indicated by the placeholder .), where the value is less than zero, with NA.↩︎\nIf the data wasn’t as simple or if we just wanted to be more explicit about things, we could filter based on valid responses for each item. For example, valid reponses to the feeling thermometer item are are anything from 0 to 100; anything else is invalid. Therefore we could write a filter() condition stating that feeling_thermometer (the name of the column) values must be %in% the set of values from 0:100. Likewise for each of the extraversion columns, rows will be retained only if their values are %in% the range 1:7.\nmy_data_complete &lt;- my_data |&gt;\n  filter(feeling_thermometer %in% 0:100,\n         extraversion1 %in% 1:7,\n         extraversion2 %in% 1:7)\n↩︎",
    "crumbs": [
      "Project 2: Correlation",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Data preparation</span>"
    ]
  },
  {
    "objectID": "correlation_3_anes.html",
    "href": "correlation_3_anes.html",
    "title": "8  Analysis",
    "section": "",
    "text": "Goals",
    "crumbs": [
      "Project 2: Correlation",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Analysis</span>"
    ]
  },
  {
    "objectID": "correlation_3_anes.html#analyzing-data-in-r",
    "href": "correlation_3_anes.html#analyzing-data-in-r",
    "title": "8  Analysis",
    "section": "Analyzing data in R",
    "text": "Analyzing data in R\nRunning with my example from last week, my variables were average extraversion scores and the Democratic Party feeling thermometer score. I made a data.frame with just those variables; filtered the data down to complete, valid responses; recoded the negatively-worded item; and computed an extraversion mean score. To refresh your memory, here’s the entire pipeline from start to finish:\n\nlibrary(tidyverse)\nlibrary(anesr)\ndata(timeseries_2016)\n\nmy_data_complete &lt;- timeseries_2016 |&gt; \n  select(extraversion1 = \"V162333\", \n         extraversion2 = \"V162338\",\n         feeling_thermometer = \"V161095\") |&gt; \n  filter(if_all(everything(), ~ . &gt;= 0)) |&gt; \n  mutate(extraversion2 = 8 - extraversion2,\n         extraversion_mean = rowMeans(across(contains(\"extraversion\"))))\n\n\nDescribing your data\nThe most common descriptive statistics are the mean (\\(M\\)) and standard deviation (\\(SD\\)). You should report these for each variable in your analysis.\nYou can find the mean of each column in a data.frame using R’s built-in colMeans() function.\n\ncolMeans(my_data_complete)\n\n      extraversion1       extraversion2 feeling_thermometer   extraversion_mean \n           4.787006            3.649718           48.317232            4.218362 \n\n\nThere’s no built-in equivalent for finding the standard deviation of columns, but there is a basic sd() function, which you could apply to each column in turn:\n\nsd(my_data_complete$extraversion1)\n\n[1] 1.579163\n\nsd(my_data_complete$extraversion2)\n\n[1] 1.764589\n\n# etc\n\nThis might be a perfectly appropriate approach, but with a lot of variables it might not be the most efficient (and it kind of violates the DRY principle: don’t repeat yourself).\nA slightly more complicated but very powerful approach is to use tidyverse functions to reshape the data and summarize() each of the variables. First, transform the structure of the data using pivot_longer(). This produces a data.frame with just two columns, one with all the numeric scores (“value”), and the other labeling which column each value came from (“variable”). Then we group_by(variable), meaning that any subsequent computations will be performed separately for each variable. Finally we pipe the data.frame into the summarize() function. There you can create any number of named variables, each computing some kind of summary. Since the data is grouped, each variable (“extraversion1”, extraversion2”, etc) gets its own count, mean, and standard deviation.\n\nmy_data_complete |&gt;\n  pivot_longer(everything(), \n               names_to = \"variable\", \n               values_to = \"value\", \n               values_transform = as.numeric) |&gt; \n  group_by(variable) |&gt; \n  summarize(count_valid = n(),\n            mean = mean(value), \n            sd = sd(value))\n\n# A tibble: 4 × 4\n  variable            count_valid  mean    sd\n  &lt;chr&gt;                     &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 extraversion1              3540  4.79  1.58\n2 extraversion2              3540  3.65  1.76\n3 extraversion_mean          3540  4.22  1.38\n4 feeling_thermometer        3540 48.3  30.0 \n\n\n\n\nVisualizing the data\nIn addition to reporting the mean and standard deviation, it is useful to visualize the distribution of the data. This can reveal nuances that are not obvious in those single numeric summary values.\nAs with most things, there are a lot of different ways of producing graphs using R. One of the most widely used and powerful is the ggplot2 package.1 The name refers to the idea of the “grammar of graphics”, and it is built around a layering approach. You first specify your data and aesthetics (what should data will go on the x and y axes), then geometry (do you want data to be represented by points or bars or as a histogram?), any scaling (e.g. what values should be labeled on each axis), and theme elements (how do you want the plot to look generally?). There can be a lot of complexity, but building things up layer by layer, gradually adding and refining elements, is a powerful and satisfying approach.\nHere’s a simple histogram of the first extraversion item. I pipe the data into the ggplot() function, specifying that I want the extraversion1 column to be represented as the x aesthetic. Then I add geometry using geom_histogram. That geom function automatically computes bins and counts; here I just specify I want a binwidth of 1, i.e. each column of the histogram will represent one scale point. Note that ggplot layers are added using + rather than the usual |&gt; pipe.\n\nmy_data_complete |&gt; \n  ggplot(aes(x = extraversion1)) +\n  geom_histogram(binwidth = 1)\n\nDon't know how to automatically pick scale for object of type &lt;haven_labelled&gt;.\nDefaulting to continuous.\n\n\n\n\n\n\n\n\nFigure 8.1: Histogram of responses to “extraverted, enthusiastic” TIPI item\n\n\n\n\n\nThe default theme is perfectly serviceable, but you can customize every element. Here I’ll specify a couple of aspects using the theme() function, and I’ll assign it to the name theme_apa. Then I can always add theme_apa as a layer to my plots going forward.\n\ntheme_apa &lt;- theme(\n  panel.background = element_blank(),\n  axis.line = element_line()\n)\n\nI’ll also customize the “breaks” on the x-axis (where the ticks and numeric labels go) and the axis labels.\n\nmy_data_complete |&gt; \n  ggplot(aes(x = extraversion1)) +\n  geom_histogram(binwidth = 1, color = \"white\") +\n  scale_x_continuous(breaks = 1:7) +\n  labs(x = \"Responses to extraversion item 1: extraverted, enthusiastic\",\n       y = \"Number of responses\") +\n  theme_apa\n\n\n\n\n\n\n\nFigure 8.2: Histogram of responses to “extraverted, enthusiastic” TIPI item\n\n\n\n\n\nHere’s a histogram of the other TIPI extraversion item.\n\nmy_data_complete |&gt; \n  ggplot(aes(x = extraversion2)) +\n  geom_histogram(binwidth = 1, color = \"white\") +\n  scale_x_continuous(breaks = 1:7) +\n  labs(x = \"Responses to extraversion item 2: reserved, quiet (reverse-coded)\",\n       y = \"Number of responses\") +\n  theme_apa\n\n\n\n\n\n\n\nFigure 8.3: Histogram of responses to “reserved, quiet” TIPI item\n\n\n\n\n\nAnd here’s a histogram of the average extraversion scores I computed.\n\nmy_data_complete |&gt; \n  ggplot(aes(x = extraversion_mean)) +\n  geom_histogram(binwidth = 0.5, color = \"white\") +\n  scale_x_continuous(breaks = 1:7) +\n  labs(x = \"Average scores across both TIPI extraversion items\",\n       y = \"Count\") +\n  theme_apa\n\n\n\n\n\n\n\nFigure 8.4: Histogram of average scores on TIPI Extraversion subscale\n\n\n\n\n\nNotice that while both individual extraversion items were a bit skewed, the distribution of averages is approximately normally-distributioned (albeit with a big spike in the middle).\nLastly, I’ll make a histogram of the feeling thermometer variable.\n\nmy_data_complete |&gt; \n  ggplot(aes(x = feeling_thermometer)) +\n  geom_histogram(binwidth = 1, color = \"white\") +\n  scale_x_continuous(breaks = seq(from = 0, to = 100, by = 10)) +\n  labs(x = \"Responses to Democratic Party feeling thermometer\",\n       y = \"Count\") +\n  theme_apa\n\n\n\n\n\n\n\nFigure 8.5: Histogram of responses to Democratic Party feeling thermometer\n\n\n\n\n\nI chose a binwidth of 1, which isn’t necessarily the most appropriate value for a 0 to 100, but it does reveal an interesting distribution of responses. People’s responses are not evenly distributed across the 0 to 100 scale; rather, some values (particularly multiples of 10) are chosen much more frequently than others.",
    "crumbs": [
      "Project 2: Correlation",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Analysis</span>"
    ]
  },
  {
    "objectID": "correlation_3_anes.html#correlation-analysis",
    "href": "correlation_3_anes.html#correlation-analysis",
    "title": "8  Analysis",
    "section": "Correlation analysis",
    "text": "Correlation analysis\n\nThe correlation statistic\nThe correlation statistic can be computed with a single line of code, as you’ll see. But it’s important to understand the math happening behind the scenes.\nIf you need to refresh your memory from a past statistics class, refer to the correlation statistic Appendix.\n\n\nCorrelation in R\nThe correlation between two variables can be found using the cor() function.\n\ncor(x = my_data_complete$extraversion_mean, \n    y = my_data_complete$feeling_thermometer)\n\n[1] -0.01012898\n\n\nIf you got an answer of NA instead of a number, it is probably because your data has some missing data. You just need to tell cor() to only use data for which both pairs of values are nonmissing:\n\ncor(x = my_data_complete$extraversion_mean, \n    y = my_data_complete$feeling_thermometer,\n    use = \"pairwise.complete.obs\")\n\n[1] -0.01012898\n\n\nThe cor.test() function goes further than cor(), giving you the \\(p\\)-value necessary for determining statistical significance2 and some other information about the correlation.\n\ncor.test(x = my_data_complete$extraversion_mean, \n         y = my_data_complete$feeling_thermometer)\n\n\n    Pearson's product-moment correlation\n\ndata:  my_data_complete$extraversion_mean and my_data_complete$feeling_thermometer\nt = -0.60251, df = 3538, p-value = 0.5469\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.04305838  0.02282241\nsample estimates:\n        cor \n-0.01012898 \n\n\nLastly, let’s make a scatterplot visualizing the correlation.\n\nmy_data_complete |&gt; \n  ggplot(aes(x = extraversion_mean, y = feeling_thermometer)) +\n  geom_point(position = position_jitter(width = 0.4, height = 0, seed = 1), \n             alpha = 0.1) +\n  scale_x_continuous(breaks = 1:7) +\n  scale_y_continuous(breaks = seq(from = 0, to = 100, by = 10)) +\n  theme_apa\n\n\n\n\n\n\n\nFigure 8.6: Scatterplot (with jitter) of average extraversion scores and feeling thermometer scores\n\n\n\n\n\nMost of that will look familiar from the previous plots we made. The only major difference is that instead of making a histogram I’m making a scatterplot, for which the “geometry” is points rather than histogram bars. Therefore I use geom_point() rather than geom_histogram() for the geometry layer. One new element is the position = position_jitter() part inside geom_point(). Its purpose is to add some random noise to each individual data point, moving it to the left or right a little bit along the x-axis. This is helpful here since there are many data points but only 5 possible answers along each axis. Try making the graph without including the jitter; it’ll just look like a grid of points. Any pattern in the data will likely be hard to see. It may seem counterintuitive to change the data by adding randomness, but for the purposes of the visualization, doing so actually makes any patterns easier to detect.\nLooking at the scatterplot, you can see horizontal bands which correspond to those big spikes on the feeling thermometer that the histogram revealed. Consistent with the correlation coefficient which was close to zero with a nonsignificant \\(p\\)-value, visually it doesn’t look like there’s much of an association between the feeling thermometer responses and extraversion scores.",
    "crumbs": [
      "Project 2: Correlation",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Analysis</span>"
    ]
  },
  {
    "objectID": "correlation_3_anes.html#footnotes",
    "href": "correlation_3_anes.html#footnotes",
    "title": "8  Analysis",
    "section": "",
    "text": "The ggplot2 package is part of the tidyverse, so because we already ran library(tidyverse) earlier the ggplot2 functions are already available to us. If you needed to, you could always run library(ggplot2) to activate it separately.↩︎\nRemember that, by convention, psychologists generally use \\(\\alpha = .05\\) as the criterion for statistical significance, meaning that if our data has less than a 5% chance of occurring under the null hypothesis we reject the null and tentatively accept the alternative hypothesis that the variables are associated.↩︎",
    "crumbs": [
      "Project 2: Correlation",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Analysis</span>"
    ]
  },
  {
    "objectID": "correlation_4_anes.html",
    "href": "correlation_4_anes.html",
    "title": "9  Presentation & report",
    "section": "",
    "text": "Presentation",
    "crumbs": [
      "Project 2: Correlation",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Presentation & report</span>"
    ]
  },
  {
    "objectID": "correlation_4_anes.html#presentation",
    "href": "correlation_4_anes.html#presentation",
    "title": "9  Presentation & report",
    "section": "",
    "text": "Guide to presenting\nEach team will give a short presentation which should encapsulate the motivation, methods, anticipated findings, and interpretation of your proposed project. Aim for clarity, conciseness, and being bold to spark the audience’s interest in your topic and findings.\nAvoid simply reading excerpts from your paper. That would be boring, and would probably take up too many words. Make it fun and interesting. Try to grab the audience’s attention and hit them with just the most important points of your ideas.\nMake your slides count. You can’t just cram a load of text on there, because nobody will be able to read it. Plus, it’d distract from what you’re saying. Make it a visual aid that somehow supports or clarifies what you’re saying. It might be a visual representation of your design, a key piece of your experimental stimuli, a graph of your expected results, or just a pertinent meme which conveys the motivation for your question.\nAfter your presentation the group will take a few questions from the audience, and your responsiveness will contribute toward your grade as well as the quality of your presentation itself (remember a perfectly acceptable answer if often: “Good question; I don’t know the answer! But here are some thoughts…”). It’s not usually an issue, but just in case your audience is left speechless, I suggest coming with a couple of questions or thoughts of your own that you can throw at the audience to spark more questions (“You might be wondering…”).\nIt is up to each group to decide how to divide up the talk, and to practice to make sure the presentation is to time.\n\n\nGuide to watching presentations\nAs an audience member, you are still being graded for class participation. That means giving everyone else’s presentation the attention and enthusiasm it deserves, and rewarding their hard work with questions. (Going to the trouble of putting together a presentation only for nobody to have anything to say about it is not a good feeling.)\nGood questions to ask are things like “Could you clarify X”, “Had you considered Y”, or “How might this relate to Z.” One reason for presenting your project is to hopefully get some useful feedback from the audience with which to refine your final paper, so try to give the kind of feedback you hope to receive.",
    "crumbs": [
      "Project 2: Correlation",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Presentation & report</span>"
    ]
  },
  {
    "objectID": "correlation_4_anes.html#sec-report",
    "href": "correlation_4_anes.html#sec-report",
    "title": "9  Presentation & report",
    "section": "Written report",
    "text": "Written report\nYou will produce a miniature research paper reporting your project. Note that each team member will produce their own individual report; even though the project has been collaborative, your write up will be your own.\n\nFormat\nYour report should consist of the following sections:\n\nIntroduction (two or three paragraphs, including summary of relevant research and hypothesis)\nMethod (a description of the variables you selected, the number of valid responses, and any other information about the procedures that generated the data that you think necessary to report)\nResults (a technical report of any descriptive statistics, figures, and statistics you produced)\nDiscussion (a paragraph or two interpreting your results and drawing conclusions)\n\n\n\nDeadline\nThe report is due by the next class (see late policy from Syllabus 1.2.2).\n\n\nGrading\nYou will receive a score out of 100 for your report. See Appendix E for general qualitative criteria which will be assessed in the context of the expectations detailed above.",
    "crumbs": [
      "Project 2: Correlation",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Presentation & report</span>"
    ]
  },
  {
    "objectID": "regression_1_anes.html",
    "href": "regression_1_anes.html",
    "title": "10  Project planning",
    "section": "",
    "text": "Goals",
    "crumbs": [
      "Project 3: Regression",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Project planning</span>"
    ]
  },
  {
    "objectID": "regression_1_anes.html#project-overview",
    "href": "regression_1_anes.html#project-overview",
    "title": "10  Project planning",
    "section": "Project overview",
    "text": "Project overview\nWith this project, you will dive deeper into the interplay between personality traits and other constructs, using multiple regression analysis to explore how several predictors are associated with an outcome of your choice. Multiple regression allows us to see the cumulative impact of multiple variables on an outcome variable, potentially revealing more complexity than the one-to-one correlations of Project 1.\nFor instance, researchers might examine how age along with one or more Big Five personality traits predict job satisfaction. Similarly, variables such as income, education, and openness might be used in a multiple regression analysis to predict political ideology. Like with correlations, this doesn’t mean that every extroverted, conscientious, and emotionally stable person will be highly satisfied with their job, or that all educated, open individuals are politically aligned in the same way. It’s about general tendencies rather than strict rules.\nLike correlation, regression studies involve determining which psychological constructs to study, how to operationally define those constructs, and how to measure them. As you saw in Project 1, the operational definitions have already been determined–the survey designers already asked the questions. But it will be up to you to make sense of what psychological constructs those operational definitions really represent and to consider the strengths, limitations, and implications for your analysis and interpretation.\n\nStep 1. Choose your variables\nWe will again use data from the 2016 ANES survey. For your regression, you will still have a single outcome variable; however unlike the correlation analysis you did before, this time you will have more than one predictor. Again, the full dataset has more than 1,800 variables so I’m going to constrain your choices; however, this time I’m giving you more freedom to select an outcome variable that most interests you.\nYour predictor variables will be at least two of the Big Five traits:\n\nExtraversion (V162333 & V162338)\nAgreeableness (V162334 & V162339)\nConscientiousness (V162335 & V162340)\nEmotional stability1 (V162336 & V162341)\nOpenness (V162337 & V162342)\n\nYour outcome variable will be any one of the feeling thermometer questions. Here are all the subjects of feeling thermometer variables you can choose from:\n\n\nDemocratic Presidential Cand (V161086)\n\n\nRepublican Presidential Cand (V161087)\n\n\nLibertarian Presidential Cand (V161088)\n\n\nGreen Party Presidential Cand (V161089)\n\n\nDemocratic Vice-Pres Cand (V161090)\n\n\nRepublican Vice-Pres Cand (V161091)\n\n\nPrevious President (V161092)\n\n\nBill Clinton (V161093)\n\n\nLibertarian Vice-Pres Cand (V161094)\n\n\nDemocratic Party (V161095)\n\n\nRepublican Party (V161096)\n\n\nDemocratic Presidential Candidate (V162078)\n\n\nRepublican Presidential Candidate (V162079)\n\n\nLibertarian Presidential Candidate (V162080)\n\n\nGreen Party Presidential Candidate (V162081)\n\n\nHouse Democratic Candidate (V162082)\n\n\nHouse Republican Candidate (V162083)\n\n\nHouse Ind/3rd-Party Candidate (V162084)\n\n\nSenate Democratic Candidate (V162085)\n\n\nSenate Republican Candidate (V162086)\n\n\nSenate Ind/3rd-Party Candidate (V162087)\n\n\nSr. Senator In State Without Race (V162088)\n\n\nJr. Senator In State Without Race (V162089)\n\n\nNonrunning Senator In State W/Race (V162090)\n\n\nDemocratic Vice Presidential Cand (V162091)\n\n\nRepublican Vice Presidential Cand (V162092)\n\n\nJohn Roberts (V162093)\n\n\nPope Francis (V162094)\n\n\nChristian Fundamentalists (V162095)\n\n\nFeminists (V162096)\n\n\nLiberals (V162097)\n\n\nLabor Unions (V162098)\n\n\nPoor People (V162099)\n\n\nBig Business (V162100)\n\n\nConservatives (V162101)\n\n\nThe U.s. Supreme Court (V162102)\n\n\nGay Men And Lesbians (V162103)\n\n\nCongress (V162104)\n\n\nRich People (V162105)\n\n\nMuslims (V162106)\n\n\nChristians (V162107)\n\n\nJews (V162108)\n\n\nTea Party (V162109)\n\n\nPolice (V162110)\n\n\nTransgender People (V162111)\n\n\nScientists (V162112)\n\n\nBlack Lives Matter (V162113)\n\n\nAsian-Americans (V162310)\n\n\nHispanics (V162311)\n\n\nBlacks (V162312)\n\n\nIllegal Immigrants (V162313)\n\n\nWhites (V162314)\n\n\n\n\nStep 2. Find relevant research\nAs with the previous projects, your approach and expectations should be informed by what has come before. Previously you didn’t have so much choice of variables so I was able to point you to some relevant research. This time you have a wider choice so you’ll have to find relevant research yourself about these (or related) personality traits. In particular, what psychological construct(s) do you think your feeling thermometer variable might reflect or relate to?\n\nWhat to look for\nA published, scholarly journal article detailing an empirical finding relevant to your variables of interest. This might be a paper reporting one or several individual studies that the researchers conducted, or it may be a review paper or meta-analysis.2\n\n\nWhere to look\n\nGoogle Scholar\nGoogle Scholar searches the full text of scholarly articles. It casts a wide net, searching across all disciplines, and including books and other materials in addition to journal articles, so will likely find many articles not very relevant to the topic as well as those that are relevant.\n\n\nAPA PsycINFO\nThe link above should take you to PsycINFO, a database for scholarly psychology research (you can also search for psycinfo in a CLIO quicksearch). PsycInfo gives you the ability to do more focused searching than Google Scholar.\n\nYou can add many keywords and combine them with the Boolean operators AND, OR, and NOT by selecting them from the dropdown boxes.\nYou can select where your keywords should appear, i.e. in the title, abstract, or full text of articles. Selecting Word in Major Subject Heading can help narrow down your search to articles that are actually on the topic you’re interested in (rather than just containing the keyword).\n\n\n\n\n\nStep 3. Articulate your design and hypothesis\nAs before, you should be able to state your:\n\nOperational definitions (that is, the specific questions that participants were asked, per the codebook)\nThe constructs that those operational definitions measure\nYour hypotheses\n\nThe hypotheses are formal statements of your expectations about how the predictors are associated with the outcome variable, and will be tested quantitatively by computing the regression model. The general hypothesis of a multiple regression is that there is a relationship between the predictor variables and the outcome variable; in other words, all the predictors combined allow us to predict scores on the outcome more accurately than you would expect if the predictors were unrelated to the outcome. This is referred to as the test of ‘overall model fit’. You can also hypothesize about each individual predictor; you may expect some predictors to be more strongly predictive of the outcome variable than others, or you might even expect certain predictors to be unrelated to the outcome.",
    "crumbs": [
      "Project 3: Regression",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Project planning</span>"
    ]
  },
  {
    "objectID": "regression_1_anes.html#footnotes",
    "href": "regression_1_anes.html#footnotes",
    "title": "10  Project planning",
    "section": "",
    "text": "This is generally referred to as Neuroticism, but the TIPI quantifies the trait such that higher scores indicate the inverse of neuroticism, i.e. emotional stability.↩︎\nA meta-analysis pools the findings of many individual studies by different researchers into a single analysis.↩︎",
    "crumbs": [
      "Project 3: Regression",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Project planning</span>"
    ]
  },
  {
    "objectID": "regression_2_anes.html",
    "href": "regression_2_anes.html",
    "title": "11  Data preparation",
    "section": "",
    "text": "Goals",
    "crumbs": [
      "Project 3: Regression",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Data preparation</span>"
    ]
  },
  {
    "objectID": "regression_2_anes.html#data-preparation",
    "href": "regression_2_anes.html#data-preparation",
    "title": "11  Data preparation",
    "section": "Data preparation",
    "text": "Data preparation\nBuilding on the correlation example, we will include additional variables of interest - conscientiousness and agreeableness - to examine how these factors, along with extraversion, collectively predict feelings towards the Democratic party. Similar to the correlation project, we will start by cleaning and filtering the data, recoding the negatively-worded TIPI items (taking care to note which ones need recoding; it’s not always the second question), and computing mean scores for each Big 5 trait.\nHere is the pipeline to prepare the data:\n\nlibrary(tidyverse)\nlibrary(anesr)\ndata(timeseries_2016)\n\nmy_data_complete &lt;- timeseries_2016 |&gt; \n  select(extraversion1 = \"V162333\", \n         extraversion2 = \"V162338\",\n         conscientiousness1 = \"V162335\", \n         conscientiousness2 = \"V162340\",\n         agreeableness1 = \"V162334\", \n         agreeableness2 = \"V162339\",\n         feeling_thermometer = \"V161095\") |&gt; \n  filter(if_all(everything(), ~ . &gt;= 0))  |&gt;\n  mutate(extraversion2 = 8 - extraversion2,\n         conscientiousness2 = 8 - conscientiousness2,\n         agreeableness1 = 8 - agreeableness1,\n         extraversion_mean = rowMeans(across(contains(\"extraversion\"))),\n         conscientiousness_mean = rowMeans(across(contains(\"conscientiousness\"))),\n         agreeableness_mean = rowMeans(across(contains(\"agreeableness\"))))",
    "crumbs": [
      "Project 3: Regression",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Data preparation</span>"
    ]
  },
  {
    "objectID": "regression_2_anes.html#describing-your-variables",
    "href": "regression_2_anes.html#describing-your-variables",
    "title": "11  Data preparation",
    "section": "Describing your variables",
    "text": "Describing your variables\nJust as in the previous lab, you’ll need to compute the mean and standard deviation for each of your variables. Use the same process, replacing the variable names with your new ones:\n\nmy_data_complete |&gt;\n  pivot_longer(everything(), \n               names_to = \"variable\", \n               values_to = \"value\", \n               values_transform = as.numeric) |&gt; \n  group_by(variable) |&gt; \n  summarize(count_valid = n(),\n            mean = mean(value), \n            sd = sd(value))\n\n# A tibble: 10 × 4\n   variable               count_valid  mean    sd\n   &lt;chr&gt;                        &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 agreeableness1                3530  4.73  1.67\n 2 agreeableness2                3530  5.68  1.23\n 3 agreeableness_mean            3530  5.21  1.14\n 4 conscientiousness1            3530  5.99  1.16\n 5 conscientiousness2            3530  5.41  1.54\n 6 conscientiousness_mean        3530  5.70  1.12\n 7 extraversion1                 3530  4.79  1.58\n 8 extraversion2                 3530  3.65  1.77\n 9 extraversion_mean             3530  4.22  1.38\n10 feeling_thermometer           3530 48.3  30.0",
    "crumbs": [
      "Project 3: Regression",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Data preparation</span>"
    ]
  },
  {
    "objectID": "regression_2_anes.html#visualizing-the-data",
    "href": "regression_2_anes.html#visualizing-the-data",
    "title": "11  Data preparation",
    "section": "Visualizing the data",
    "text": "Visualizing the data\nYou can create histograms for each of your new variables, just like you did for extraversion. Since there are so many, rather than producing individual plots, I’m going to use the pivot_longer(), like we’ve done before grouping and summarizing several variables. In this case, however, we won’t summarize(). Instead, the long-formatted data gets piped into ggplot(), and a facet_wrap() layer is added. That produces several sub-plots (“facets”) based on the formula provided within the function. In this case, I want subplots for each different variable (the column with the names of the different variables), so the formula is just ~variable. So the whole layer can be read as “facet wrap the plots by the different values of the”variable” column.”\n\nmy_data_complete |&gt;\n  select(extraversion1:agreeableness2) |&gt; \n  pivot_longer(everything(), \n               names_to = \"variable\", \n               values_to = \"value\", \n               values_transform = as.numeric) |&gt; \n  ggplot(aes(x = value)) +\n  facet_wrap(~variable, nrow = 3) +\n  geom_histogram(binwidth = 1, color = \"white\") +\n  scale_x_continuous(breaks = 1:7) +\n  theme_apa\n\n\n\n\n\n\n\n\nNow I’ll do the same for the 3 computed trait-means.\n\nmy_data_complete |&gt;\n  select(contains(\"mean\")) |&gt; \n  pivot_longer(everything(), \n               names_to = \"variable\", \n               values_to = \"value\", \n               values_transform = as.numeric) |&gt; \n  ggplot(aes(x = value)) +\n  facet_wrap(~variable, nrow = 3) +\n  geom_histogram(binwidth = 0.5, color = \"white\") +\n  scale_x_continuous(breaks = 1:7) +\n  theme_apa\n\n\n\n\n\n\n\n\nLastly, you’ll make a histogram for your feeling thermometer. I’ll leave this as a exercise for you, since the code for this single graph will be very close to what you did in Project 1 (i.e., since you’re just graphing a single variable you won’t need to pivot_longer() here.",
    "crumbs": [
      "Project 3: Regression",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Data preparation</span>"
    ]
  },
  {
    "objectID": "regression_3_anes.html",
    "href": "regression_3_anes.html",
    "title": "12  Analysis",
    "section": "",
    "text": "Goals",
    "crumbs": [
      "Project 3: Regression",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Analysis</span>"
    ]
  },
  {
    "objectID": "regression_3_anes.html#visualization",
    "href": "regression_3_anes.html#visualization",
    "title": "12  Analysis",
    "section": "Visualization",
    "text": "Visualization\nPreviously, we visualized a bivariate correlation using a scatterplot. One way of visualizing a regression when the predictors are all measured on the same scale (as they are in this project) is to essentially produce several scatterplots overlaid on top of one another. The outcome variable will always be on the Y axis, and the values of the predictors on the X axis. Color (or some other aesthetic) is used to differentiate the different predictors.\nThis can be achieved by reshaping the data into long-format as we have done before. Here, however, as a parameter in pivot_longer() I specify -feeling_thermometer, meaning I want every column except the feeling thermometer to be pivoted longer. That keeps feeling_thermometer as a unique column of its own, duplicating its value across rows for each of the three predictor variables. The reshaped data can then be piped into ggplot().\n\nmy_data_complete |&gt; \n  select(feeling_thermometer, contains(\"mean\")) |&gt; \n  pivot_longer(-feeling_thermometer) |&gt; \n  ggplot(aes(x = value, y = feeling_thermometer, color = name)) +\n  geom_point(position = position_jitter(width = 0.4, seed = 1), alpha = 0.3) +\n  geom_smooth(method = \"lm\") + \n  theme_apa\n\nDon't know how to automatically pick scale for object of type &lt;haven_labelled&gt;.\nDefaulting to continuous.\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nThis kind of visualization doesn’t map on to the regression model perfectly; it essentially shows three bivariate correlations, while the regression model, in quantifying the relationship between each predictor and the outcome, also controls for the relationship between the predictor and the other predictors in the model. And with more than 3 or so predictors it can get visually messy and hard to easily interpret. For this project’s design, however, it seems an appropriate choice.",
    "crumbs": [
      "Project 3: Regression",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Analysis</span>"
    ]
  },
  {
    "objectID": "regression_3_anes.html#analysis",
    "href": "regression_3_anes.html#analysis",
    "title": "12  Analysis",
    "section": "Analysis",
    "text": "Analysis\n\nComputing regression in R\nNow we’ll compute the regression model. The model quantifies the relationship between the single outcome variable (in this case, feeling_thermometer) and several independent variables (extraversion_mean, conscientiousness_mean, and agreeableness_mean).\nThe lm() function compute a linear model. The first argument is a formula with the generic form outcome ~ predictor_1 + predictor_2 + predictor_3 ..., where those generic names will be replaced with the relevant column names from your data.frame. The second argument is data; the formula specifies the names of columns in a data.frame where the relevant values can be found, therefore the data = argument is necessary to point R to the data.frame containing those columns.\nBy itself, the lm() function doesn’t output all the information we need to report about the regression model. That’s why I pipe the output of lm() into the summary() function, which outputs all the necessary information to the console.\n\nlm(feeling_thermometer ~ extraversion_mean + conscientiousness_mean + agreeableness_mean, \n   data = my_data_complete) |&gt; \n  summary()\n\n\nCall:\nlm(formula = feeling_thermometer ~ extraversion_mean + conscientiousness_mean + \n    agreeableness_mean, data = my_data_complete)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-54.523 -24.494   2.127  22.216  55.932 \n\nCoefficients:\n                        Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)            51.218290   3.342704  15.322  &lt; 2e-16 ***\nextraversion_mean      -0.006588   0.369615  -0.018 0.985780    \nconscientiousness_mean -1.633627   0.476950  -3.425 0.000621 ***\nagreeableness_mean      1.234787   0.465963   2.650 0.008086 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 29.96 on 3526 degrees of freedom\nMultiple R-squared:  0.00422,   Adjusted R-squared:  0.003373 \nF-statistic: 4.981 on 3 and 3526 DF,  p-value: 0.001893\n\n\n\n\n\n\nInterpreting the results\nUnder “Coefficients” you’ll see an “Estimate” of the relationship between that predictor and the outcome variable, controlling for the other predictors. You’ll also see a \\(t\\)-value and a \\(p\\)-value for each predictor, which tell you whether each predictor is significantly related to the outcome variable, controlling for the other predictors. The Estimate indicates how much the outcome variable changes on average with a one-unit increase in the predictor, holding all other predictors constant. So in this example, a one-point increase in conscientiousness predicts a \\(~1.6\\) unit decrease on the feeling thermometer. A one-point increase in agreeableness predicts a \\(~1.2\\) unit increase on the feeling thermometer. Both of these predictors are significantly associated with the feeling thermometer variable. Extraversion, however, is not a significant predictor; knowledge of somebody’s extraversion score cannot reliably predict their feeling thermometer response.\nThe last part of the output gives the overall model fit. “Multiple R-squared” is the proportion of variance in the outcome variable that can be explained by the predictor variables, and Adjusted R-squared is a version of R-squared adjusted for the number of predictors.\nFinally, the \\(F\\)-statistic and its corresponding \\(p\\)-value assess the overall statistical significance of the model. If the \\(p\\)-value is less than your desired significance level you can reject the null hypothesis that all the regression coefficients are zero.",
    "crumbs": [
      "Project 3: Regression",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Analysis</span>"
    ]
  },
  {
    "objectID": "regression_4_anes.html",
    "href": "regression_4_anes.html",
    "title": "13  Presentation & report",
    "section": "",
    "text": "Presentation\nThe guide to delivering an effective presentation is the same as last time. My main advice this time is to focus on making your interpretation of the combined and individual relationships between predictors and outcome as clear and convincing as possible. This complexity can be tricky to get your head around, and even trickier to explain to someone else. The best presentations will make the logic of your regression model and its results as easy to follow as possible.",
    "crumbs": [
      "Project 3: Regression",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Presentation & report</span>"
    ]
  },
  {
    "objectID": "regression_4_anes.html#sec-report",
    "href": "regression_4_anes.html#sec-report",
    "title": "13  Presentation & report",
    "section": "Written report",
    "text": "Written report\nYou will again produce a miniature research paper reporting your project. Note that each team member will produce their own individual report; even though the project has been collaborative, your write up will be your own.\n\nFormat\nYour report should consist of the following sections:\n\nIntroduction (two or three paragraphs, including the general research question; summary of relevant research; and hypothesis)\nMethod (a description of your variables, the number of valid responses, and any other information about the procedures that generated the data that you think necessary to report)\nResults (a technical report of any descriptive statistics, figures, and statistics you produced)\nDiscussion (a paragraph or two interpreting your results and drawing conclusions)\n\n\n\nDeadline\nThe report is due by the next class (see late policy from Syllabus 1.2.2).",
    "crumbs": [
      "Project 3: Regression",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Presentation & report</span>"
    ]
  },
  {
    "objectID": "regression_4_anes.html#grading",
    "href": "regression_4_anes.html#grading",
    "title": "13  Presentation & report",
    "section": "Grading",
    "text": "Grading\nAs before you will receive a scores out of 100 for your presentation and report. See Appendix E for general qualitative criteria which will be assessed in the context of the expectations detailed above.",
    "crumbs": [
      "Project 3: Regression",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Presentation & report</span>"
    ]
  },
  {
    "objectID": "appendix-r-basics.html",
    "href": "appendix-r-basics.html",
    "title": "Appendix A — Getting started with R",
    "section": "",
    "text": "posit.cloud\nYou will use posit.cloud to write R code and work with data in RStudio. To use it you’ll just need to sign up for a free account.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Getting started with R</span>"
    ]
  },
  {
    "objectID": "appendix-r-basics.html#posit.cloud",
    "href": "appendix-r-basics.html#posit.cloud",
    "title": "Appendix A — Getting started with R",
    "section": "",
    "text": "Let’s do something cool\nOnce you have a posit.cloud account, click this link.\nOnce the project is up and running, click on anes.R in the bottom-right pane to open some analysis code.\n\n\nWait, what are you talking about?\nThere are a few different names involved here, so to try and clear things up:\n\nR is a coding language\nRStudio is a software interface for using R\nPosit is the name of the company that makes RStudio\nposit.cloud provides a way of using RStudio in your web browser\n\nYou can install R and RStudio on your own computer for free and do things that way, but using the cloud-based RStudio via posit.cloud simplifies things immensely.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Getting started with R</span>"
    ]
  },
  {
    "objectID": "appendix-r-basics.html#fundamentals-of-r-for-data-analysis",
    "href": "appendix-r-basics.html#fundamentals-of-r-for-data-analysis",
    "title": "Appendix A — Getting started with R",
    "section": "Fundamentals of R for data analysis",
    "text": "Fundamentals of R for data analysis\nR is a programming language well-suited to interactive data exploration and analysis. It might seem daunting if you’ve have no experience with coding, but the basic idea is that you have some data, like you are familiar with from a regular Excel or Google Sheets spreadsheet, and you perform operations on your data using functions a lot like you would in Excel/Sheets. For example, you might compute an average in Sheets by typing =AVERAGE(A1:A10). In R you might type mean(my_data$column_a). The specifics of the function names are different, but the basic idea is the same.\nHere are some of the basics to help you get started coding in R.\n\nRStudio\nRStudio is the interface we’ll use to write and run R code and see its output. The interface has 4 panels, each with a few tabs:\n\n\nTop-left: Code editor / data viewer\n\nYou will type code here\nYou can run a line of code by clicking on it and pressing Ctrl/Cmd + Enter on your keyboard\n\nBottom-left: R console\n\nYou can type code directly and run it by pressing enter.\nYou won’t be saving your code as a document like when you type in in the editor, so this is useful for just testing something before you commit it to your working document\n\nTop-right: Environment\n\nAs you excute code you may be creating objects like sets of numbers of data.frames. Those objects will appear here.\nYou can click the name of some objects, like data.frames, and it will open a view of the data as a tab in the editor pane\n\nBottom-right: Files/folders, plot viewer, help window\n\nYou can navigate the file tree, and you will see any plots you create appear here\n\n\n\n\nAssignment\nR has a fancy assignment operator: &lt;-.1 You assign things to a name by typing something like:\n\nname &lt;- thing\n\nThe thing there might be a set of numbers, an entire dataset, or something else. Giving it a name allows to you perform subsequent operations more easily, and choosing appropriate names makes your code easier to understand.\n\noriginal_numbers &lt;- 1:10\noriginal_numbers\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\ndoubled_numbers &lt;- original_numbers * 2\ndoubled_numbers\n\n [1]  2  4  6  8 10 12 14 16 18 20\n\n\n\n\nFunctions\nAlmost everything happens inside functions.\n\nmean(original_numbers)\n\n[1] 5.5\n\nmean(doubled_numbers)\n\n[1] 11\n\n\nYou can also nest functions inside one another.\n\nsqrt(mean(original_numbers))\n\n[1] 2.345208\n\n\nA function generally has one or more “arguments”, to which you supply parameters. For example, the mean() function’s first argument is the set of numbers you want to compute the mean of; in the previous examples original_numbers and doubled_numbers were the parameters I supplied. You don’t necessarily have to type the name of the argument, but it can be helpful. The seq() function, for example, produces a sequence of numbers according to three arguments, from, to, and by.\n\nseq(from = 1, to = 10, by = 2)\n\n[1] 1 3 5 7 9\n\n\nWhen you don’t type the names of the arguments, R matches them by position, so this gives exactly the same output as the previous line of code:\n\nseq(1, 10, 2)\n\n[1] 1 3 5 7 9\n\n\nYou can get help with a function (to see what arguments it accepts, for example) by typing a question mark followed by the function name (without parentheses) in your console.\n\n?mean\n\nRunning the code will bring up the function’s help documentation in RStudio’s Help pane.\n\n\nPiping\nYou can string together different operations in a pipeline using the pipe operator: |&gt;.2 The result of each line of code gets “piped” into the function on the next line as its first argument. For example, below I take some data (named data) and perform a series of operations, first selecting a subset of columns, then filtering rows based on whether the values in certain columns meet specified criteria, then I create (mutate) a new column averaging across existing columns; and lastly, I summarize the new column down to an average value.\n\ndata |&gt; \n  select(column_a, column_b) |&gt; \n  filter(if_all(c(column_a, column_b), ~!is.na(.))) |&gt; \n  mutate(column_c = rowSums(across(everything()))) |&gt; \n  summarize(mean_sum = mean(column_c))\n\nThere’s a lot going on there, and the specifics will become clearer as we work though this project. But using the pipe operator this way can make for relatively readable code.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Getting started with R</span>"
    ]
  },
  {
    "objectID": "appendix-r-basics.html#footnotes",
    "href": "appendix-r-basics.html#footnotes",
    "title": "Appendix A — Getting started with R",
    "section": "",
    "text": "Most other coding languages tend to use a boring = for assignment. Sure it’s nice not having to type an extra character, but there’s a keyboard shortcut to quickly add an &lt;- in RStudio: Option/Alt + -. And philosophically, the &lt;- arrow conveys the inherent directionality of the assignment operation. The object is assigned to the name; the object and its name are not equal and so the = arguably gives a misleading impression of the two things being one and the same. (Also, to let you in on a secret, = also works for assignment in R.)↩︎\nIf you’re looking at R code from beyond this handbook (e.g. looking up help elsewhere) you may see a different pipe: %&gt;%. The |&gt; pipe, called the “native” pipe, was only included as a feature of base R relatively recently. Until then, the %&gt;% pipe was provided by an external package (called magrittr. Get it?). In practice the pipes work similarly, so you can often just replace %&gt;% with |&gt; and it’ll work fine, but it’s worth being aware of.↩︎",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Getting started with R</span>"
    ]
  },
  {
    "objectID": "appendix-t-test.html",
    "href": "appendix-t-test.html",
    "title": "Appendix B — \\(t\\)-test",
    "section": "",
    "text": "Types of \\(t\\)-tests\nThere are three main types of \\(t\\)-tests:",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>$t$-test</span>"
    ]
  },
  {
    "objectID": "appendix-t-test.html#types-of-t-tests",
    "href": "appendix-t-test.html#types-of-t-tests",
    "title": "Appendix B — \\(t\\)-test",
    "section": "",
    "text": "Single-sample \\(t\\)-test: compares the mean of a single group to a known value or population mean.\nIndependent samples \\(t\\)-test: compares the means of two independent groups.\nPaired samples \\(t\\)-test: compares means from the same group at different times (e.g., before and after a treatment).",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>$t$-test</span>"
    ]
  },
  {
    "objectID": "appendix-t-test.html#calculating-the-t-statistic",
    "href": "appendix-t-test.html#calculating-the-t-statistic",
    "title": "Appendix B — \\(t\\)-test",
    "section": "Calculating the t-statistic",
    "text": "Calculating the t-statistic\nFor an independent samples \\(t\\)-test, the formula for the \\(t\\)-statistic is:\n\\[\nt = \\frac{(M_1 - M_2)}{\\sqrt{\\frac{S^2_1}{n_1} + \\frac{S^2_2}{n_2}}}\n\\]\nWhere:\n\n\\(M_1\\) and \\(M_2\\) are the means of the two groups.\n\\(S^2_1\\) and \\(S^2_2\\) are the variances of the two groups.\n\\(n_1\\) and \\(n_2\\) are the sample sizes of the two groups.\n\nThis formula essentially measures the difference between the group means relative to the variability of the scores within each group.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>$t$-test</span>"
    ]
  },
  {
    "objectID": "appendix-t-test.html#interpreting-the-t-statistic",
    "href": "appendix-t-test.html#interpreting-the-t-statistic",
    "title": "Appendix B — \\(t\\)-test",
    "section": "Interpreting the \\(t\\)-statistic",
    "text": "Interpreting the \\(t\\)-statistic\nAfter calculating the \\(t\\)-statistic, you compare it to a critical value from the \\(t\\)-distribution table, which depends on your chosen significance level (typically \\(0.05\\)) and the degrees of freedom. If your calculated \\(t\\)-value exceeds the critical value, you reject the null hypothesis (which states that there is no difference between the group means).",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>$t$-test</span>"
    ]
  },
  {
    "objectID": "appendix-t-test.html#confidence-intervals",
    "href": "appendix-t-test.html#confidence-intervals",
    "title": "Appendix B — \\(t\\)-test",
    "section": "Confidence Intervals",
    "text": "Confidence Intervals\nFor each point estimate–that is, each group mean–a confidence interval (CI) can be calculated. The CI quantifies the uncertainty around that point estimate, providing a margin of error (a range of values) around the point estimate. The CI is about long-run probabilities; if samples were repeatedly drawn from the same population, 95% of the sample CIs would include the true population parameter. For example, if the population average extraversion score for every Leo was really \\(\\mu = 3.25\\), then 95% of 95% CIs would include \\(M = 3.25\\) within their range.\nOf course we only have a single CI for each group, so they are used to help clarify the binary decision to reject (or fail to reject) the null hypothesis; if the CIs for two groups overlap, then the data does not provide sufficient evidence of a difference between the groups to reject the null hypothesis. If the CIs do not overlap, we reject the null hypothesis.\n\\[\nM \\pm t_{critical} \\times \\sqrt{\\frac{s^2}{n} }\n\\]\nWhere:\n\n\\(M\\) is the sample mean.\n\\(t_{critical}\\) is the critical value from the \\(t\\)-distribution for your chosen significance level.\n\\(s^2\\) is the sample’s standard deviation squared (i.e. variance).\n\\(n\\) is the sample size.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>$t$-test</span>"
    ]
  },
  {
    "objectID": "appendix-t-test.html#effect-size-for-t-tests",
    "href": "appendix-t-test.html#effect-size-for-t-tests",
    "title": "Appendix B — \\(t\\)-test",
    "section": "Effect size for \\(t\\)-tests",
    "text": "Effect size for \\(t\\)-tests\nThe effect size for a \\(t\\)-test is often measured using Cohen’s d, which standardizes the difference between the means. the formula is:\n\\[\nd = \\frac{M_1 - M_2}{\\sqrt{\\frac{(S^2_1 + S^2_2)}{2}}}\n\\]\nCohen suggested the following thresholds for interpreting \\(d\\):\n\n0.2 = small effect\n0.5 = medium effect\n0.8 = large effect\n\nHowever, context matters, and these rules of thumb might not always apply. It’s crucial to consider the practical significance and the specific field of study.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>$t$-test</span>"
    ]
  },
  {
    "objectID": "appendix-t-test.html#summary",
    "href": "appendix-t-test.html#summary",
    "title": "Appendix B — \\(t\\)-test",
    "section": "Summary",
    "text": "Summary\nThe \\(t\\)-test is a fundamental tool in statistics for comparing group means. It helps you determine whether observed differences are likely to be real or just due to random chance. By understanding the calculation and interpretation of the \\(t\\)-statistic and effect size, you can make informed decisions about your data.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>$t$-test</span>"
    ]
  },
  {
    "objectID": "appendix-correlation.html",
    "href": "appendix-correlation.html",
    "title": "Appendix C — Correlation",
    "section": "",
    "text": "Calculating the correlation coefficient\nTo calculate the correlation between two variables, you must first calculate the Sum Product, \\(SP\\). The mathematical formula is:\n\\[\nSP = (X-M_X)(Y-M_Y)\n\\]\nNotice that \\(X - M_X\\) and \\(Y - M_Y\\) are deviation scores, just like we calculated for the standard deviation. Here we have two variables, \\(X\\) and \\(Y\\), so the equation is telling us to calculate the deviation of each score from its respective mean. We then multiply each deviation for variable \\(X\\) by its counterpart deviation from variable \\(Y\\). These are the “products,” meaning multiplied deviation scores. Finally, the tells us to add up all those products, giving the “sum of products,” \\(SP\\).\nOnce we have calculated \\(SP\\), the correlation coefficient, symbolized by \\(r\\) is calculated using the following equation:\n\\[\nr = \\dfrac{SP}{\\sqrt{SS_X SS_Y}}\n\\]\nHere, \\(SS_X\\) and \\(SS_Y\\) are the Sums of Squares for each variable. Multiplying them and taking the square root gets us a measure of the variability in \\(X\\) and \\(Y\\) separately. The numerator, \\(SP\\), represents the covariability of \\(X\\) and \\(Y\\). So the equation results in covariability as a proportion of all variability. It can range from \\(-1\\), meaning a perfect negative correlation, to \\(0\\), meaning no correlation at all, to \\(+1\\), meaning a perfect positive correlation.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Correlation</span>"
    ]
  },
  {
    "objectID": "appendix-correlation.html#sec-cor-effect-size",
    "href": "appendix-correlation.html#sec-cor-effect-size",
    "title": "Appendix C — Correlation",
    "section": "Effect size for correlation",
    "text": "Effect size for correlation\nThe correlation coefficient is a measure of effect size. It’s absolute value can range from 0 to 1.\nYou may see some “rules of thumb” about interpreting the “effect size” of correlations in psychology. Cohen (1977) proposed that correlations of less than around \\(\\pm 0.30\\) should be considered weak; around \\(\\pm 0.30\\) to \\(\\pm 0.70\\) considered moderate; and greater than around \\(\\pm 0.70\\) considered large.\nHowever, more recent researchers have proposed more nuanced and empirically-grounded interpretations. Funder and Ozer (2019) proposed the following:\n\n\n\n\n\n\n\n\n\nr\nDescription\n\n\n\n\n0.05\nVery small for the explanation of single events but potentially consequential in longer run\n\n\n0.10\nStill small at the level of single events but potentially more ultimately consequential\n\n\n0.20\nMedium effect of some explanatory and practical use even in the short run\n\n\n0.30\nLarge effect that is potentially powerful in both the short and the long run\n\n\n0.40\nA very large effect in the context of psychological research; likely to be a gross overestimate",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Correlation</span>"
    ]
  },
  {
    "objectID": "appendix-regression.html",
    "href": "appendix-regression.html",
    "title": "Appendix D — Regression",
    "section": "",
    "text": "Calculating Multiple Regression\nThe equation of the regression line in a simple case (with only one predictor) can be represented as:\n\\[\nY = b_0 + b_1X_1\n\\]\nHere, \\(Y\\) is the predicted value of the dependent variable, \\(b_0\\) is the intercept, \\(b_1\\) is the regression coefficient for predictor \\(X_1\\), and \\(X_1\\) is the value of the predictor. The intercept and regression coefficient are calculated such that the overall differences between the observed values of the dependent variable and the predicted values from the model are minimized. This method finds the best-fitting line (plane in multiple dimensions) that minimizes the sum of squared differences between observed and predicted values. This line is often referred to as the best-fit line.\nIn multiple regression, when there are multiple predictors, the equation extends to:\n\\[\nY = b_0 + b_1X_1 + b_2X_2 + \\ldots + b_kX_k\n\\]\nWhere \\(k\\) is the number of predictors.\nTo calculate multiple regression, you use a method that minimizes the differences between the observed values of the dependent variable and the predicted values from the model. This method finds the best-fitting line (plane in multiple dimensions) that minimizes the sum of squared differences between observed and predicted values. This line is often referred to as the regression line or hyperplane.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Regression</span>"
    ]
  },
  {
    "objectID": "appendix-regression.html#evaluating-the-model",
    "href": "appendix-regression.html#evaluating-the-model",
    "title": "Appendix D — Regression",
    "section": "Evaluating the model",
    "text": "Evaluating the model\n\nOverall model fit\nThe effect size for multiple regression is often reported using the \\(F\\)-statistic and its associated \\(p\\)-value. The F-statistic tests whether the overall model is a significant improvement over a model with no predictors. The \\(p\\)-value associated with the \\(F\\)-statistic helps determine whether the predictors, as a group, have a significant effect on the dependent variable.\n\nEffect size\nRemember, as with correlation, understanding the context of the variables you’re working with is crucial. Just like with correlations, effect sizes can be interpreted as small, moderate, or large, based on the context and established benchmarks in your field.\nR-squared (\\(R^2\\)) is a measure that tells you the proportion of the variability in the dependent variable that’s explained by the predictors in the model. It ranges from 0 to 1, where a higher value indicates a better fit. However, adding more predictors can artificially inflate \\(R^2\\), which is why we use adjusted R-squared. Adjusted R-squared takes into account the number of predictors and provides a more accurate representation of model fit.\nThe multiple correlation coefficient, (R), represents the correlation between the observed and predicted values of the outcome. It gives us an idea of how well our set of predictors predicts the outcome together. The square of (R), (R^2), represents the proportion of variance in the outcome that’s explained by the predictors. For example, an (R^2) of 0.40 means that our predictors explain 40% of the variance in the outcome.\nThe (R^2) value is a measure of effect size in multiple regression. Like the correlation coefficient, its value can range from 0 to 1.\nAs a rule of thumb: - (R^2) values of around 0.02 are considered small - (R^2) values of around 0.13 are considered medium - (R^2) values of around 0.26 are considered large\nThis might differ somewhat from the thresholds you’re familiar with for simple correlation because the interpretation is slightly different; here, we’re looking at the proportion of variance explained by all predictors combined.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Regression</span>"
    ]
  },
  {
    "objectID": "appendix-regression.html#interpreting-the-regression-coefficients",
    "href": "appendix-regression.html#interpreting-the-regression-coefficients",
    "title": "Appendix D — Regression",
    "section": "Interpreting the regression coefficients",
    "text": "Interpreting the regression coefficients\nIn multiple regression, we don’t just have a single correlation coefficient. Instead, we have a regression coefficient for each predictor variable, represented as (B). The (B) coefficient tells us about the relationship between the predictor and the outcome when all other predictors are held constant. The mathematical calculations are more complex than for a simple correlation and typically rely on matrix algebra. For our purposes, though, we need to know what the coefficients represent.\nIf (B) is positive, it means that as the predictor increases, the outcome also tends to increase, holding all else constant. If (B) is negative, then as the predictor increases, the outcome tends to decrease. A (B) of zero means the predictor doesn’t have a unique effect on the outcome when considering other predictors.\nThe regression coefficients (\\(b\\) values) represent the change in the dependent variable for a unit change in the corresponding predictor while holding other predictors constant. Positive coefficients indicate a positive relationship, while negative coefficients indicate a negative relationship.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Regression</span>"
    ]
  },
  {
    "objectID": "appendix-rubric.html",
    "href": "appendix-rubric.html",
    "title": "Appendix E — Grading rubric",
    "section": "",
    "text": "For each presentation and project report you will receive a score out of 100 according to the rubric below.\nNote that presentations will be given jointly. In general, grades will be the same for all group members as it is expected that group members will contribute equally to the presentation; however, exceptions may be made when it is clear that group members did not all contribute equally.\nAlso note that even though projects will be a group effort, the written reports will be completed individually.\n\n\n\n\n\n\n\n\nGrade\nPoint range\nDescription\n\n\n\n\nA+\n97-100\nOutstanding and exceptional work. The report clearly articulates the problem, purpose, methods, and results. There is evidence of critical thought, and the report goes beyond the assignment requirements in terms of analysis or presentation. The report demonstrates a sophisticated understanding of the concepts and techniques used. The report is free of errors and is clearly and professionally written.\n\n\nA\n90-97\nExcellent work. The report clearly articulates the problem, purpose, methods, and results. There is evidence of critical thought. The report demonstrates a strong understanding of the concepts and techniques used. The report is virtually free of errors and is clearly and professionally written.\n\n\nB\n80-89\nAbove average work. The report articulates the problem, purpose, methods, and results. There is some evidence of critical thought. The report demonstrates a good understanding of the concepts and techniques used. There are minor errors in the report, but the writing is generally clear and professional.\n\n\nC\n70-79\nSatisfactory work. The report articulates the problem, purpose, methods, and results but may lack clarity or detail. There is minimal evidence of critical thought. The report demonstrates an acceptable understanding of the concepts and techniques used. There are noticeable errors in the report, and the writing could be improved.\n\n\nD\n60-69\nBelow average work. The report does not clearly articulate the problem, purpose, methods, or results. There is little to no evidence of critical thought. The report demonstrates a minimal understanding of the concepts and techniques used. There are significant errors in the report, and the writing is unclear.\n\n\nF\n&lt;60\nUnsatisfactory work. The report does not articulate the problem, purpose, methods, or results. There is no evidence of critical thought. The report demonstrates a lack of understanding of the concepts and techniques used. The report is filled with errors, and the writing is poor.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Grading rubric</span>"
    ]
  },
  {
    "objectID": "t-test_1_zodiac.html#to-do-for-next-time",
    "href": "t-test_1_zodiac.html#to-do-for-next-time",
    "title": "2  Project Planning",
    "section": "To do for next time",
    "text": "To do for next time\nRead up on the development of the TIPI ([Gosling et al., 2003](https://gosling.psy.utexas.edu/wp-content/uploads/2014/09/JRP-03-tipi.pdf)).\nThe more detailed your understanding of how the Big Five trait was measured, the better you will be able to interpret the results of your analysis.",
    "crumbs": [
      "Project 1: $t$-test",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Project Planning</span>"
    ]
  },
  {
    "objectID": "t-test_3_zodiac.html#to-do-for-next-time",
    "href": "t-test_3_zodiac.html#to-do-for-next-time",
    "title": "4  Analysis",
    "section": "To do for next time",
    "text": "To do for next time\nPrepare your presentation! Share your google slides with Prof. Brotherton in advance. See guidelines under next week’s lab section.",
    "crumbs": [
      "Project 1: $t$-test",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Analysis</span>"
    ]
  },
  {
    "objectID": "t-test_2_zodiac.html#to-do-for-next-time",
    "href": "t-test_2_zodiac.html#to-do-for-next-time",
    "title": "3  Data preparation",
    "section": "To do for next time",
    "text": "To do for next time\nRead and take notes on another of the research papers listed under Lab 2.3.1",
    "crumbs": [
      "Project 1: $t$-test",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data preparation</span>"
    ]
  },
  {
    "objectID": "t-test_1_zodiac.html#astrology-references",
    "href": "t-test_1_zodiac.html#astrology-references",
    "title": "2  Project Planning",
    "section": "Step 2. Read relevant research",
    "text": "Step 2. Read relevant research\nReal research doesn’t happen in a vacuum; research plans and expectations should be informed by what has come before. Therefore once you have a general idea for your study, you will see what other researchers have found and refine your plans and expectations based on what you learn.\nA real research project would involve an exhaustive literature review, in which you attempt to find and understand all the research relevant to your question. Since this project of ours is just for practice and our time is limited, you don’t need to read everything. For now, pick one of these papers to skim to give you an idea of what has been found.\n\nClarke, D., Gabriels, T., & Barnes, J. (1996). Astrological signs as determinants of extroversion and emotionality: An empirical study. The Journal of Psychology, 130(2), 131–140. https://doi.org/10.1080/00223980.1996.9914995\nMayo, J., White, O., & Eyesenck, H. J. (1978). An empirical study of the relation between astrological factors and personality. Journal of Social Psychology, 105(2), 229.\nMcGrew, J. H., & McFall, R. M. (1990). A scientific inquiry into the validity of astrology. Journal of Scientific Exploration, 4(1), 75-83.\nSaklofske, D. H., Kelly, I. W., & McKerracher, D. W. (1982). An empirical study of personality and astrological factors. Journal of Psychology, 110(2), 275. https://doi.org/10.1080/00223980.1982.9915349\nSmithers, A. G., & Cooper, H. J. (1978). Personality and season of birth. The Journal of Social Psychology, 105(2), 237-241. https://doi.org/10.1080/00224545.1978.9924120",
    "crumbs": [
      "Project 1: $t$-test",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Project Planning</span>"
    ]
  },
  {
    "objectID": "t-test_1_zodiac.html#sec-astrology-references",
    "href": "t-test_1_zodiac.html#sec-astrology-references",
    "title": "2  Project Planning",
    "section": "Step 2. Read relevant research",
    "text": "Step 2. Read relevant research\nReal research doesn’t happen in a vacuum; research plans and expectations should be informed by what has come before. Therefore once you have a general idea for your study, you will see what other researchers have found and refine your plans and expectations based on what you learn.\nA real research project would involve an exhaustive literature review, in which you attempt to find and understand all the research relevant to your question. Since this project of ours is just for practice and our time is limited, you don’t need to read everything. For now, pick one of these papers to skim to give you an idea of what has been found.\n\nReferences\n\nClarke, D., Gabriels, T., & Barnes, J. (1996). Astrological signs as determinants of extroversion and emotionality: An empirical study. The Journal of Psychology, 130(2), 131–140. https://doi.org/10.1080/00223980.1996.9914995\nMayo, J., White, O., & Eyesenck, H. J. (1978). An empirical study of the relation between astrological factors and personality. Journal of Social Psychology, 105(2), 229.\nMcGrew, J. H., & McFall, R. M. (1990). A scientific inquiry into the validity of astrology. Journal of Scientific Exploration, 4(1), 75-83.\nSaklofske, D. H., Kelly, I. W., & McKerracher, D. W. (1982). An empirical study of personality and astrological factors. Journal of Psychology, 110(2), 275. https://doi.org/10.1080/00223980.1982.9915349\nSmithers, A. G., & Cooper, H. J. (1978). Personality and season of birth. The Journal of Social Psychology, 105(2), 237-241. https://doi.org/10.1080/00224545.1978.9924120",
    "crumbs": [
      "Project 1: $t$-test",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Project Planning</span>"
    ]
  }
]