[
  {
    "objectID": "index.html#course-details",
    "href": "index.html#course-details",
    "title": "Personality Psychology Lab Handbook",
    "section": "Course details",
    "text": "Course details\nPre-requisites: PSYC BC1001 Introduction to Psychology; PSYC BC1101 Statistics; PSYC BC 1024 Research Methods\nCo-requisite: PSYC BC2125 Personality Psychology\n\nTime, venue & instructor\nSection 001: Monday 10:10-1PM, Milbank 410\nSection 002: Monday 1:10-4:00PM, Milbank 410\nInstructor: Dr. Rob Brotherton (rbrother@barnard.edu)\nOffice hour: TBC"
  },
  {
    "objectID": "index.html#course-overview",
    "href": "index.html#course-overview",
    "title": "Personality Psychology Lab Handbook",
    "section": "Course overview",
    "text": "Course overview\nThis lab will usually be taken concurrently with BC2125 Personality lecture. It will expand upon some of the theoretical, methodological and analytic issues introduced there, as well as giving you the opportunity to explore topics of your choosing from within (or beyond) those covered in the lectures in greater depth through hands-on experience with research design and data analysis.\nThe semester is broken into 3 projects. The first will involve planning and executing a correlational analysis of existing data. The second will involve performing a multiple regression analysis on existing data. The third project will involve designing and pilot-testing a novel scale to measure an aspect of personality. Through these projects you will gain experience in formulating psychological research questions pertaining to personality; collecting, analyzing and visualizing data; and interpreting and communicating your findings. Projects will be undertaken in groups; group members will collaborate on design and analysis. Each project will culminate in an in-class group presentation and submission of a brief individual write up of your project.\n\nClass format & participation\nLabs are substantially more interactive and discussion-based than the traditional lecture format, and depend on everyone’s active participation in class discussions and activity as well as group work focused around the projects. Your active participation across the semester will therefore contribute a substantial portion of your grade.\nIf you have questions, thoughts, or ideas you want to share, feel free to do so at any time (while keeping within the bounds of polite conversation, obviously–don’t interrupt or talk over other people! But do feel free to respond to others without having to raise your hand or wait to be called on). Everyone will get the most out of this lab when the discussion can develop organically and everyone feels free to be part of the conversation if & when they have something to add.\nBeing part of the in-person discussion is one obvious way to participate, but it’s not the only way. Different people have different styles of participation, and the lab is designed to try and accommodate and encourage different approaches. Your level of engagement with your project partner(s), your TA and Prof. Brotherton as you work through your projects is also an important form of participation. You can also participate by coming to office hours.\nAt a minimum (i.e. for a passing grade), I’ll be looking for some form of participation (loosely defined) from you every week. Higher participation grades will be earned through regular, enthusiastic, productive participation (note that quality is more important than quantity).\n\n\nWorkload\nAs a general rule for the amount of time students should expect to commit to classes, the college suggests three hours per week in or outside of class per credit. Since this class is worth 1.5 credits, that corresponds to 4.5 hours per week, split between time in the classroom and time spent completing the associated assignments.\n\n\nFinal Grades\nYour numeric score for the course is a product of your scores for each assignment, weighted as follows:\n\n\n\n\n\n\nWeight (%)\n\n\n\n\nParticipation (over the course of the semester)\n10\n\n\nPresentations\n30\n\n\nReports\n60\n\n\n\n\n\nFinal grades are determined according to the following boundaries:\nLetter grade:  A+ A  A- B+ B  B- C+ C  C- D  F\nNumeric score: 97 93 90 87 83 80 77 73 70 60 <60"
  },
  {
    "objectID": "index.html#course-policies",
    "href": "index.html#course-policies",
    "title": "Personality Psychology Lab Handbook",
    "section": "Course policies",
    "text": "Course policies\n\nAttendance & timeliness\nIn-person attendance of every lab session is expected, and you should expect to stay for the full duration of the lab. Normally it is departmental policy to remove students who miss more than two lab sessions from the course; however, given ongoing revisions to college-wide health-related policies, exceptions may be made. If you are feeling unwell, you should not come to class and notify me of nonattendance before class if possible.\nWhen you are attending, please arrive on time for class. Frequent lateness will impact your participation grade.\n\n\nAssignment deadlines & late policy\nAssignments are listed in the class schedule next to the class in which details about completing the assignment will be provided. The assignment must be completed and submitted before the following class, i.e. requirements for the first presentation slide will be explained in class on 10/2, and the slide must be submitted before the next class on 10/9.\nFor the written project reports, a grade penalty of 5 points will be applied for each day (or part thereof) that an assignment is late (up to a maximum of 6 days; work not submitted before the next lab will receive a score of zero). For example, if your work is A+ quality but is submitted a day-and-a-half late, you will only receive a B+. This policy is intended to incentivize timely submission while easing the stress of genuine emergencies. When things come up that prevent timely submission you can prioritize accordingly, knowing that a small penalty on one assignment for this lab will not tank your final grade.\nLate submission for the presentation slides will not be possible; failure to submit a link to your slides in advance of the presentation will obviously limit your presentation grade.\n\n\nAcademic integrity\nStudents are expected to follow the Barnard Honor Code, available at https://barnard.edu/honor-code.\nNote that while you will collaborate with group members on the design, analysis, and presentation of research projects, you may not collaborate on the written report: each group member must write their own individual reports.\n\n\nAcademic accommodations and general wellness\nIt is always important to recognize the different pressures, burdens, and stressors you may be facing, whether personal, emotional, physical, financial, mental, or academic. The faculty and administration recognize this, and are prepared to provide assistance to students in need. I encourage you to seek advice from your advisor, Dean, the Center for Accessibility Resources & Disability Services (CARDS), or Barnard Health & Wellness as needed. Please let me know of any issues you wish to share with me that you feel are impacting your ability to complete the course to the best of your ability. Though it isn’t always easy, it is better to proactively seek help rather than letting problems build up."
  },
  {
    "objectID": "index.html#class-schedule",
    "href": "index.html#class-schedule",
    "title": "Personality Psychology Lab Handbook",
    "section": "Class schedule",
    "text": "Class schedule\n\n\n\n\n \n  \n    Date \n    Topic \n    Assignment \n  \n \n\n  \n    9/11 \n    Course overview \n     \n  \n  Project 1: Correlation\n\n    9/18 \n    Project planning \n     \n  \n  \n    9/25 \n    Data cleaning \n     \n  \n  \n    10/2 \n    Analysis \n    Presentation slide \n  \n  \n    10/9 \n    Presentations \n    Project 1 report \n  \n  Project 2: Multiple regression\n\n    10/16 \n    Project planning \n     \n  \n  \n    10/23 \n    Data cleaning & analysis \n     \n  \n  \n    10/30 \n    Visualization & reporting \n    Presentation slide \n  \n  \n    11/6 \n    Presentations \n    Project 2 report \n  \n  Project 3: Scale design\n\n    11/13 \n    Scale planning \n     \n  \n  \n    11/20 \n    Questionnaire design \n     \n  \n  \n    11/27 \n    No class (Thanksgiving) \n     \n  \n  \n    12/4 \n    Analysis & reporting \n    Presentation slide \n  \n  \n    12/11 \n    Presentations \n    Project 3 report \n  \n\n\n\n\n* Assignments due by the following class."
  },
  {
    "objectID": "lab-2.html#project-overview",
    "href": "lab-2.html#project-overview",
    "title": "Lab 2: Project Planning",
    "section": "Project overview",
    "text": "Project overview\nA correlation refers an association between two things. It is a statement of a statistical relationship–a general tendency, rather than a rigid law. To say that some aspect of personality is correlated with something else–for example, neuroticism is correlated with lower wellbeing or openness is correlated with greater cognitive ability–is to say that those things tend to go together. Not everyone who scores high on neuroticism will have lower wellbeing than anyone low on neuroticism, but there is some tendency for the two to go together on the whole.\nOf course, these kind of correlations aren’t just facts found lying around in nature; they are empirical findings produced by researchers. All the findings you learn about in the personality psychology lecture (and beyond) are the product of research procedures. Researchers decide what psychological constructs they want to investigate; how to operationally define those constructs; what statistical analyses are appropriate; and what conclusions may be drawn.\nWith this project, you will examine a correlation between a personality trait and some other construct of your choosing by analyzing existing data.\n\nStep 1. Examine the data\nThe dataset we will use is from the American National Election Studies (ANES), academic surveys of voters in the United States conducted before and after every presidential election, going back to the 1940s. Specifically, for this project we will use data collected around the 2016 election. The reason for using this (instead of more recent data) is that the 2016 survey included a personality scale: the Ten-Item Personality Inventory (TIPI: Gosling et al., 2003). This scale is a short measure of the Big 5 personality traits of Openness, Conscientiousness, Extraversion, Agreeableness, and Neuroticism. For your project, you will pick one of these traits and investigate its correlation with one of the other constructs recorded in the survey.\nTo see what variables were recorded, you will skim the Codebook. The codebook details the survey methodology exhaustively, including listing every question that was asked. It’s not fun reading, but it is your guide to picking out the question or construct that interests you the most.\nTo get you started, here are some of the things you will find:\n\nPolitical preferences and behavior (as you’d expect for a survey about politics, there are many questions about voting intentions, approval of various political actors, policy preferences, etc)\nMedia exposure and attention\nDemographic variables (age, race, gender, marital status, education, income, religion, etc)\nPolitical knowledge and general intelligence\nFeeling thermometers (0 to 100 scales of warmth of feeling towards various political actors and groups, like the president, democrats, Black Lives Matter)\nConspiracy beliefs (is Barack Obama Muslim? Did the U.S. government know about 9/11 in advance?)\nPersonality traits or personality-adjacent attitudes (religiosity; authoritarianism; traditionalism; conservatism; social trust; stereotypes; sexism; equalitarianism; patriotism; opinionatedness; security/anxiety about various things like personal finances, vaccine risks, etc; life satisfaction)\n\n\n\nStep 2. Find relevant research\nReal research doesn’t happen in a vacuum; research plans and expectations should be informed by what has come before. Therefore once you have an idea of what variables you would like to analyze, you will search the literature to see what other researchers have found of these (or related) personality traits.\n\nWhat to look for\nA published, scholarly journal article detailing an empirical finding relevant to your variables of interest. This might be a paper reporting one or several individual studies that the researchers conducted, or it may be a review paper or meta-analysis.1\n\n\nWhere to look\n\nGoogle Scholar\nGoogle Scholar searches the full text of scholarly articles. It casts a wide net, searching across all disciplines, and including books and other materials in addition to journal articles, so will likely find many articles not very relevant to the topic as well as those that are relevant.\n\n\nAPA PsycINFO\nThe link above should take you to PsycINFO, a database for scholarly psychology research (you can also search for psycinfo in a CLIO quicksearch). PsycInfo gives you the ability to do more focused searching than Google Scholar.\n\nYou can add many keywords and combine them with the Boolean operators AND, OR, and NOT by selecting them from the dropdown boxes.\nYou can select where your keywords should appear, i.e. in the title, abstract, or full text of articles. Selecting Word in Major Subject Heading can help narrow down your search to articles that are actually on the topic you’re interested in (rather than just containing the keyword).\n\n\n\n\n\nStep 3. Articulate your hypothesis\nHaving chosen your variables and found some relevant research to inform your theoretical perspective about how the variables are (or aren’t) associated, you should be able to articulate your hypothesis. This is a formal statement of your expectations about how the variables are associated, and it will be tested quantitatively by calculating a correlation statistic."
  },
  {
    "objectID": "lab-2.html#your-proposal",
    "href": "lab-2.html#your-proposal",
    "title": "Lab 2: Project Planning",
    "section": "Your proposal",
    "text": "Your proposal\nAt the start of next week’s class, each project team will give a short, informal presentation of their research proposal. This should outline:\n\nYour variables of interest (one should be one of the Big 5; the other any variable of your choosing)\nYour theoretical perspective (based on the research you found)\nYour expectations (this should follow from your theoretical perspective)"
  },
  {
    "objectID": "lab-3.html#working-with-data-in-r",
    "href": "lab-3.html#working-with-data-in-r",
    "title": "Lab 3: Data cleaning",
    "section": "Working with data in R",
    "text": "Working with data in R\n\nGetting R ready\nIn addition to containing a Big 5 personality scale, the ANES 2016 dataset is convenient for our purposes because someone went to the trouble of creating an R package which makes working with the ANES data relatively straightforward (not that you won’t still run into issues!): anesr (github.com/jamesmartherus/anesr).\nTo start exploring the data in R, you first need to set up your environment. This means installing the anesr package from github. Since the package is hosted on GitHub (as opposed to the official R repository of packages), the easiest way to install it is by first installing the devtools package, which has a function for installing other packages from GitHub.\n\ninstall.packages(\"devtools\")\n\ndevtools::install_github(\"jamesmartherus/anesr\")\n\nWe will also use some other packages for data wrangling and analysis. Developers have created a collection of packages for R called the tidyverse to make coding these common tasks easier. The tidyverse can be installed like so:\n\ninstall.packages(\"tidyverse\")\n\nIf you execute those lines of code the packages will be installed on your system. That step only needs to be done once, but you need to ‘activate’ the packages using library() to make their functions and data available each time to start a new R session.\n\nlibrary(anesr)\nlibrary(tidyverse)\n\n\n\nGetting data into R\nOften getting your data into R involves reading in a .csv (comma-separated values) spreadsheet file that you downloaded to your computer. Indeed, if you needed to you could download the ANES 2016 data file as a .csv from the ANES website and read it into R. However, the anesr package contains the data so you don’t need to download it separately. Instead you can make it available by running this line of code:\n\ndata(timeseries_2016)\n\nWhen you execute the code you won’t see any output, but you should see the name timeseries_2016 appear in your Environment pane. That is now an object in R called a data.frame. You can think of it as a spreadsheet like you’re familiar with from Excel or Google Sheets; a set of columns, one for each variable in the dataset, and a row for each participant’s answers.\nTyping the name of the data.frame and running that line of code will show the first few columns and rows.\n\ntimeseries_2016\n\n# A tibble: 4,270 × 1,842\n   version       V160001 V160001_orig V160101 V160101f V160101w V160102 V160102f\n   <chr>           <dbl>        <dbl>   <dbl>    <dbl>    <dbl>   <dbl>    <dbl>\n 1 ANES2016Time…       1       300001   0.827    0.888        0   0.842    0.927\n 2 ANES2016Time…       2       300002   1.08     1.16         0   1.01     1.08 \n 3 ANES2016Time…       3       300003   0.388    0.416        0   0.367    0.398\n 4 ANES2016Time…       4       300004   0.360    0.385        0   0.366    0.418\n 5 ANES2016Time…       5       300006   0.647    0.693        0   0.646    0.726\n 6 ANES2016Time…       6       300007   0.706    0.759        0   0.688    0.725\n 7 ANES2016Time…       7       300008   3.96     4.25         0   4.62     4.79 \n 8 ANES2016Time…       8       300012   0.962    1.03         0   0.943    1.04 \n 9 ANES2016Time…       9       300018   0.976    1.05         0   1.01     1.07 \n10 ANES2016Time…      10       300020   0.618    0.664        0   0.600    0.638\n# ℹ 4,260 more rows\n# ℹ 1,834 more variables: V160102w <dbl>, V160201 <dbl>, V160201f <dbl>,\n#   V160201w <dbl>, V160202 <dbl>, V160202f <dbl>, V160202w <dbl>,\n#   V160501 <hvn_lbll>, V160502 <hvn_lbll>, V161001 <hvn_lbll>,\n#   V161002 <hvn_lbll>, V161003 <hvn_lbll>, V161004 <hvn_lbll>,\n#   V161005 <hvn_lbll>, V161006 <hvn_lbll>, V161007 <hvn_lbll>,\n#   V161008 <hvn_lbll>, V161009 <hvn_lbll>, V161010a <hvn_lbll>, …\n\n\nYou can also click on the name in the Environment pane to see the data like a spreadsheet in a new tab.\n\n\nSelect your variables\nAs you can see, the data.frame contains a lot of variables; there are 1,842 columns of data. You’ll only need a few of those. So the first step is selecting just the variables you need to work with.\nThere are a lot of ways to do this. The simplest would be to make a note of the variable IDs from the codebook and use them within dplyr’s select() function. This allows us to simply type in variable names separated by commas.\nFor this example I’ll look at the correlation between extraversion and the Democratic part feeling thermometer. Extraversion has two TIPI items; their IDs (from the codebook) are V162333 and V162338. The ID for the Democratic Party feeling thermometer is V161095. Since I’ll probably forget which ID is which, I’ll give the columns more meaningful names as I select them.\n\nmy_data <- timeseries_2016 |> \n  select(extraversion1 = \"V162333\", \n         extraversion2 = \"V162338\",\n         feeling_thermometer = \"V161095\")\n\nLet’s see what this new data.frame looks like:\n\nmy_data\n\n# A tibble: 4,270 × 3\n   extraversion1 extraversion2 feeling_thermometer\n   <hvn_lbll>    <hvn_lbll>    <hvn_lbll>         \n 1 6             5              0                 \n 2 6             6             15                 \n 3 6             2             50                 \n 4 6             4             30                 \n 5 5             7             70                 \n 6 5             6             15                 \n 7 5             1             85                 \n 8 6             3              0                 \n 9 7             1             15                 \n10 5             5             50                 \n# ℹ 4,260 more rows\n\n\nIt all looks good so far. But if you inspect the data more extensively (click the name in your Environment and scroll down a bit) you’ll notice that there are some negative numbers in the data. That’s from survey codes which record missing data. If you try to calculate an average score with those included it’ll mess up the sums, so we need to do some data cleaning to handle things like that.\n\n\nCleaning the data\nThere are a lot of different ways we could handle this. One way is to filter() the data, retaining only rows which meet certain conditions.1\nThe ANES coding scheme uses negative values for the various kinds of missing or inappropriate data, which makes things simple. We know that any positive values are valid and any negative values should be dropped.\nTo implement this as a filter(), we can use the if_all() function; i.e., we are going to select some columns and if all the values in those columns meet some condition the row will be retained. To select the columns we can use the everything() function, since the positive-valid/negative-invalid rule is true of every column in our data. The part after the comma, ~ . >= 0, articulates the condition. The ~ prefix is necessary because instead of naming one specific column to refer to its values we use . as a placeholder representing the values in each of the selected columns; the value must be greater than or equal to 0 to be retained.2\n\nmy_data_complete <- my_data |> \n  filter(if_all(everything(), ~ . >= 0))\n\nNotice that the number of rows in the data.frame has changed, because rows that didn’t meet that condition have been dropped.\n\nnrow(my_data)\n\n[1] 4270\n\nnrow(my_data_complete) \n\n[1] 3540\n\n\nAfter filtering to keep only rows with complete data, we’re left with 3,540 valid responses.\n\n\nComputing scale averages\nNow that we have selected our columns and filtered out missing/invalid responses, the last thing to do is compute any new values required for analysis. As an example, if you have a scale which has multiple questions asking about a particular construct, it is often necessary to compute an average score for each participant.\nThe TIPI has 10 questions in total, two for each of the Big 5 personality traits, so it may be desirable to compute a mean trait score by averaging its two respective items.\nNotice, however, that for each of the 5 traits, one question is positively worded and one is negatively worded. For extraversion, item V162333 is “extraverted, enthusiastic”, while item V162338 is “reserved, quiet”. The second one needs to be reverse-coded, so that higher scores on both items indicate greater extraversion. Since answers can range from 1 to 7, an easy way to recode the scores is to subtract the participant’s response from 8; 1 becomes 7, 2 becomes 6, etc.\n\nmy_data_complete <- my_data_complete |>\n    mutate(extraversion2 = 8 - extraversion2)\n\nNow we can go ahead and compute the average, using mutate() to create a new column (named extraversion_mean) consisting of the rowMeans() (i.e. an average for each row) across() the specified columns (those for which the column name contains(\"extraversion\").\n\nmy_data_complete <- my_data_complete |>\n    mutate(extraversion_mean = rowMeans(across(contains(\"extraversion\"))))"
  },
  {
    "objectID": "lab-4.html#analyzing-data-in-r",
    "href": "lab-4.html#analyzing-data-in-r",
    "title": "Lab 4: Analysis",
    "section": "Analyzing data in R",
    "text": "Analyzing data in R\nRunning with my example from last week, my variables were avearge extraversion scores and the Democratic Party feeling thermometer score. I made a data.frame with just those variables, filtered the data down to complete, valid responses, recoded the negatively-worded item, and computed an extraversion mean score. To refresh your memory, here’s the entire pipeline from start to finish:\n\nlibrary(tidyverse)\nlibrary(anesr)\ndata(timeseries_2016)\n\nmy_data_complete <- timeseries_2016 |> \n  select(extraversion1 = \"V162333\", \n         extraversion2 = \"V162338\",\n         feeling_thermometer = \"V161095\") |> \n  filter(if_all(everything(), ~ . >= 0)) |> \n  mutate(extraversion2 = 8 - extraversion2,\n         extraversion_mean = rowMeans(across(contains(\"extraversion\"))))\n\n\nDescribing your data\nThe most common descriptive statistics are the mean (\\(M\\)) and standard deviation (\\(SD\\)). You should compute and report these for each variable in your analysis.\nYou can find the mean of each column in a data.frame using R’s built-in colMeans() function.\n\ncolMeans(my_data_complete)\n\n      extraversion1       extraversion2 feeling_thermometer   extraversion_mean \n           4.787006            3.649718           48.317232            4.218362 \n\n\nThere’s no built-in equivalent for finding the standard deviation of columns, but there is a basic sd() function, which you could apply to each column in turn:\n\nsd(my_data_complete$extraversion1)\n\n[1] 1.579163\n\nsd(my_data_complete$extraversion2)\n\n[1] 1.764589\n\n# etc\n\nThis might be a perfectly appropriate approach, but with a lot of variables it might not be the most efficient (and it kind of violates the DRY principle: don’t repeat yourself).\nA slightly more complicated but very powerful approach is to use tidyverse functions to reshape the data and summarize() each of the variables. First, transform the structure of the data using pivot_longer(). This produces a data.frame with just two columns, one with all the numeric scores (“value”), and the other labeling which column each value came from (“variable”). Then we group_by(variable), meaning that any subsequent computations will be performed separately for each variable. Finally we pipe the data.frame into the summarize() function. There you can create any number of named variables, each computing some kind of summary. Since the data is grouped, each variable (“extraversion1”, extraversion2”, etc) gets its own count, mean, and standard deviation.\n\nmy_data_complete |>\n  pivot_longer(everything(), \n               names_to = \"variable\", \n               values_to = \"value\", \n               values_transform = as.numeric) |> \n  group_by(variable) |> \n  summarize(count_valid = n(),\n            mean = mean(value), \n            sd = sd(value))\n\n# A tibble: 4 × 4\n  variable            count_valid  mean    sd\n  <chr>                     <int> <dbl> <dbl>\n1 extraversion1              3540  4.79  1.58\n2 extraversion2              3540  3.65  1.76\n3 extraversion_mean          3540  4.22  1.38\n4 feeling_thermometer        3540 48.3  30.0 \n\n\n\n\nVisualizing the data\nIn addition to reporting the mean and standard deviation, it is useful to visualize the distribution of the data. This can reveal nuances that are not obvious in those single numeric summary values.\nAs with most things, there are a lot of different ways of producing graphs using R. One of the most widely used and powerful is the ggplot2 package.1 The name refers to the idea of the “grammar of graphics”, and it is built around a layering approach. You first specify your data and aesthetics (what should data will go on the x and y axes), then geometry (do you want data to be represented by points or bars or as a histogram?), any scaling (e.g. what values should be labeled on each axis), and theme elements (how do you want the plot to look generally?). There can be a lot of complexity, but building things up layer by layer, gradually adding and refining elements, is a powerful and satisfying approach.\nHere’s a simple histogram of the first extraversion item. I pipe the data into the ggplot() function, specifying that I want the extraversion1 column to be represented as the x aesthetic. Then I add geometry using geom_histogram. That geom function automatically computes bins and counts; here I just specify I want a binwidth of 1, i.e. each column of the histogram will represent one scale point. Note that ggplot layers are added using + rather than the usual |> pipe.\n\nmy_data_complete |> \n  ggplot(aes(x = extraversion1)) +\n  geom_histogram(binwidth = 1)\n\nDon't know how to automatically pick scale for object of type <haven_labelled>.\nDefaulting to continuous.\n\n\n\n\n\nFigure 1: Histogram of responses to “extraverted, enthusiastic” TIPI item\n\n\n\n\nThe default theme is perfectly serviceable, but you can customize every element. Here I’ll specify a couple of aspects using the theme() function, and I’ll assign it to the name theme_apa. Then I can always add theme_apa as a layer to my plots going forward.\n\ntheme_apa <- theme(\n  panel.background = element_blank(),\n  axis.line = element_line()\n)\n\nI’ll also customize the “breaks” on the x-axis (where the ticks and numeric labels go) and the axis labels.\n\nmy_data_complete |> \n  ggplot(aes(x = extraversion1)) +\n  geom_histogram(binwidth = 1, color = \"white\") +\n  scale_x_continuous(breaks = 1:7) +\n  labs(x = \"Responses to extraversion item 1: extraverted, enthusiastic\",\n       y = \"Number of responses\") +\n  theme_apa\n\n\n\n\nFigure 2: Histogram of responses to “extraverted, enthusiastic” TIPI item\n\n\n\n\nHere’s a histogram of the other TIPI extraversion item.\n\nmy_data_complete |> \n  ggplot(aes(x = extraversion2)) +\n  geom_histogram(binwidth = 1, color = \"white\") +\n  scale_x_continuous(breaks = 1:7) +\n  labs(x = \"Responses to extraversion item 2: reserved, quiet (reverse-coded)\",\n       y = \"Number of responses\") +\n  theme_apa\n\n\n\n\nFigure 3: Histogram of responses to “reserved, quiet” TIPI item\n\n\n\n\nAnd here’s a histogram of the average extraversion scores I computed.\n\nmy_data_complete |> \n  ggplot(aes(x = extraversion_mean)) +\n  geom_histogram(binwidth = 0.5, color = \"white\") +\n  scale_x_continuous(breaks = 1:7) +\n  labs(x = \"Average scores across both TIPI extraversion items\",\n       y = \"Count\") +\n  theme_apa\n\n\n\n\nFigure 4: Histogram of average scores on TIPI Extraversion subscale\n\n\n\n\nNotice that while both individual extraversion items were a bit skewed, the distribution of averages is approximately normally-distributioned (albeit with a big spike in the middle).\nLastly, I’ll make a histogram of the feeling thermometer variable.\n\nmy_data_complete |> \n  ggplot(aes(x = feeling_thermometer)) +\n  geom_histogram(binwidth = 1, color = \"white\") +\n  scale_x_continuous(breaks = seq(from = 0, to = 100, by = 10)) +\n  labs(x = \"Responses to Democratic Party feeling thermometer\",\n       y = \"Count\") +\n  theme_apa\n\n\n\n\nFigure 5: Histogram of responses to Democratic Party feeling thermometer\n\n\n\n\nI chose a binwidth of 1, which isn’t necessarily the most appropriate value for a 0 to 100, but it does reveal an interesting distribution of responses. People’s responses are not evenly distributed across the 0 to 100 scale; rather, some values (particularly multiples of 10) are chosen much more frequently than others."
  },
  {
    "objectID": "lab-4.html#correlation-analysis",
    "href": "lab-4.html#correlation-analysis",
    "title": "Lab 4: Analysis",
    "section": "Correlation analysis",
    "text": "Correlation analysis\n\nThe correlation statistic\nThe correlation statistic can be computed with a single line of code, as you’ll see. But it’s important to understand the math happening behind the scenes.\n\n\nCorrelation in R\nThe data is ready to be analyzed. The correlation between two variables can be found using the cor() function.\n\ncor(x = my_data_complete$extraversion_mean, \n    y = my_data_complete$feeling_thermometer)\n\n[1] -0.01012898\n\n\nIf you got an answer of NA instead of a number, it is probably because your data has some missing data. You just need to tell cor() to only use data for which both pairs of values are nonmissing:\n\ncor(x = my_data_complete$extraversion_mean, \n    y = my_data_complete$feeling_thermometer,\n    use = \"pairwise.complete.obs\")\n\n[1] -0.01012898\n\n\nThe cor.test() function goes further than cor(), giving you the \\(p\\)-value (necessary for determining statistical significance) and some other information about the correlation.\n\ncor.test(x = my_data_complete$extraversion_mean, \n         y = my_data_complete$feeling_thermometer)\n\n\n    Pearson's product-moment correlation\n\ndata:  my_data_complete$extraversion_mean and my_data_complete$feeling_thermometer\nt = -0.60251, df = 3538, p-value = 0.5469\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.04305838  0.02282241\nsample estimates:\n        cor \n-0.01012898 \n\n\nLastly, let’s make a scatterplot visualizing the correlation.\n\nmy_data_complete |> \n  ggplot(aes(x = extraversion_mean, y = feeling_thermometer)) +\n  geom_point(position = position_jitter(width = 0.4, height = 0), \n             alpha = 0.1) +\n  scale_x_continuous(breaks = 1:7) +\n  scale_y_continuous(breaks = seq(from = 0, to = 100, by = 10)) +\n  theme_apa\n\n\n\n\nFigure 6: Scatterplot (with jitter) of average extraversion scores and feeling thermometer scores\n\n\n\n\nYou can see horizontal bands which correspond to those big spikes on the feeling thermometer that the histogram revealed. Consistent with the correlation coefficient which was close to zero, visually it doesn’t look like there’s much of an association between the feeling thermometer responses and extraversion scores."
  },
  {
    "objectID": "lab-5.html#presentation",
    "href": "lab-5.html#presentation",
    "title": "Lab 5: Presentations",
    "section": "Presentation",
    "text": "Presentation\n\nGuide to presenting\nEach team will give a short presentation which should encapsulate the motivation, methods, anticipated findings, and interpretation of your proposed project. Aim for clarity, conciseness, and being bold to spark the audience’s interest in your topic and findings.\nAvoid simply reading excerpts from your paper. That would be boring, and would probably take up too many words. Make it fun and interesting. Try to grab the audience’s attention and hit them with just the most important points of your ideas.\nMake your slides count. You can’t just cram a load of text on there, because nobody will be able to read it. Plus, it’d distract from what you’re saying. Make it a visual aid that somehow supports or clarifies what you’re saying. It might be a visual representation of your design, a key piece of your experimental stimuli, a graph of your expected results, or just a pertinent meme which conveys the motivation for your question.\nAfter your presentation the group will take a few questions from the audience, and your responsiveness will contribute toward your grade as well as the quality of your presentation itself (remember a perfectly acceptable answer if often: “Good question; I don’t know the answer!”). It’s not usually an issue, but just in case your audience is left speechless, I suggest coming with a couple of questions or thoughts of your own that you can throw at the audience to spark more questions.\nIt is up to each group to decide how to divide up the talk, and to practice to make sure the presentation is to time.\n\n\nGuide to watching presentations\nAs an audience member, you are still being graded for class participation. That means giving everyone else’s presentation the attention and enthusiasm it deserves, and rewarding their hard work with questions. (Going to the trouble of putting together a presentation only for nobody to have anything to say about it is not a good feeling.)\nGood questions to ask are things like “Could you clarify X”, “Had you considered Y”, or “How might this relate to Z.” One reason for presenting your project is to hopefully get some useful feedback from the audience with which to refine your final paper, so try to give the kind of feedback you hope to receive."
  },
  {
    "objectID": "lab-5.html#sec-report",
    "href": "lab-5.html#sec-report",
    "title": "Lab 5: Presentations",
    "section": "Written report",
    "text": "Written report\nYou will produce a miniature research paper reporting your project. Note that each team member will produce their own individual report; even though the project has been collaborative, your write up will be your own.\nYour report should consist of the following sections:\n\nIntroduction (two or three paragraphs, including summary of relevant research and hypothesis)\nMethod (a description of the variables you selected, the number of valid responses, and any other information about the procedures that generated the data that you think necessary to report)\nResults (all the descriptive statistics, figures, and statistics you produced)\nDiscussion (a paragraph or two interpreting your results and drawing conclusions)"
  },
  {
    "objectID": "lab-6.html#project-overview",
    "href": "lab-6.html#project-overview",
    "title": "Lab 6: Project planning",
    "section": "Project overview",
    "text": "Project overview\nMultiple regression goes beyond simple correlations and captures the relationships between multiple predictor variables and a single outcome variable. It allows us to see the combined impact of multiple variables on one outcome, and how these predictors may interact with each other to affect the outcome. This can provide valuable insights into how the relationship between one predictor and the outcome might depend on the level of another predictor.\nFor instance, researchers might examine how several Big Five personality traits like extraversion, conscientiousness, and neuroticism can predict job satisfaction. Similarly, variables such as age, education, and openness might be used in a multiple regression analysis to predict political ideologies. Like with correlations, this doesn’t mean that every extroverted, conscientious, and emotionally stable person will always be satisfied with their job, or that all older, educated, and open individuals are politically aligned in the same way. It’s about general tendencies rather than strict rules.\nLike correlation, regression studies involve determining which psychological constructs to study, how to operationally define those constructs, and how to measure them. They then use these definitions and measurements to explore relationships, using appropriate statistical analyses.\nWith this project, you will dive deeper into the interplay between personality traits and other constructs, using multiple regression analysis to explore how a combination of predictors contributes to an outcome of your choice by analyzing existing data. This will empower you to better understand the complex interactions that shape human behavior and personality, beyond simple one-to-one relationships.\n\nStep 1. Choose your dataset and variables\nWe will again use data from the ANES. I suggest that you use the 2016 dataset again; you may even look a the same variables you did with Project 1 and just add one or more new predictors. However, if you’re feeling ambitious or limited by what’s available in the 2016 dataset you may choose a different one (the most recent is from 2022), or even use the cumulative timeseries data which combines data from across the many years the study has been conducted (this would be a good choice if you want to see how the passage of time might have contributed to a change on some outcome of interest).\n\n\nStep 2. Find relevant research\nAs with Project 1, your approach here should be informed by what has come before. Once you have an idea of what variables you would like to analyze, you will search the literature to see what other researchers have found of these (or related) personality traits.\n\n\nStep 3. Articulate your hypothesis\nHaving chosen your variables and found some relevant research to inform your theoretical perspective about how the variables are (or aren’t) associated, you should be able to articulate your hypothesis. This is a formal statement of your expectations about how the variables are associated, and it will be tested quantitatively by computing the regression model.\nA choice you will make at this point is whether you will study the simple additive effect of your predictors, or whether you will look at the interaction between your predictors. An interaction effect means that two (or more) variables combined have a significantly larger effect on a feature as compared to the sum of the individual variables alone.\nThe general hypothesis of a multiple regression is that there is a relationship between the predictor variables and the outcome variable; in other words, the predictors allow us to predict scores on the outcome more accurately than you would expect if the variables we unrelated."
  },
  {
    "objectID": "lab-6.html#your-proposal",
    "href": "lab-6.html#your-proposal",
    "title": "Lab 6: Project planning",
    "section": "Your proposal",
    "text": "Your proposal\nAt the start of next week’s class, each project team will give a short, informal presentation of their research proposal. This should outline:\n\nYour variables of interest\nYour theoretical perspective (based on the research you found)\nYour expectations (this should follow from your theoretical perspective)"
  },
  {
    "objectID": "lab-7.html#multiple-regression-in-r",
    "href": "lab-7.html#multiple-regression-in-r",
    "title": "Lab 7: Data cleaning & analysis",
    "section": "Multiple Regression in R",
    "text": "Multiple Regression in R\n\nData wrangling\nBuilding on the correlation example, we will include additional variables of interest - conscientiousness and agreeableness - to examine how these factors, along with extraversion, collectively predict feelings towards the Democratic party. Similar to the correlation project, we will start by cleaning and filtering the data, recoding the negatively-worded items (taking care to note which ones need recoding; it’s not always the second question), and computing mean scores for each Big 5 trait.\nHere is the pipeline to prepare the data:\n\nlibrary(tidyverse)\nlibrary(anesr)\ndata(timeseries_2016)\n\nmy_data_complete <- timeseries_2016 |> \n  select(extraversion1 = \"V162333\", \n         extraversion2 = \"V162338\",\n         conscientiousness1 = \"V162335\", \n         conscientiousness2 = \"V162340\",\n         agreeableness1 = \"V162334\", \n         agreeableness2 = \"V162339\",\n         feeling_thermometer = \"V161095\") |> \n  filter(if_all(everything(), ~ . >= 0))  |>\n  mutate(extraversion2 = 8 - extraversion2,\n         conscientiousness2 = 8 - conscientiousness2,\n         agreeableness1 = 8 - agreeableness1,\n         extraversion_mean = rowMeans(across(contains(\"extraversion\"))),\n         conscientiousness_mean = rowMeans(across(contains(\"conscientiousness\"))),\n         agreeableness_mean = rowMeans(across(contains(\"agreeableness\"))))\n\n\n\nDescribing your variables\nJust as in the previous lab, you’ll need to compute the mean and standard deviation for each of your variables. Use the same process, replacing the variable names with your new ones:\n\nmy_data_complete |>\n  pivot_longer(everything(), \n               names_to = \"variable\", \n               values_to = \"value\", \n               values_transform = as.numeric) |> \n  group_by(variable) |> \n  summarize(count_valid = n(),\n            mean = mean(value), \n            sd = sd(value))\n\n# A tibble: 10 × 4\n   variable               count_valid  mean    sd\n   <chr>                        <int> <dbl> <dbl>\n 1 agreeableness1                3530  4.73  1.67\n 2 agreeableness2                3530  5.68  1.23\n 3 agreeableness_mean            3530  5.21  1.14\n 4 conscientiousness1            3530  5.99  1.16\n 5 conscientiousness2            3530  5.41  1.54\n 6 conscientiousness_mean        3530  5.70  1.12\n 7 extraversion1                 3530  4.79  1.58\n 8 extraversion2                 3530  3.65  1.77\n 9 extraversion_mean             3530  4.22  1.38\n10 feeling_thermometer           3530 48.3  30.0 \n\n\n\n\nVisualizing the data\nYou can create histograms for each of your new variables, just like you did for extraversion. Since there are\n\ntheme_apa <- theme(\n  panel.background = element_blank(),\n  axis.line = element_line()\n)\n\n\nmy_data_complete |>\n  select(extraversion1:agreeableness2) |> \n  pivot_longer(everything(), \n               names_to = \"variable\", \n               values_to = \"value\", \n               values_transform = as.numeric) |> \n  ggplot(aes(x = value)) +\n  geom_histogram(binwidth = 1, color = \"white\") +\n  scale_x_continuous(breaks = 1:7) +\n  facet_wrap(~variable, nrow = 3) +\n  theme_apa\n\n\n\n\n\nmy_data_complete |>\n  select(contains(\"mean\")) |> \n  pivot_longer(everything(), \n               names_to = \"variable\", \n               values_to = \"value\", \n               values_transform = as.numeric) |> \n  ggplot(aes(x = value)) +\n  geom_histogram(binwidth = 0.5, color = \"white\") +\n  scale_x_continuous(breaks = 1:7) +\n  facet_wrap(~variable, nrow = 3) +\n  theme_apa"
  },
  {
    "objectID": "lab-7.html#regression-analysis",
    "href": "lab-7.html#regression-analysis",
    "title": "Lab 7: Data cleaning & analysis",
    "section": "Regression analysis",
    "text": "Regression analysis\nNow we’ll perform a multiple regression analysis. This allows us to examine the relationship between one dependent variable (in this case, feeling_thermometer) and several independent variables (extraversion_mean, conscientiousness_mean, and agreeableness_mean).\n\nmodel <- lm(feeling_thermometer ~ extraversion_mean + conscientiousness_mean + agreeableness_mean, data = my_data_complete)\n\nsummary(model)\n\n\nCall:\nlm(formula = feeling_thermometer ~ extraversion_mean + conscientiousness_mean + \n    agreeableness_mean, data = my_data_complete)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-54.523 -24.494   2.127  22.216  55.932 \n\nCoefficients:\n                        Estimate Std. Error t value Pr(>|t|)    \n(Intercept)            51.218290   3.342704  15.322  < 2e-16 ***\nextraversion_mean      -0.006588   0.369615  -0.018 0.985780    \nconscientiousness_mean -1.633627   0.476950  -3.425 0.000621 ***\nagreeableness_mean      1.234787   0.465963   2.650 0.008086 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 29.96 on 3526 degrees of freedom\nMultiple R-squared:  0.00422,   Adjusted R-squared:  0.003373 \nF-statistic: 4.981 on 3 and 3526 DF,  p-value: 0.001893\n\n\nThe summary() function will output the results of your regression analysis. For each predictor, you’ll see an estimate of the relationship between that predictor and the outcome variable, controlling for the other predictors. These are your regression coefficients. You’ll also see a t-value and a p-value for each predictor, which tell you whether each predictor is significantly related to the outcome variable, controlling for the other predictors. The summary will also include information on the overall model fit.\n\nVisualizing a regression model\nFinally, as you did in the correlation project, you’ll want to create a scatterplot to visualize the relationships between your predictors and the outcome variable. This will be more complex than in the correlation project, since you now have more variables to include."
  },
  {
    "objectID": "lab-8.html",
    "href": "lab-8.html",
    "title": "Lab 8: Visualization & reporting",
    "section": "",
    "text": "Goals\n\nStyle and contents of an APA Introduction section\nHow to frame previous findings to create a coherent and compelling justification\nAPA style for citations & references"
  },
  {
    "objectID": "lab-9.html",
    "href": "lab-9.html",
    "title": "Lab 9: Presentations",
    "section": "",
    "text": "Present in class.\nWrite up due by next class."
  },
  {
    "objectID": "lab-10.html#goals",
    "href": "lab-10.html#goals",
    "title": "Lab 10: Scale planning",
    "section": "Goals",
    "text": "Goals\n\nUnderstand the process of scale design and validation\nPick a personality trait to design a scale around\nWrite a brief proposal of your project and expectations"
  },
  {
    "objectID": "lab-11.html#goals",
    "href": "lab-11.html#goals",
    "title": "Lab 11: Questionnaire design",
    "section": "Goals",
    "text": "Goals\n\nGenerate items\nConsider face validity\nDecide on reponse options\nCreate your survey using Google Forms"
  },
  {
    "objectID": "lab-13.html",
    "href": "lab-13.html",
    "title": "Lab 13: Presentations",
    "section": "",
    "text": "Present in class.\nWrite up due by next class."
  },
  {
    "objectID": "appendix-r-basics.html",
    "href": "appendix-r-basics.html",
    "title": "Appendix A — Getting started with R",
    "section": "",
    "text": "Fundamentals of R for data analysis\nR is a programming language well-suited to interactive data exploration and analysis. It might seem daunting if you’ve have no experience with coding, but the basic idea is that you have some data, like you are familiar with from a regular Excel or Google Sheets spreadsheet, and you perform operations on your data using functions a lot like you would in Excel/Sheets. For example, you might compute an average in Sheets by typing =AVERAGE(A1:A10). In R you might type mean(my_data$column_a). The specifics of the function names are different, but the basic idea is the same.\nThere are two other ideas that will help you get started coding in R."
  },
  {
    "objectID": "appendix-r-basics.html#posit.cloud",
    "href": "appendix-r-basics.html#posit.cloud",
    "title": "Appendix A — Getting started with R",
    "section": "posit.cloud",
    "text": "posit.cloud\nYou will use posit.cloud to work with data in R.\n\nLet’s do something cool\nOnce you have a posit.cloud account, click this link.\n\n\nWait, what are you talking about?\nThere are a few different names involved here, so to try and clear things up:\n\nR is a coding language\nRStudio is a software interface for using R\nPosit is the name of the company that makes RStudio\nposit.cloud provides a way of using RStudio in your web browser\n\nYou can install R and RStudio on your own computer for free and do things that way, but using the cloud-based RStudio via posit.cloud simplifies things immesnely."
  }
]